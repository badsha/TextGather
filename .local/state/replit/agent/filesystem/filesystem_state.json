{"file_contents":{"DEPLOYMENT_GUIDE.md":{"content":"# VoiceScript Collector - Local Deployment Guide\n\n## Quick Start\n\n### Prerequisites\n- Python 3.8 or higher\n- 50MB free disk space for audio files\n- Modern web browser with microphone access\n\n### Automated Setup\n1. Download or clone the project to your local machine\n2. Open terminal in the project directory\n3. Run the deployment script:\n   ```bash\n   ./deploy.sh\n   ```\n4. Start the application:\n   ```bash\n   ./start.sh\n   ```\n\nThe application will be available at: http://localhost:8000\n\n## Demo Accounts\n- **Provider**: `provider@demo.com` / `demo123`\n- **Reviewer**: `reviewer@demo.com` / `demo123`  \n- **Admin**: `admin@demo.com` / `demo123`\n\n## Manual Setup (Alternative)\n\n### 1. Environment Setup\n```bash\n# Create virtual environment\npython3 -m venv venv\nsource venv/bin/activate\n\n# Install dependencies\npip install flask flask-sqlalchemy python-dotenv werkzeug gunicorn\n\n# Create uploads directory\nmkdir -p uploads\nchmod 755 uploads\n```\n\n### 2. Configuration\nCreate `.env` file:\n```bash\nFLASK_ENV=production\nFLASK_DEBUG=False\nSECRET_KEY=your-secret-key-here\nDATABASE_URL=sqlite:///voicescript.db\nUPLOAD_FOLDER=uploads\nMAX_CONTENT_LENGTH=52428800\n```\n\n### 3. Database Initialization\n```bash\npython3 -c \"\nfrom app import app, db, create_demo_data\nwith app.app_context():\n    db.create_all()\n    create_demo_data()\n\"\n```\n\n### 4. Start Application\n```bash\npython app.py\n```\n\n## Production Deployment\n\n### Using Gunicorn\n```bash\ngunicorn --bind 0.0.0.0:8000 --workers 4 app:app\n```\n\n### Using Systemd (Linux)\n1. Copy service file: `sudo cp voicescript-collector.service /etc/systemd/system/`\n2. Enable service: `sudo systemctl enable voicescript-collector`\n3. Start service: `sudo systemctl start voicescript-collector`\n\n## Features Overview\n\n### Data Providers\n- Record audio content using browser microphone\n- Submit text-based content\n- View submission history and earnings\n- Track word count and payment calculations\n\n### Quality Reviewers  \n- Review pending submissions\n- Rate content quality (1-5 stars)\n- Approve, reject, or request changes\n- Track review earnings (fixed rate per review)\n\n### Administrators\n- Manage languages and pricing rates\n- Create and edit recording scripts\n- View platform analytics\n- Manage user accounts and roles\n\n## Technical Architecture\n\n### Backend\n- **Framework**: Flask (Python)\n- **Database**: SQLite (local) / PostgreSQL (production)\n- **Authentication**: Session-based with secure cookies\n- **File Storage**: Local filesystem with secure upload handling\n\n### Frontend  \n- **Styling**: Tailwind CSS\n- **Icons**: Font Awesome\n- **Audio**: MediaRecorder API (WebRTC)\n- **Forms**: HTML5 with JavaScript validation\n\n### Key Components\n- Multi-role authentication system\n- Language-specific pricing management\n- Audio recording and playback\n- Real-time billing calculations\n- Responsive dashboard interfaces\n\n## Security Features\n- Secure session management\n- File upload validation and restrictions\n- Role-based access control\n- CSRF protection\n- Input sanitization\n\n## Troubleshooting\n\n### Common Issues\n\n**Microphone not working**\n- Ensure browser has microphone permissions\n- Use HTTPS in production for microphone access\n- Check browser compatibility (Chrome/Firefox recommended)\n\n**Database errors**\n- Delete `voicescript.db` and run initialization again\n- Check file permissions in project directory\n\n**Port 8000 already in use**\n- Change port in `app.py`: `app.run(host='0.0.0.0', port=9000)`\n- Or kill existing process: `lsof -ti:8000 | xargs kill -9`\n\n**Audio files not playing**\n- Check uploads directory permissions: `chmod 755 uploads`\n- Verify file paths in database match actual files\n\n### Performance Optimization\n- Use Gunicorn with multiple workers for production\n- Configure nginx as reverse proxy for better performance\n- Enable gzip compression for static assets\n- Monitor disk space for audio file storage\n\n## Support\nFor issues or questions:\n1. Check this deployment guide\n2. Review error logs in terminal\n3. Verify all prerequisites are installed\n4. Try rerunning the deployment script","size_bytes":4051},"LOCAL_DEPLOYMENT.md":{"content":"# Local Mac Mini Deployment Instructions\n\n## Step-by-Step Setup for Mac Mini\n\n### 1. Prepare Your Mac Mini\nEnsure your Mac Mini has:\n- macOS 10.15+ (Catalina or newer)\n- Python 3.8+ (check with `python3 --version`)\n- At least 1GB free space\n- Terminal access\n\n### 2. Download the Project\n```bash\n# If you have the project files, navigate to the directory\ncd /path/to/voicescript-collector\n\n# Or if downloading, extract to desired location\n# Make sure all project files are present\n```\n\n### 3. Run Automated Setup\n```bash\n# Make deployment script executable (if needed)\nchmod +x deploy.sh\n\n# Run the deployment script\n./deploy.sh\n```\n\nThe script will:\n- ✅ Check Python installation\n- ✅ Create virtual environment\n- ✅ Install all dependencies\n- ✅ Set up database with demo data\n- ✅ Create startup scripts\n- ✅ Configure security settings\n\n### 4. Start the Application\n```bash\n# Start the server\n./start.sh\n```\n\nYou'll see:\n```\n🚀 Starting VoiceScript Collector...\n📊 Dashboard will be available at: http://localhost:8000\n👤 Demo Accounts:\n   Provider: provider@demo.com / demo123\n   Reviewer: reviewer@demo.com / demo123\n   Admin:    admin@demo.com / demo123\n\nPress Ctrl+C to stop the server\n```\n\n### 5. Access the Application\n1. Open your web browser\n2. Go to: http://localhost:8000\n3. Login with any demo account\n4. Start using the platform!\n\n## Network Access (Optional)\n\n### Access from Other Devices\nTo access from other devices on your network:\n\n1. Find your Mac Mini's IP address:\n   ```bash\n   ifconfig | grep \"inet \" | grep -v 127.0.0.1\n   ```\n\n2. Edit `app.py` to bind to all interfaces:\n   ```python\n   app.run(host='0.0.0.0', port=8000, debug=True)\n   ```\n\n3. Access from other devices using: `http://[MAC_MINI_IP]:8000`\n\n### Firewall Configuration\nIf needed, allow port 8000 through macOS firewall:\n1. System Preferences → Security & Privacy → Firewall\n2. Click \"Firewall Options\"\n3. Add Python or your application to allowed apps\n\n## Production Setup\n\n### Run as Background Service\nFor always-on operation:\n\n1. **Using screen (simple)**:\n   ```bash\n   screen -S voicescript\n   ./start.sh\n   # Press Ctrl+A, then D to detach\n   # Reconnect with: screen -r voicescript\n   ```\n\n2. **Using launchd (macOS service)**:\n   Create `/Library/LaunchDaemons/com.voicescript.collector.plist`:\n   ```xml\n   <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n   <!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n   <plist version=\"1.0\">\n   <dict>\n       <key>Label</key>\n       <string>com.voicescript.collector</string>\n       <key>ProgramArguments</key>\n       <array>\n           <string>/path/to/your/project/start.sh</string>\n       </array>\n       <key>RunAtLoad</key>\n       <true/>\n       <key>KeepAlive</key>\n       <true/>\n   </dict>\n   </plist>\n   ```\n\n   Then:\n   ```bash\n   sudo launchctl load /Library/LaunchDaemons/com.voicescript.collector.plist\n   ```\n\n## Data Management\n\n### Backup Important Data\n```bash\n# Backup database\ncp voicescript.db voicescript.db.backup\n\n# Backup audio files\ntar -czf uploads_backup.tar.gz uploads/\n\n# Backup configuration\ncp .env .env.backup\n```\n\n### Reset/Clean Install\n```bash\n# Stop the application (Ctrl+C)\n# Remove virtual environment\nrm -rf venv/\n# Remove database\nrm voicescript.db\n# Remove uploads\nrm -rf uploads/\n# Run deployment again\n./deploy.sh\n```\n\n## Monitoring & Maintenance\n\n### Check Application Status\n```bash\n# If running in background, check process\nps aux | grep python | grep app.py\n\n# Check log files (if using systemd/launchd)\ntail -f /var/log/system.log | grep voicescript\n```\n\n### Update Application\n```bash\n# Stop current application\n# Replace files with new version\n# Run deployment script again\n./deploy.sh\n./start.sh\n```\n\n### Disk Space Management\nAudio files will accumulate over time:\n```bash\n# Check uploads directory size\ndu -sh uploads/\n\n# Clean old files if needed (be careful!)\nfind uploads/ -name \"*.mp4\" -mtime +30 -delete\n```\n\n## Troubleshooting Mac-Specific Issues\n\n### Python Issues\n```bash\n# If python3 command not found\nbrew install python3\n\n# If pip issues\npython3 -m ensurepip --upgrade\n```\n\n### Permission Issues\n```bash\n# Fix permissions\nchmod -R 755 .\nchmod +x deploy.sh start.sh\n```\n\n### Port Issues\n```bash\n# Check what's using port 8000\nlsof -i :8000\n\n# Kill process if needed\nkill -9 [PID]\n```\n\n### Browser Microphone Issues\n- Safari: Preferences → Websites → Microphone → Allow\n- Chrome: Settings → Privacy and Security → Site Settings → Microphone\n- Ensure using `http://localhost:8000` not `127.0.0.1:8000`\n\n## Performance on Mac Mini\n\n### Optimizations\n- Mac Mini can easily handle 10+ concurrent users\n- SQLite is sufficient for up to 1000 users\n- Audio files: ~300KB per minute of recording\n- RAM usage: ~50MB for the application\n\n### Scaling Considerations\n- For 100+ concurrent users, consider PostgreSQL\n- For heavy audio processing, monitor disk I/O\n- Use SSD storage for better performance","size_bytes":4970},"README.md":{"content":"# VoiceScript Collector - Flask Application\n\n## Overview\n\nVoiceScript Collector is a web-based platform built with Flask for collecting high-quality voice and text data for NLP training. The system supports data providers, quality reviewers, and administrators with browser-based audio recording, multi-stage approval workflow, and flexible billing.\n\n## Features\n\n### Core Functionality\n- **Multi-role Authentication**: Provider, Reviewer, and Admin roles\n- **Audio Recording**: Browser-based voice recording with MediaRecorder API\n- **Language Management**: Support for multiple languages with custom pricing\n- **Quality Review System**: Multi-stage approval workflow with reviewer feedback\n- **Billing System**: Automated payment calculation based on word count and duration\n- **Analytics Dashboard**: Role-specific dashboards with comprehensive statistics\n\n### Technical Architecture\n- **Backend**: Flask (Python 3.8+)\n- **Database**: SQLite (development) / PostgreSQL (production)\n- **Frontend**: Server-side rendered HTML with Tailwind CSS\n- **Authentication**: Session-based with secure cookies\n- **File Storage**: Local filesystem with secure upload handling\n\n## Quick Start\n\n### Prerequisites\n- Python 3.8 or higher\n- 50MB free disk space for audio files\n- Modern web browser with microphone access\n\n### Automated Deployment\n1. Download or extract the project files to your desired location\n2. Open terminal in the project directory\n3. Run the deployment script:\n   ```bash\n   chmod +x deploy.sh\n   ./deploy.sh\n   ```\n4. Start the application:\n   ```bash\n   ./start.sh\n   ```\n\nThe application will be available at: http://localhost:8000\n\n### Demo Accounts\nAll demo accounts use password: `demo123`\n\n#### Core Demo Accounts\n- **Admin**: `admin@demo.com` - Platform administrator  \n- **Provider**: `provider@demo.com` - Standard data provider\n- **Reviewer**: `reviewer@demo.com` - Quality reviewer\n\n#### Additional Example Users\n- **John Smith**: `john.provider@example.com` - Teen male provider\n- **Maria Rodriguez**: `maria.provider@example.com` - Elderly female provider\n\n#### Age & Gender Demo Users\n**Male Providers:**\n- **Alex Johnson**: `male.child@demo.com` - Child (0-12)\n- **Ryan Davis**: `male.teen@demo.com` - Teen (13-19)  \n- **Michael Brown**: `male.adult@demo.com` - Adult (20-59)\n- **Robert Wilson**: `male.elderly@demo.com` - Elderly (60+)\n\n**Female Providers:**\n- **Emma Taylor**: `female.child@demo.com` - Child (0-12)\n- **Sophie Anderson**: `female.teen@demo.com` - Teen (13-19)\n- **Jessica Martinez**: `female.adult@demo.com` - Adult (20-59)\n- **Margaret Garcia**: `female.elderly@demo.com` - Elderly (60+)\n\n## Manual Installation\n\nIf you prefer manual setup:\n\n### 1. Environment Setup\n```bash\n# Create virtual environment\npython3 -m venv venv\nsource venv/bin/activate\n\n# Install dependencies\npip install flask flask-sqlalchemy python-dotenv werkzeug gunicorn\n\n# Create uploads directory\nmkdir -p uploads\nchmod 755 uploads\n```\n\n### 2. Configuration\nCreate `.env` file (or copy from `.env.example`):\n```bash\nFLASK_ENV=production\nFLASK_DEBUG=False\nSECRET_KEY=your-secure-random-secret-key\nDATABASE_URL=sqlite:///voicescript.db\nUPLOAD_FOLDER=uploads\nMAX_CONTENT_LENGTH=52428800\n```\n\n### 3. Database Initialization\n```bash\npython3 -c \"\nfrom app import app, db, create_demo_data\nwith app.app_context():\n    db.create_all()\n    create_demo_data()\n    print('Database initialized successfully')\n\"\n```\n\n### 4. Start Application\n```bash\npython app.py\n```\n\n## Production Deployment\n\n### Using Gunicorn\n```bash\ngunicorn --bind 0.0.0.0:8000 --workers 4 app:app\n```\n\n### Background Service (Linux)\nThe deployment script creates a systemd service file:\n```bash\nsudo cp voicescript-collector.service /etc/systemd/system/\nsudo systemctl enable voicescript-collector\nsudo systemctl start voicescript-collector\n```\n\n### Background Service (macOS)\nUse screen for simple background operation:\n```bash\nscreen -S voicescript\n./start.sh\n# Press Ctrl+A, then D to detach\n# Reconnect with: screen -r voicescript\n```\n\n## Application Usage\n\n### For Data Providers\n1. Login with provider account\n2. Browse available recording scripts\n3. Record audio using browser microphone\n4. Submit recordings with optional text notes\n5. Track earnings and submission history\n\n### For Quality Reviewers\n1. Login with reviewer account\n2. Access pending submissions queue\n3. Review audio quality and content\n4. Approve, reject, or request corrections\n5. Track review earnings\n\n### For Administrators\n1. Login with admin account\n2. Manage languages and pricing rates\n3. Create and edit recording scripts\n4. View platform analytics and user statistics\n5. Monitor system performance\n\n## File Structure\n\n```\nvoicescript-collector/\n├── app.py                 # Main Flask application\n├── templates/            # HTML templates\n│   ├── base.html         # Base template with navigation\n│   ├── landing.html      # Landing page\n│   ├── dashboard_*.html  # Role-specific dashboards\n│   ├── record.html       # Audio recording interface\n│   └── admin_*.html      # Admin management pages\n├── uploads/              # Audio file storage\n├── voicescript.db        # SQLite database (created automatically)\n├── deploy.sh             # Automated deployment script\n├── start.sh              # Application startup script\n├── .env                  # Environment configuration\n└── *.md                  # Documentation files\n```\n\n## Security Features\n\n- **Session Management**: Secure HTTP-only cookies with CSRF protection\n- **File Upload Security**: Type validation and size limits (50MB)\n- **Role-Based Access**: Strict permission controls for different user types\n- **Input Sanitization**: Protection against common web vulnerabilities\n- **Database Security**: SQLAlchemy ORM prevents SQL injection\n\n## Network Configuration\n\n### Local Network Access\nTo access from other devices on your network:\n\n1. Find your machine's IP address:\n   ```bash\n   # Linux/macOS\n   ifconfig | grep \"inet \" | grep -v 127.0.0.1\n   \n   # Windows\n   ipconfig | findstr \"IPv4\"\n   ```\n\n2. The application binds to `0.0.0.0:8000` by default, so it's accessible from:\n   - Local: `http://localhost:8000`\n   - Network: `http://[YOUR_IP]:8000`\n\n### Port Configuration\nThe application uses port 8000 by default (avoiding macOS AirPlay conflicts). To change:\n- Set `PORT=9000` in your `.env` file\n- Or modify `app.py` directly\n\n## Troubleshooting\n\n### Common Issues\n\n**Microphone not working**\n- Ensure browser has microphone permissions\n- Use Chrome or Firefox (Safari may have limitations)\n- Check that you're using `http://localhost:8000` not `127.0.0.1:8000`\n\n**Database errors**\n- Delete `voicescript.db` and run deployment script again\n- Check file permissions in project directory\n\n**Port already in use**\n- Change port in `.env` file: `PORT=9000`\n- Or kill existing process: `lsof -ti:8000 | xargs kill -9`\n\n**Audio files not playing**\n- Check uploads directory permissions: `chmod -R 755 uploads/`\n- Verify audio files exist in uploads directory\n\n### Performance Optimization\n- Use Gunicorn with multiple workers for production\n- Monitor disk space for audio file accumulation\n- Consider PostgreSQL for high-traffic deployments\n- Set up nginx reverse proxy for better static file serving\n\n## Backup and Maintenance\n\n### Important Data\n```bash\n# Backup database\ncp voicescript.db voicescript.db.backup\n\n# Backup audio files\ntar -czf uploads_backup.tar.gz uploads/\n\n# Backup configuration\ncp .env .env.backup\n```\n\n### Clean Installation\n```bash\n# Stop application (Ctrl+C)\nrm -rf venv/ voicescript.db uploads/\n./deploy.sh  # Redeploy from scratch\n```\n\n## System Requirements\n\n### Minimum Requirements\n- CPU: 1 core, 1GHz\n- RAM: 512MB available\n- Storage: 1GB free space\n- Network: Standard internet connection\n\n### Recommended for Production\n- CPU: 2+ cores\n- RAM: 2GB+ available\n- Storage: 10GB+ free space (for audio files)\n- SSD storage for better performance\n\n### Browser Compatibility\n- Chrome 60+ (recommended)\n- Firefox 55+\n- Safari 12+ (limited microphone support)\n- Edge 79+\n\n## Development\n\n### Adding New Features\n1. Modify `app.py` for backend logic\n2. Update templates in `templates/` directory\n3. Add database models using SQLAlchemy\n4. Test with demo accounts\n5. Update documentation\n\n### Database Schema Changes\nThe application uses SQLAlchemy with automatic table creation. Schema changes are applied automatically when the application starts.\n\n## License\n\nMIT License - see LICENSE file for details.\n\n## Support\n\nFor issues or questions:\n1. Check this README and deployment guides\n2. Review console logs for error messages\n3. Verify all prerequisites are installed\n4. Try rerunning the deployment script\n\n---\n\n**Note**: This is a Flask-based Python application with server-side rendering. No Node.js, npm, or React components are required.","size_bytes":8891},"app.py":{"content":"import os\nimport logging\nimport click\nfrom flask import Flask, render_template, request, redirect, url_for, flash, session, jsonify, send_from_directory, send_file\nfrom flask_sqlalchemy import SQLAlchemy\nfrom werkzeug.security import generate_password_hash, check_password_hash\nfrom werkzeug.utils import secure_filename\nfrom authlib.integrations.flask_client import OAuth\nimport uuid\nfrom datetime import datetime\nimport secrets\nimport functools\nfrom sqlalchemy import text\nimport csv\nimport io\nimport zipfile\n\napp = Flask(__name__)\n\n# Production-ready configuration\nis_production = os.environ.get('FLASK_ENV') == 'production'\n\n# Secret key - fail fast in production if not set\nif is_production and not os.environ.get('SECRET_KEY'):\n    raise RuntimeError(\"SECRET_KEY environment variable must be set in production\")\napp.config['SECRET_KEY'] = os.environ.get('SECRET_KEY', 'dev-secret-key-change-in-production')\n\n# Database configuration - PostgreSQL first, SQLite only for local development\ndatabase_url = os.environ.get('DATABASE_URL')\nif not database_url:\n    if is_production:\n        raise RuntimeError(\"DATABASE_URL environment variable must be set in production\")\n    else:\n        # Local development fallback to SQLite\n        database_url = 'sqlite:///voicescript.db'\n        app.logger.info(\"⚠️  Using SQLite for local development - use PostgreSQL for production\")\n\napp.config['SQLALCHEMY_DATABASE_URI'] = database_url\napp.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n\n# Production security settings\n# Only use secure cookies if explicitly running on HTTPS (not just production mode)\nuse_https = os.environ.get('USE_HTTPS', 'false').lower() == 'true'\napp.config['PREFERRED_URL_SCHEME'] = 'https' if use_https else 'http'\napp.config['SESSION_COOKIE_SECURE'] = use_https  # Only secure on HTTPS\napp.config['SESSION_COOKIE_HTTPONLY'] = True\napp.config['WTF_CSRF_ENABLED'] = is_production\n\n# Enhanced database configuration for PostgreSQL connection stability\napp.config['SQLALCHEMY_ENGINE_OPTIONS'] = {\n    'pool_pre_ping': True,      # Test connections before use to catch dropped connections\n    'pool_recycle': 300,        # Recycle connections every 5 minutes\n    'pool_timeout': 20,         # Timeout for getting connection from pool\n    'pool_size': 5,             # Number of connections to keep open\n    'max_overflow': 10,         # Additional connections if pool is full\n    'echo': False               # Set to True for SQL debugging if needed\n}\napp.config['UPLOAD_FOLDER'] = 'uploads'\n\n# Session configuration - production vs development\nif is_production:\n    # Production session settings\n    app.config['SESSION_COOKIE_NAME'] = 'voicescript_session'\n    app.config['SESSION_COOKIE_SAMESITE'] = 'Lax'\n    app.config['SESSION_COOKIE_DOMAIN'] = None\n    app.config['SESSION_COOKIE_PATH'] = '/'\n    app.config['PERMANENT_SESSION_LIFETIME'] = 3600  # 1 hour\nelse:\n    # Development session settings for Replit environment\n    app.config['SESSION_COOKIE_NAME'] = 'voicescript_session'\n    app.config['SESSION_COOKIE_HTTPONLY'] = False\n    app.config['SESSION_COOKIE_SECURE'] = False\n    app.config['SESSION_COOKIE_SAMESITE'] = 'None'\n    app.config['SESSION_COOKIE_DOMAIN'] = None\n    app.config['SESSION_COOKIE_PATH'] = '/'\n    app.config['PERMANENT_SESSION_LIFETIME'] = 3600\n\n# Google OAuth Configuration\napp.config['GOOGLE_CLIENT_ID'] = os.environ.get('GOOGLE_CLIENT_ID')\napp.config['GOOGLE_CLIENT_SECRET'] = os.environ.get('GOOGLE_CLIENT_SECRET')\n\n# Ensure required directories exist FIRST (before logging)\nos.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)\nif is_production:\n    os.makedirs('logs', exist_ok=True)\n\n# Production logging configuration\nif is_production:\n    logging.basicConfig(\n        level=logging.INFO,\n        format='%(asctime)s %(levelname)s: %(message)s [in %(pathname)s:%(lineno)d]',\n        handlers=[\n            logging.FileHandler('logs/app.log'),\n            logging.StreamHandler()\n        ]\n    )\n    app.logger.setLevel(logging.INFO)\n    app.logger.info('VoiceScript Collector startup - Production Mode')\nelse:\n    logging.basicConfig(level=logging.DEBUG)\n    app.logger.info('VoiceScript Collector startup - Development Mode')\n\ndb = SQLAlchemy(app)\noauth = OAuth(app)\n\n# Configure Google OAuth only if credentials are available\ngoogle = None\nif app.config['GOOGLE_CLIENT_ID'] and app.config['GOOGLE_CLIENT_SECRET']:\n    google = oauth.register(\n        name='google',\n        client_id=app.config['GOOGLE_CLIENT_ID'],\n        client_secret=app.config['GOOGLE_CLIENT_SECRET'],\n        server_metadata_url='https://accounts.google.com/.well-known/openid_configuration',\n        client_kwargs={\n            'scope': 'openid email profile'\n        }\n    )\n\n# Database Models\nclass User(db.Model):\n    __tablename__ = 'users'\n    \n    id = db.Column(db.Integer, primary_key=True)\n    email = db.Column(db.String(120), unique=True, nullable=False)\n    password_hash = db.Column(db.String(255), nullable=True)  # Made nullable for OAuth users\n    first_name = db.Column(db.String(50), nullable=False)\n    last_name = db.Column(db.String(50), nullable=False)\n    role = db.Column(db.String(20), default='provider')\n    gender = db.Column(db.String(20), nullable=True)  # male, female, non-binary, prefer-not-to-say\n    age_group = db.Column(db.String(20), nullable=True)  # Child (0–12), Teen (13–19), Adult (20–59), Elderly (60+)\n    google_id = db.Column(db.String(100), unique=True, nullable=True)  # Google OAuth ID\n    profile_picture = db.Column(db.String(255), nullable=True)  # Profile picture URL\n    auth_provider = db.Column(db.String(20), default='local')  # 'local' or 'google'\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    def set_password(self, password):\n        self.password_hash = generate_password_hash(password)\n    \n    def check_password(self, password):\n        if not self.password_hash:\n            return False\n        return check_password_hash(self.password_hash, password)\n\nclass Script(db.Model):\n    __tablename__ = 'scripts'\n    id = db.Column(db.Integer, primary_key=True)\n    title = db.Column(db.String(255))\n    content = db.Column(db.Text, nullable=False)\n    category = db.Column(db.String(100))\n    difficulty = db.Column(db.String(50))\n    target_duration = db.Column(db.Integer)  # in seconds\n    language = db.Column(db.String(10), default='en')\n    is_active = db.Column(db.Boolean, default=True)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n\nclass ScriptVariantRequirement(db.Model):\n    __tablename__ = 'script_variant_requirements'\n    id = db.Column(db.Integer, primary_key=True)\n    script_id = db.Column(db.Integer, db.ForeignKey('scripts.id'), nullable=False)\n    gender = db.Column(db.String(20), nullable=False)  # male, female, non-binary, prefer-not-to-say\n    age_group = db.Column(db.String(20), nullable=False)  # Child (0-12), Teen (13-19), Adult (20-59), Elderly (60+)\n    target_total = db.Column(db.Integer, default=1, nullable=False)  # How many recordings needed for this variant\n    enabled = db.Column(db.Boolean, default=True, nullable=False)  # Whether this variant is actively being collected\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    script = db.relationship('Script', backref='variant_requirements')\n    \n    # Ensure unique combination of script + gender + age_group\n    __table_args__ = (db.UniqueConstraint('script_id', 'gender', 'age_group', name='unique_script_variant'),)\n\nclass Submission(db.Model):\n    __tablename__ = 'submissions'\n    id = db.Column(db.Integer, primary_key=True)\n    user_id = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=True)  # Nullable for field-collected submissions\n    script_id = db.Column(db.Integer, db.ForeignKey('scripts.id'), nullable=False)  # Required for script-based recordings\n    text_content = db.Column(db.Text)  # Optional text response\n    audio_filename = db.Column(db.String(255), nullable=False)  # Audio required for script recordings\n    status = db.Column(db.String(20), default='pending')\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    reviewed_at = db.Column(db.DateTime)\n    reviewed_by = db.Column(db.Integer, db.ForeignKey('users.id'))\n    review_notes = db.Column(db.Text)\n    quality_score = db.Column(db.Integer)\n    word_count = db.Column(db.Integer, default=0)\n    duration = db.Column(db.Float, default=0.0)  # Changed from duration_seconds for consistency\n    # Demographic snapshot columns for variant tracking\n    provider_gender = db.Column(db.String(20), nullable=True)  # Snapshot of user's gender at submission time\n    provider_age_group = db.Column(db.String(20), nullable=True)  # Snapshot of user's age_group at submission time\n    \n    # Field collection metadata (when admin collects on behalf of anonymous speaker)\n    collected_by_admin_id = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=True)  # Admin who collected this\n    speaker_name = db.Column(db.String(100), nullable=True)  # Anonymous speaker's name (optional)\n    speaker_location = db.Column(db.String(255), nullable=True)  # Where recording was collected\n    is_field_collection = db.Column(db.Boolean, default=False)  # Flag to identify field-collected submissions\n    \n    user = db.relationship('User', foreign_keys=[user_id])\n    script = db.relationship('Script')\n    reviewer = db.relationship('User', foreign_keys=[reviewed_by])\n    collected_by_admin = db.relationship('User', foreign_keys=[collected_by_admin_id])\n\nclass BillingRecord(db.Model):\n    __tablename__ = 'billing_records'\n    id = db.Column(db.Integer, primary_key=True)\n    user_id = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=False)\n    submission_id = db.Column(db.Integer, db.ForeignKey('submissions.id'), nullable=True)\n    amount = db.Column(db.Float, nullable=False)\n    rate_per_word = db.Column(db.Float)  # For provider payments\n    rate_per_submission = db.Column(db.Float)  # For reviewer payments\n    billing_type = db.Column(db.String(20), nullable=False)  # 'provider' or 'reviewer'\n    language_code = db.Column(db.String(10), nullable=False)\n    word_count = db.Column(db.Integer, default=0)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    user = db.relationship('User')\n    submission = db.relationship('Submission')\n\nclass Language(db.Model):\n    __tablename__ = 'languages'\n    id = db.Column(db.Integer, primary_key=True)\n    code = db.Column(db.String(10), unique=True, nullable=False)\n    name = db.Column(db.String(100), nullable=False)\n    native_name = db.Column(db.String(100))\n    is_active = db.Column(db.Boolean, default=True)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n\nclass PricingRate(db.Model):\n    __tablename__ = 'pricing_rates'\n    id = db.Column(db.Integer, primary_key=True)\n    language_code = db.Column(db.String(10), db.ForeignKey('languages.code'), nullable=False)\n    provider_rate_per_word = db.Column(db.Float, default=0.01)  # Rate paid to providers\n    reviewer_rate_per_submission = db.Column(db.Float, default=2.00)  # Fixed rate per review\n    currency = db.Column(db.String(10), default='USD')  # Currency code (USD, EUR, BDT, etc.)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n    \n    language = db.relationship('Language')\n\nclass AppSettings(db.Model):\n    __tablename__ = 'app_settings'\n    id = db.Column(db.Integer, primary_key=True)\n    setting_key = db.Column(db.String(50), unique=True, nullable=False)\n    setting_value = db.Column(db.String(255), nullable=False)\n    description = db.Column(db.String(255))\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n\ndef get_app_setting(key, default_value=''):\n    \"\"\"Get application setting value with fallback to default\"\"\"\n    setting = AppSettings.query.filter_by(setting_key=key).first()\n    return setting.setting_value if setting else default_value\n\ndef get_show_earnings():\n    \"\"\"Get earnings visibility setting as boolean\"\"\"\n    setting_value = get_app_setting('show_earnings', 'true')\n    return setting_value.lower() == 'true'\n\ndef set_app_setting(key, value, description=''):\n    \"\"\"Set application setting value\"\"\"\n    setting = AppSettings.query.filter_by(setting_key=key).first()\n    if setting:\n        setting.setting_value = value\n        setting.updated_at = datetime.utcnow()\n    else:\n        setting = AppSettings(\n            setting_key=key,\n            setting_value=value,\n            description=description\n        )\n        db.session.add(setting)\n    db.session.commit()\n\n@app.context_processor\ndef inject_common_variables():\n    \"\"\"Make common variables available to all templates\"\"\"\n    show_earnings_setting = get_show_earnings()\n    return dict(global_show_earnings=show_earnings_setting)\n\ndef require_auth(f):\n    @functools.wraps(f)\n    def decorated_function(*args, **kwargs):\n        # Primary session authentication\n        if 'user_id' in session:\n            return f(*args, **kwargs)\n        \n        # Fallback authentication ONLY in development mode (SECURITY: disabled in production)\n        enable_fallback = os.environ.get('ENABLE_WEBVIEW_FALLBACK', 'false').lower() == 'true'\n        \n        if enable_fallback and not is_production:\n            # Fallback authentication for Replit webview environment (DEV ONLY)\n            fallback_cookies = [\n                request.cookies.get('voicescript_session'),\n                request.cookies.get('replit_auth_backup'),\n                request.cookies.get('session_backup')\n            ]\n            \n            for cookie_auth in fallback_cookies:\n                if cookie_auth:\n                    try:\n                        user_id, user_role, user_name = cookie_auth.split(':', 2)\n                        session.permanent = True\n                        session['user_id'] = int(user_id)\n                        session['user_role'] = user_role\n                        session['user_name'] = user_name\n                        session.modified = True\n                        app.logger.warning(f\"Fallback auth used: {user_role} (DEV ONLY)\")\n                        return f(*args, **kwargs)\n                    except (ValueError, IndexError):\n                        continue\n            \n            # Last resort: Check URL token for webview authentication (DEV ONLY)\n            auth_token = request.args.get('auth_token')\n            if auth_token:\n                try:\n                    user_id, user_role, user_name = auth_token.split(':', 2)\n                    session.permanent = True\n                    session['user_id'] = int(user_id)\n                    session['user_role'] = user_role\n                    session['user_name'] = user_name\n                    session.modified = True\n                    app.logger.warning(f\"Token auth used: {user_role} (DEV ONLY)\")\n                    return f(*args, **kwargs)\n                except (ValueError, IndexError):\n                    pass\n        \n        flash('Please log in to access this page.', 'error')\n        return redirect(url_for('login'))\n    return decorated_function\n\ndef require_role(required_roles):\n    def decorator(f):\n        @functools.wraps(f)\n        def decorated_function(*args, **kwargs):\n            if 'user_role' not in session or session['user_role'] not in required_roles:\n                flash('Access denied. Insufficient privileges.', 'error')\n                return redirect(url_for('index'))\n            return f(*args, **kwargs)\n        return decorated_function\n    return decorator\n\n# Routes\n@app.route('/')\ndef index():\n    if 'user_id' not in session:\n        return render_template('landing.html')\n\n    user_role = session['user_role']\n    if user_role == 'admin':\n        return redirect(url_for('admin_dashboard'))\n    elif user_role == 'reviewer':\n        return redirect(url_for('reviewer_dashboard'))\n    else:\n        return redirect(url_for('provider_dashboard'))\n\n@app.route('/login', methods=['GET', 'POST'])\ndef login():\n    # If already logged in, redirect to dashboard\n    if 'user_id' in session:\n        user_role = session.get('user_role', 'provider')\n        if user_role == 'admin':\n            return redirect(url_for('admin_dashboard'))\n        elif user_role == 'reviewer':\n            return redirect(url_for('reviewer_dashboard'))\n        else:\n            return redirect(url_for('provider_dashboard'))\n    \n    # Handle demo login via URL parameter\n    demo_role = request.args.get('demo')\n    if demo_role in ['provider', 'reviewer', 'admin']:\n        email = f\"{demo_role}@demo.com\"\n        user = User.query.filter_by(email=email).first()\n        if user:\n            # Store user info in the session with explicit permanence\n            session.clear()  # Clear any old session data\n            session.permanent = True\n            session['user_id'] = user.id\n            session['user_role'] = user.role\n            session['user_name'] = f\"{user.first_name} {user.last_name}\"\n            session.modified = True\n            \n            app.logger.info(f\"Demo login: {email} -> {user.role} (ID: {user.id})\")\n            flash('Login successful!', 'success')\n\n            # Create response and redirect to appropriate dashboard\n            if user.role == 'admin':\n                response = redirect(url_for('admin_dashboard'))\n            elif user.role == 'reviewer':\n                response = redirect(url_for('reviewer_dashboard'))\n            else:\n                response = redirect(url_for('provider_dashboard'))\n            \n            # Only set fallback cookie in development mode with explicit flag (SECURITY)\n            enable_fallback = os.environ.get('ENABLE_WEBVIEW_FALLBACK', 'false').lower() == 'true'\n            if enable_fallback and not is_production:\n                response.set_cookie('voicescript_session', \n                                  value=f\"{user.id}:{user.role}:{user.first_name} {user.last_name}\",\n                                  max_age=3600,\n                                  secure=False,\n                                  httponly=False,\n                                  samesite='Lax',\n                                  path='/')\n            return response\n\n    if request.method == 'POST':\n        email = request.form['email']\n        password = request.form['password']\n\n        user = User.query.filter_by(email=email).first()\n        if user and user.check_password(password):\n            # Store user info in the session with explicit permanence\n            session.clear()  # Clear any old session data\n            session.permanent = True\n            session['user_id'] = user.id\n            session['user_role'] = user.role\n            session['user_name'] = f\"{user.first_name} {user.last_name}\"\n            session.modified = True\n            \n            app.logger.info(f\"User login: {email} -> {user.role} (ID: {user.id})\")\n            flash('Login successful!', 'success')\n\n            # Create response and redirect to appropriate dashboard\n            if user.role == 'admin':\n                response = redirect(url_for('admin_dashboard'))\n            elif user.role == 'reviewer':\n                response = redirect(url_for('reviewer_dashboard'))\n            else:\n                response = redirect(url_for('provider_dashboard'))\n            \n            # Only set fallback cookie in development mode with explicit flag (SECURITY)\n            enable_fallback = os.environ.get('ENABLE_WEBVIEW_FALLBACK', 'false').lower() == 'true'\n            if enable_fallback and not is_production:\n                response.set_cookie('voicescript_session', \n                                  value=f\"{user.id}:{user.role}:{user.first_name} {user.last_name}\",\n                                  max_age=3600,\n                                  secure=False,\n                                  httponly=False,\n                                  samesite='Lax',\n                                  path='/')\n            return response\n        else:\n            flash('Invalid email or password', 'error')\n\n    return render_template('login.html')\n\n# Google OAuth routes\n@app.route('/login/google')\ndef google_login():\n    \"\"\"Initiate Google OAuth login\"\"\"\n    if not google or not app.config['GOOGLE_CLIENT_ID']:\n        flash('Google authentication is not configured. Please use email/password login.', 'error')\n        return redirect(url_for('login'))\n    \n    redirect_uri = url_for('google_callback', _external=True)\n    return google.authorize_redirect(redirect_uri)\n\n@app.route('/callback/google')\ndef google_callback():\n    \"\"\"Handle Google OAuth callback\"\"\"\n    global logged_in_user\n    \n    if not google or not app.config['GOOGLE_CLIENT_ID']:\n        flash('Google authentication is not configured.', 'error')\n        return redirect(url_for('login'))\n    \n    try:\n        token = google.authorize_access_token()\n        user_info = token.get('userinfo')\n        \n        if user_info:\n            # Check if user exists\n            user = User.query.filter_by(google_id=user_info['sub']).first()\n            \n            if not user:\n                # Check if user with same email exists (local account)\n                existing_user = User.query.filter_by(email=user_info['email']).first()\n                if existing_user:\n                    # Link Google account to existing local account\n                    existing_user.google_id = user_info['sub']\n                    existing_user.profile_picture = user_info.get('picture')\n                    existing_user.auth_provider = 'google'\n                    db.session.commit()\n                    user = existing_user\n                else:\n                    # Create new user\n                    user = User(\n                        email=user_info['email'],\n                        first_name=user_info.get('given_name', ''),\n                        last_name=user_info.get('family_name', ''),\n                        google_id=user_info['sub'],\n                        profile_picture=user_info.get('picture'),\n                        auth_provider='google',\n                        role='provider'  # Default role for new Google users\n                    )\n                    db.session.add(user)\n                    db.session.commit()\n            \n            # Store user info in the session with explicit permanence\n            session.permanent = True\n            session['user_id'] = user.id\n            session['user_role'] = user.role\n            session['user_name'] = f\"{user.first_name} {user.last_name}\"\n            flash('Google login successful!', 'success')\n\n            # Create response and redirect to appropriate dashboard\n            if user.role == 'admin':\n                response = redirect(url_for('admin_dashboard'))\n            elif user.role == 'reviewer':\n                response = redirect(url_for('reviewer_dashboard'))\n            else:\n                response = redirect(url_for('provider_dashboard'))\n            \n            # Only set fallback cookie in development mode with explicit flag (SECURITY)\n            enable_fallback = os.environ.get('ENABLE_WEBVIEW_FALLBACK', 'false').lower() == 'true'\n            if enable_fallback and not is_production:\n                response.set_cookie('voicescript_session', \n                                  value=f\"{user.id}:{user.role}:{user.first_name} {user.last_name}\",\n                                  max_age=3600,\n                                  secure=False,\n                                  httponly=False,\n                                  samesite='Lax',\n                                  path='/')\n            return response\n        else:\n            flash('Failed to get user information from Google.', 'error')\n            return redirect(url_for('login'))\n                \n    except Exception as e:\n        flash(f'Google authentication failed: {str(e)}', 'error')\n        return redirect(url_for('login'))\n\n@app.route('/logout')\ndef logout():\n    session.clear()\n    flash('You have been logged out successfully.', 'success')\n    return redirect(url_for('index'))\n\n# Webview authentication bypass route\n@app.route('/webview_login')\ndef webview_login():\n    \"\"\"Direct authentication for Replit webview environment\"\"\"\n    # If already logged in, redirect to dashboard\n    if 'user_id' in session:\n        user_role = session.get('user_role', 'provider')\n        if user_role == 'admin':\n            return redirect(url_for('admin_dashboard'))\n        elif user_role == 'reviewer':\n            return redirect(url_for('reviewer_dashboard'))\n        else:\n            return redirect(url_for('provider_dashboard'))\n    \n    # Default to provider demo account for webview\n    email = request.args.get('email', 'provider@demo.com')\n    user = User.query.filter_by(email=email).first()\n    \n    if user:\n        # Store user info in the session\n        session.clear()  # Clear any old session data\n        session.permanent = True\n        session['user_id'] = user.id\n        session['user_role'] = user.role\n        session['user_name'] = f\"{user.first_name} {user.last_name}\"\n        session.modified = True\n        \n        app.logger.info(f\"Webview login: {email} -> {user.role} (ID: {user.id})\")\n        \n        # Redirect to appropriate dashboard\n        if user.role == 'admin':\n            return redirect(url_for('admin_dashboard'))\n        elif user.role == 'reviewer':\n            return redirect(url_for('reviewer_dashboard'))\n        else:\n            return redirect(url_for('provider_dashboard'))\n    else:\n        flash('Authentication failed', 'error')\n        return redirect(url_for('login'))\n\n\n\n@app.route('/dashboard/provider')\n@require_auth  \ndef provider_dashboard():\n    user = User.query.get(session['user_id'])\n    if not user:\n        flash('User not found', 'error')\n        return redirect(url_for('login'))\n        \n    submissions = Submission.query.filter_by(user_id=user.id).order_by(Submission.created_at.desc()).limit(10).all()\n    scripts = Script.query.filter_by(is_active=True).all()\n    \n    # Calculate user stats\n    total_submissions = Submission.query.filter_by(user_id=user.id).count()\n    approved_submissions = Submission.query.filter_by(user_id=user.id, status='approved').count()\n    pending_submissions = Submission.query.filter_by(user_id=user.id, status='pending').count()\n    \n    # Calculate earnings\n    earnings = db.session.query(db.func.sum(BillingRecord.amount)).filter_by(user_id=user.id).scalar() or 0\n    \n    stats = {\n        'total_submissions': total_submissions,\n        'approved': approved_submissions,\n        'pending': pending_submissions,\n        'rejected': total_submissions - approved_submissions - pending_submissions,\n        'earnings': round(earnings, 2)\n    }\n    \n    return render_template('dashboard_provider.html', \n                         user=user, \n                         submissions=submissions, \n                         scripts=scripts, \n                         stats=stats)\n\n@app.route('/dashboard/reviewer')\n@require_role(['reviewer', 'admin'])\ndef reviewer_dashboard():\n    pending_submissions = Submission.query.filter_by(status='pending').order_by(Submission.created_at.desc()).all()\n    recent_reviews = Submission.query.filter(\n        Submission.reviewed_by == session['user_id']\n    ).order_by(Submission.reviewed_at.desc()).limit(10).all()\n    \n    return render_template('dashboard_reviewer.html', \n                         pending_submissions=pending_submissions, \n                         recent_reviews=recent_reviews)\n\n# Admin convenience redirect\n@app.route('/admin')\n@require_role(['admin'])\ndef admin_redirect():\n    \"\"\"Redirect /admin to the main admin dashboard\"\"\"\n    return redirect(url_for('admin_dashboard'))\n\n@app.route('/dashboard/admin')\n@require_role(['admin'])\ndef admin_dashboard():\n    # Calculate platform stats\n    stats = {\n        'total_users': User.query.count(),\n        'total_submissions': Submission.query.count(),\n        'pending_submissions': Submission.query.filter_by(status='pending').count(),\n        'approved_submissions': Submission.query.filter_by(status='approved').count(),\n        'total_scripts': Script.query.count(),\n        'active_scripts': Script.query.filter_by(is_active=True).count()\n    }\n    \n    recent_activity = Submission.query.order_by(Submission.created_at.desc()).limit(10).all()\n    \n    return render_template('dashboard_admin.html', \n                         stats=stats, \n                         recent_activity=recent_activity)\n\n# Additional routes for complete functionality  \n@app.route('/record')\n@require_auth\ndef record_list():\n    # Scripts are now loaded via AJAX, no need to pass them\n    return render_template('record.html')\n\n@app.route('/record/script/<int:script_id>')\n@require_auth\ndef record_script(script_id):\n    language = request.args.get('language', 'en')\n    # Handle script ID 0 as custom content creation\n    if script_id == 0:\n        script = None  # No script selected, custom content\n    else:\n        script = Script.query.get_or_404(script_id)\n    \n    scripts = Script.query.filter_by(is_active=True, language=language).order_by(Script.created_at.desc()).all()\n    return render_template('record.html', script=script, scripts=scripts)\n\n@app.route('/record-queue')\n@require_auth\ndef record_queue():\n    \"\"\"Streamlined recording interface with auto-advance functionality\"\"\"\n    user = User.query.get(session['user_id'])\n    if not user:\n        flash('User not found', 'error')\n        return redirect(url_for('login'))\n    \n    # Check if user has complete demographic profile\n    if not user.gender or not user.age_group:\n        flash('Please complete your profile with gender and age group information before recording.', 'error')\n        return redirect(url_for('provider_dashboard'))\n    \n    # Get available languages\n    languages = Language.query.filter_by(is_active=True).all()\n    \n    return render_template('record_queue.html', user=user, languages=languages)\n\n# API endpoint to get paginated scripts data\n@app.route('/api/scripts', methods=['GET'])\n@require_auth\ndef get_scripts():\n    # Get query parameters\n    language = request.args.get('language', '')\n    search_query = request.args.get('q', '').strip()\n    page = max(1, int(request.args.get('page', 1)))\n    page_size = min(100, max(10, int(request.args.get('page_size', 20))))  # Cap at 100, min 10\n    \n    # Build query\n    query = Script.query.filter_by(is_active=True)\n    \n    # Apply language filter if specified\n    if language:\n        query = query.filter(Script.language == language)\n    \n    # Apply search filter if specified\n    if search_query:\n        search_pattern = f\"%{search_query}%\"\n        query = query.filter(\n            db.or_(\n                Script.title.ilike(search_pattern),\n                Script.content.ilike(search_pattern),\n                Script.category.ilike(search_pattern)\n            )\n        )\n    \n    # Order and paginate\n    query = query.order_by(Script.created_at.desc())\n    total = query.count()\n    scripts = query.offset((page - 1) * page_size).limit(page_size).all()\n    \n    # Calculate pagination info\n    has_next = total > page * page_size\n    \n    return jsonify({\n        'items': [{\n            'id': script.id,\n            'title': getattr(script, 'title', None) or f\"Script {script.id}\",\n            'content': script.content[:200] + '...' if len(script.content) > 200 else script.content,  # Preview only\n            'language': script.language,\n            'category': getattr(script, 'category', None) or 'General',\n            'difficulty': getattr(script, 'difficulty', None) or 'Medium',\n            'target_duration': getattr(script, 'target_duration', None)\n        } for script in scripts],\n        'page': page,\n        'page_size': page_size,\n        'total': total,\n        'has_next': has_next\n    })\n\n# API endpoint to get individual script details for users\n@app.route('/api/scripts/<int:script_id>/details', methods=['GET'])\n@require_auth\ndef get_script_details(script_id):\n    script = Script.query.filter_by(id=script_id, is_active=True).first()\n    if not script:\n        return jsonify({'error': 'Script not found'}), 404\n    \n    return jsonify({\n        'id': script.id,\n        'title': getattr(script, 'title', None) or f\"Script {script.id}\",\n        'content': script.content,  # Full content\n        'language': script.language,\n        'category': getattr(script, 'category', None) or 'General',\n        'difficulty': getattr(script, 'difficulty', None) or 'Medium',\n        'target_duration': getattr(script, 'target_duration', None)\n    })\n\n# API endpoint to get available languages\n@app.route('/api/languages', methods=['GET'])\n@require_auth\ndef get_languages():\n    languages = Language.query.filter_by(is_active=True).order_by(Language.name).all()\n    return jsonify([{\n        'code': lang.code,\n        'name': lang.name,\n        'native_name': lang.native_name\n    } for lang in languages])\n\n# Removed custom content route - only script-based recordings allowed\n\n@app.route('/submissions')\n@require_auth\ndef submissions():\n    # Admins see ALL submissions, regular users see only their own\n    if session.get('user_role') == 'admin':\n        user_submissions = Submission.query.order_by(Submission.created_at.desc()).all()\n    else:\n        user_submissions = Submission.query.filter_by(user_id=session['user_id']).order_by(Submission.created_at.desc()).all()\n    return render_template('submissions.html', submissions=user_submissions)\n\n@app.route('/reviews')\n@require_role(['reviewer', 'admin'])\ndef reviews():\n    pending_submissions = Submission.query.filter_by(status='pending').order_by(Submission.created_at.asc()).all()\n    return render_template('reviews.html', submissions=pending_submissions)\n\n@app.route('/admin/languages')\n@require_role(['admin'])\ndef admin_languages():\n    \"\"\"Admin language and pricing management (merged interface)\"\"\"\n    languages = Language.query.order_by(Language.created_at.desc()).all()\n    \n    # Get pricing data for all languages\n    pricing_records = PricingRate.query.all()\n    pricing_dict = {pricing.language_code: pricing for pricing in pricing_records}\n    \n    return render_template('admin_languages_pricing.html', \n                         languages=languages, \n                         pricing_dict=pricing_dict)\n\n@app.route('/admin/scripts')\n@require_role(['admin'])\ndef admin_scripts():\n    scripts = Script.query.order_by(Script.created_at.desc()).all()\n    languages = Language.query.all()\n    return render_template('admin_scripts.html', scripts=scripts, languages=languages)\n\n# Recording and submission routes\n@app.route('/submit_recording', methods=['POST'])\n@require_auth\ndef submit_recording():\n    script_id = request.form.get('script_id')\n    text_content = request.form.get('text_content', '').strip()\n    audio_file = request.files.get('audio_file')\n    \n    # Validate required fields - for script-based recordings, audio is mandatory\n    if not script_id:\n        return jsonify({'success': False, 'error': 'Script selection is required'}), 400\n    \n    if not audio_file or not audio_file.filename:\n        return jsonify({'success': False, 'error': 'Audio recording is required for script submissions'}), 400\n    \n    # Handle audio file if uploaded\n    audio_filename = None\n    duration = None\n    if audio_file and audio_file.filename:\n        filename = secure_filename(audio_file.filename)\n        # Generate unique filename to prevent conflicts\n        audio_filename = f\"{uuid.uuid4()}_{filename}\"\n        \n        # Ensure upload directory exists\n        os.makedirs(app.config.get('UPLOAD_FOLDER', 'uploads'), exist_ok=True)\n        audio_file.save(os.path.join(app.config.get('UPLOAD_FOLDER', 'uploads'), audio_filename))\n    \n    # Calculate word count - use script content if no text_content provided\n    word_count = 0\n    if text_content:\n        word_count = len(text_content.split())\n    elif script_id:\n        # If recording from a script but no text provided, use script word count\n        script = Script.query.get(int(script_id))\n        if script and script.content:\n            word_count = len(script.content.split())\n    \n    # Get user for demographic snapshot\n    user = User.query.get(session['user_id'])\n    \n    # Create new submission with demographic snapshot\n    submission = Submission(\n        user_id=session['user_id'],\n        script_id=int(script_id) if script_id and script_id != '0' else None,\n        text_content=text_content,\n        audio_filename=audio_filename,\n        duration=duration,\n        word_count=word_count,\n        status='pending',\n        provider_gender=user.gender if user else None,  # Snapshot at submission time\n        provider_age_group=user.age_group if user else None  # Snapshot at submission time\n    )\n    \n    db.session.add(submission)\n    db.session.commit()\n    \n    return jsonify({'success': True, 'message': 'Recording submitted successfully!', 'submission_id': submission.id})\n\n# Field Collection Routes for Admins\n@app.route('/admin/field-collect')\n@require_role(['admin'])\ndef admin_field_collect():\n    \"\"\"Mobile-optimized field collection interface for admins\"\"\"\n    languages = Language.query.filter_by(is_active=True).all()\n    return render_template('admin_field_collect.html', languages=languages)\n\n@app.route('/admin/field-collect/submit', methods=['POST'])\n@require_role(['admin'])\ndef submit_field_collection():\n    \"\"\"Handle field-collected recording submissions by admins\"\"\"\n    script_id = request.form.get('script_id')\n    audio_file = request.files.get('audio_file')\n    \n    # Speaker metadata\n    speaker_name = request.form.get('speaker_name', '').strip()\n    speaker_location = request.form.get('speaker_location', '').strip()\n    provider_gender = request.form.get('provider_gender')\n    provider_age_group = request.form.get('provider_age_group')\n    \n    # Validate required fields\n    if not script_id:\n        return jsonify({'success': False, 'message': 'Script selection is required'}), 400\n    \n    if not audio_file or not audio_file.filename:\n        return jsonify({'success': False, 'message': 'Audio recording is required'}), 400\n    \n    if not provider_gender or not provider_age_group:\n        return jsonify({'success': False, 'message': 'Speaker gender and age group are required'}), 400\n    \n    # Handle audio file upload\n    filename = secure_filename(audio_file.filename)\n    audio_filename = f\"{uuid.uuid4()}_{filename}\"\n    \n    upload_folder = app.config.get('UPLOAD_FOLDER', 'uploads')\n    os.makedirs(upload_folder, exist_ok=True)\n    audio_file.save(os.path.join(upload_folder, audio_filename))\n    \n    # Calculate word count from script\n    word_count = 0\n    script = Script.query.get(int(script_id))\n    if script and script.content:\n        word_count = len(script.content.split())\n    \n    # Create field-collected submission (auto-approved, no review needed)\n    submission = Submission(\n        user_id=None,  # No user for field collections\n        script_id=int(script_id),\n        text_content='',\n        audio_filename=audio_filename,\n        word_count=word_count,\n        status='approved',  # Auto-approve field collections\n        provider_gender=provider_gender,\n        provider_age_group=provider_age_group,\n        collected_by_admin_id=session['user_id'],  # Track who collected it\n        speaker_name=speaker_name or None,\n        speaker_location=speaker_location or None,\n        is_field_collection=True\n    )\n    \n    db.session.add(submission)\n    db.session.commit()\n    \n    return jsonify({\n        'success': True, \n        'message': 'Recording submitted successfully!',\n        'submission_id': submission.id\n    })\n\n# File serving route for audio files\n@app.route('/uploads/<filename>')\n@require_auth\ndef uploaded_file(filename):\n    \"\"\"Serve uploaded audio files\"\"\"\n    return send_from_directory(app.config['UPLOAD_FOLDER'], filename)\n\n# Delete submission route for providers\n@app.route('/delete_submission/<int:submission_id>', methods=['POST'])\n@require_auth\ndef delete_submission(submission_id):\n    \"\"\"Allow providers to delete their own submissions before review\"\"\"\n    submission = Submission.query.get_or_404(submission_id)\n    \n    # Check if user owns this submission\n    if submission.user_id != session['user_id']:\n        flash('You can only delete your own submissions.', 'error')\n        return redirect(url_for('provider_dashboard'))\n    \n    # Check if submission is still pending (not reviewed)\n    if submission.status != 'pending':\n        flash('You can only delete submissions that haven\\'t been reviewed yet.', 'error')\n        return redirect(url_for('provider_dashboard'))\n    \n    # Delete audio file if it exists\n    if submission.audio_filename:\n        audio_path = os.path.join(app.config['UPLOAD_FOLDER'], submission.audio_filename)\n        if os.path.exists(audio_path):\n            os.remove(audio_path)\n    \n    # Delete submission from database\n    db.session.delete(submission)\n    db.session.commit()\n    \n    flash('Submission deleted successfully.', 'success')\n    return redirect(url_for('provider_dashboard'))\n\n# Review submission page for reviewers\n@app.route('/review/submission/<int:submission_id>')\n@require_role(['reviewer', 'admin'])\ndef review_submission(submission_id):\n    \"\"\"Display submission review interface\"\"\"\n    submission = Submission.query.get_or_404(submission_id)\n    return render_template('review_submission.html', submission=submission)\n\n# API endpoint for processing review decisions\n@app.route('/api/submissions/<int:submission_id>/review', methods=['POST'])\n@require_role(['reviewer', 'admin'])\ndef process_review(submission_id):\n    \"\"\"Handle submission review by reviewers\"\"\"\n    submission = Submission.query.get_or_404(submission_id)\n    \n    if request.method == 'GET':\n        # Return submission details for review modal\n        return jsonify({\n            'id': submission.id,\n            'script_title': submission.script.title if submission.script else 'Custom Content',\n            'script_content': submission.script.content if submission.script else '',\n            'text_content': submission.text_content or '',\n            'audio_filename': submission.audio_filename,\n            'word_count': submission.word_count,\n            'duration': submission.duration,\n            'created_at': submission.created_at.strftime('%Y-%m-%d %H:%M:%S'),\n            'user_name': f\"{submission.user.first_name} {submission.user.last_name}\"\n        })\n    \n    elif request.method == 'POST':\n        # Process review decision\n        data = request.json or {}\n        action = data.get('action')  # 'approve', 'reject', or 'request_changes'\n        review_notes = data.get('notes', '')\n        quality_score = data.get('quality_score', 0)\n        \n        # Update submission\n        submission.status = action if action in ['approved', 'rejected'] else 'pending'\n        submission.reviewed_by = session['user_id']\n        submission.reviewed_at = datetime.utcnow()\n        submission.review_notes = review_notes\n        submission.quality_score = quality_score\n        \n        # Create billing records for approved submissions\n        if action == 'approved':\n            # Get language-specific pricing\n            script_language = submission.script.language if submission.script else 'en'\n            pricing = PricingRate.query.filter_by(language_code=script_language).first()\n            \n            if not pricing:\n                # Create default pricing if none exists\n                pricing = PricingRate(\n                    language_code=script_language,\n                    provider_rate_per_word=0.01,\n                    reviewer_rate_per_submission=2.00\n                )\n                db.session.add(pricing)\n                db.session.flush()  # Get the ID\n            \n            # Provider payment (per word) - recalculate word count if needed\n            provider_word_count = submission.word_count\n            if provider_word_count == 0 and submission.script:\n                # Use script word count if submission word count is 0\n                provider_word_count = len(submission.script.content.split())\n            \n            if provider_word_count > 0:\n                provider_amount = provider_word_count * pricing.provider_rate_per_word\n                provider_billing = BillingRecord(\n                    user_id=submission.user_id,\n                    submission_id=submission.id,\n                    amount=provider_amount,\n                    rate_per_word=pricing.provider_rate_per_word,\n                    billing_type='provider',\n                    language_code=script_language,\n                    word_count=provider_word_count\n                )\n                db.session.add(provider_billing)\n            \n            # Reviewer payment (per submission)\n            reviewer_billing = BillingRecord(\n                user_id=session['user_id'],  # Current reviewer\n                submission_id=submission.id,\n                amount=pricing.reviewer_rate_per_submission,\n                rate_per_submission=pricing.reviewer_rate_per_submission,\n                billing_type='reviewer',\n                language_code=script_language\n            )\n            db.session.add(reviewer_billing)\n        \n        db.session.commit()\n        \n        return jsonify({\n            'success': True,\n            'message': f'Submission {action} successfully'\n        })\n\n# Pricing management routes\n@app.route('/admin/pricing')\n@require_role(['admin'])\ndef admin_pricing():\n    \"\"\"Admin interface for managing pricing rates\"\"\"\n    languages = Language.query.filter_by(is_active=True).all()\n    pricing_rates = PricingRate.query.all()\n    \n    # Create dict for easy lookup\n    pricing_dict = {rate.language_code: rate for rate in pricing_rates}\n    \n    return render_template('admin_pricing.html', \n                         languages=languages, \n                         pricing_dict=pricing_dict)\n\n@app.route('/api/pricing/update', methods=['POST'])\n@require_role(['admin'])\ndef update_pricing():\n    \"\"\"Update pricing rates for languages\"\"\"\n    data = request.json or {}\n    language_code = data.get('language_code')\n    provider_rate = float(data.get('provider_rate', 0.01))\n    reviewer_rate = float(data.get('reviewer_rate', 2.00))\n    currency = data.get('currency', 'USD')\n    \n    # Find or create pricing record\n    pricing = PricingRate.query.filter_by(language_code=language_code).first()\n    if pricing:\n        pricing.provider_rate_per_word = provider_rate\n        pricing.reviewer_rate_per_submission = reviewer_rate\n        pricing.currency = currency\n        pricing.updated_at = datetime.utcnow()\n    else:\n        pricing = PricingRate(\n            language_code=language_code,\n            provider_rate_per_word=provider_rate,\n            reviewer_rate_per_submission=reviewer_rate,\n            currency=currency\n        )\n        db.session.add(pricing)\n    \n    db.session.commit()\n    return jsonify({'success': True})\n\n# Earnings dashboard routes  \n@app.route('/earnings')\n@require_auth\ndef earnings_dashboard():\n    \"\"\"User earnings dashboard\"\"\"\n    # Check if earnings functionality is enabled\n    if not get_show_earnings():\n        flash('Earnings functionality is currently disabled.', 'info')\n        # Redirect to appropriate dashboard based on user role\n        user_role = session.get('user_role', 'provider')\n        if user_role == 'admin':\n            return redirect(url_for('admin_dashboard'))\n        elif user_role == 'reviewer':\n            return redirect(url_for('reviewer_dashboard'))\n        else:\n            return redirect(url_for('provider_dashboard'))\n    \n    user_id = session['user_id']\n    user = User.query.get(user_id)\n    if not user:\n        flash('User not found', 'error')\n        return redirect(url_for('login'))\n    \n    # Get user's billing records (handle potential schema migration)\n    try:\n        provider_earnings = BillingRecord.query.filter_by(\n            user_id=user_id, \n            billing_type='provider'\n        ).order_by(BillingRecord.created_at.desc()).all()\n        \n        reviewer_earnings = BillingRecord.query.filter_by(\n            user_id=user_id, \n            billing_type='reviewer'\n        ).order_by(BillingRecord.created_at.desc()).all()\n    except Exception as e:\n        # Handle old schema - show empty for now\n        provider_earnings = []\n        reviewer_earnings = []\n    \n    # Calculate totals\n    total_provider = sum(record.amount for record in provider_earnings)\n    total_reviewer = sum(record.amount for record in reviewer_earnings)\n    \n    # Role-specific total earnings\n    if user.role == 'provider':\n        total_earnings = total_provider\n    elif user.role == 'reviewer':\n        total_earnings = total_reviewer\n    else:  # admin\n        total_earnings = total_provider + total_reviewer\n    \n    return render_template('earnings.html',\n                         user=user,\n                         provider_earnings=provider_earnings,\n                         reviewer_earnings=reviewer_earnings,\n                         total_provider=total_provider,\n                         total_reviewer=total_reviewer,\n                         total_earnings=total_earnings,\n                         user_role=user.role)\n\n# API routes for admin panel\n@app.route('/api/scripts', methods=['POST'])\n@require_role(['admin'])\ndef create_script():\n    data = request.json or {}\n    \n    script = Script(\n        content=data['content'],\n        language=data.get('language', 'en')\n    )\n    db.session.add(script)\n    db.session.commit()\n    return jsonify({'success': True, 'id': script.id})\n\n@app.route('/api/scripts/<int:script_id>', methods=['GET'])\n@require_role(['admin'])\ndef get_script(script_id):\n    script = Script.query.get_or_404(script_id)\n    languages = Language.query.all()\n    return jsonify({\n        'success': True,\n        'script': {\n            'id': script.id,\n            'content': script.content,\n            'language': script.language,\n            'is_active': script.is_active\n        },\n        'languages': [{'code': lang.code, 'name': lang.name} for lang in languages]\n    })\n\n@app.route('/api/scripts/<int:script_id>/submissions', methods=['GET'])\n@require_role(['admin'])\ndef get_script_submissions(script_id):\n    \"\"\"Get all submissions for a specific script\"\"\"\n    script = Script.query.get_or_404(script_id)\n    \n    submissions = Submission.query.filter_by(script_id=script_id).order_by(Submission.created_at.desc()).all()\n    \n    result = []\n    for sub in submissions:\n        # Get submitter info\n        if sub.is_field_collection:\n            admin = User.query.get(sub.collected_by_admin_id) if sub.collected_by_admin_id else None\n            admin_name = f\"{admin.first_name} {admin.last_name}\" if admin else 'Unknown'\n            submitter_name = f\"Field: {sub.speaker_name or 'Anonymous'} (collected by {admin_name})\"\n        else:\n            user = User.query.get(sub.user_id) if sub.user_id else None\n            submitter_name = f\"{user.first_name} {user.last_name}\" if user else 'Unknown User'\n        \n        result.append({\n            'id': sub.id,\n            'submitter_name': submitter_name,\n            'speaker_location': sub.speaker_location,\n            'provider_gender': sub.provider_gender,\n            'provider_age_group': sub.provider_age_group,\n            'status': sub.status,\n            'audio_filename': sub.audio_filename,\n            'is_field_collection': sub.is_field_collection,\n            'created_at': sub.created_at.strftime('%Y-%m-%d %H:%M') if sub.created_at else None\n        })\n    \n    return jsonify({\n        'success': True,\n        'script': {\n            'id': script.id,\n            'content': script.content,\n            'language': script.language\n        },\n        'submissions': result\n    })\n\n@app.route('/api/scripts/<int:script_id>', methods=['PUT'])\n@require_role(['admin'])\ndef update_script(script_id):\n    script = Script.query.get_or_404(script_id)\n    data = request.json or {}\n    \n    script.content = data.get('content', script.content)\n    script.language = data.get('language', script.language)\n    script.is_active = data.get('is_active', script.is_active)\n    \n    db.session.commit()\n    return jsonify({'success': True})\n\n@app.route('/api/scripts/<int:script_id>', methods=['DELETE'])\n@require_role(['admin'])\ndef delete_script(script_id):\n    script = Script.query.get_or_404(script_id)\n    \n    # Get all submissions for this script\n    submissions = Submission.query.filter_by(script_id=script_id).all()\n    \n    # Delete audio files and submissions\n    deleted_files = 0\n    for submission in submissions:\n        if submission.audio_filename:\n            audio_path = os.path.join(app.config['UPLOAD_FOLDER'], submission.audio_filename)\n            if os.path.exists(audio_path):\n                try:\n                    os.remove(audio_path)\n                    deleted_files += 1\n                except Exception as e:\n                    app.logger.error(f\"Failed to delete audio file {audio_path}: {e}\")\n        \n        # Delete the submission record\n        db.session.delete(submission)\n    \n    # Delete the script\n    db.session.delete(script)\n    db.session.commit()\n    \n    app.logger.info(f\"Deleted script {script_id} with {len(submissions)} submissions and {deleted_files} audio files\")\n    return jsonify({\n        'success': True,\n        'deleted_submissions': len(submissions),\n        'deleted_files': deleted_files\n    })\n\n@app.route('/api/scripts/bulk-delete', methods=['DELETE'])\n@require_role(['admin'])\ndef bulk_delete_scripts():\n    data = request.json or {}\n    script_ids = data.get('script_ids', [])\n    \n    if not script_ids:\n        return jsonify({'success': False, 'error': 'No script IDs provided'}), 400\n    \n    # Validate that all IDs are integers\n    try:\n        script_ids = [int(id) for id in script_ids]\n    except ValueError:\n        return jsonify({'success': False, 'error': 'Invalid script ID format'}), 400\n    \n    # Delete scripts and their associated submissions\n    total_deleted_scripts = 0\n    total_deleted_submissions = 0\n    total_deleted_files = 0\n    \n    for script_id in script_ids:\n        script = Script.query.get(script_id)\n        if not script:\n            continue\n        \n        # Get all submissions for this script\n        submissions = Submission.query.filter_by(script_id=script_id).all()\n        \n        # Delete audio files and submissions\n        for submission in submissions:\n            if submission.audio_filename:\n                audio_path = os.path.join(app.config['UPLOAD_FOLDER'], submission.audio_filename)\n                if os.path.exists(audio_path):\n                    try:\n                        os.remove(audio_path)\n                        total_deleted_files += 1\n                    except Exception as e:\n                        app.logger.error(f\"Failed to delete audio file {audio_path}: {e}\")\n            \n            db.session.delete(submission)\n            total_deleted_submissions += 1\n        \n        # Delete the script\n        db.session.delete(script)\n        total_deleted_scripts += 1\n    \n    db.session.commit()\n    \n    app.logger.info(f\"Bulk deleted {total_deleted_scripts} scripts with {total_deleted_submissions} submissions and {total_deleted_files} audio files\")\n    return jsonify({\n        'success': True,\n        'deleted_count': total_deleted_scripts,\n        'deleted_submissions': total_deleted_submissions,\n        'deleted_files': total_deleted_files\n    })\n\n@app.route('/api/scripts/bulk-upload', methods=['POST'])\n@require_role(['admin'])\ndef bulk_upload_scripts():\n    try:\n        # Check if file was uploaded\n        if 'csvFile' not in request.files:\n            return jsonify({'success': False, 'error': 'No CSV file provided'}), 400\n        \n        csv_file = request.files['csvFile']\n        language = request.form.get('language')\n        \n        if csv_file.filename == '':\n            return jsonify({'success': False, 'error': 'No file selected'}), 400\n        \n        if not language:\n            return jsonify({'success': False, 'error': 'Language selection is required'}), 400\n        \n        # Verify language exists\n        if not Language.query.filter_by(code=language).first():\n            return jsonify({'success': False, 'error': 'Invalid language selected'}), 400\n        \n        # Read and parse CSV content\n        import csv\n        import io\n        \n        # Read file content\n        content = csv_file.read().decode('utf-8')\n        csv_reader = csv.DictReader(io.StringIO(content))\n        \n        # Validate CSV has required column\n        fieldnames = csv_reader.fieldnames or []\n        if 'content' not in fieldnames:\n            return jsonify({\n                'success': False, \n                'error': 'CSV must have a \"content\" column. Found columns: ' + ', '.join(fieldnames)\n            }), 400\n        \n        # Process CSV rows and create scripts\n        created_count = 0\n        errors = []\n        \n        for row_num, row in enumerate(csv_reader, start=2):  # Start from 2 because header is row 1\n            script_content = row.get('content', '').strip()\n            \n            if not script_content:\n                errors.append(f\"Row {row_num}: Empty content\")\n                continue\n            \n            # Check if script with same content and language already exists\n            existing_script = Script.query.filter_by(content=script_content, language=language).first()\n            if existing_script:\n                errors.append(f\"Row {row_num}: Script with same content already exists\")\n                continue\n            \n            try:\n                # Create new script\n                script = Script(\n                    content=script_content,\n                    language=language,\n                    is_active=True\n                )\n                db.session.add(script)\n                created_count += 1\n            except Exception as e:\n                errors.append(f\"Row {row_num}: Error creating script - {str(e)}\")\n                continue\n        \n        # Commit all changes if at least one script was created\n        if created_count > 0:\n            db.session.commit()\n        \n        # Prepare response\n        response_data = {'success': True, 'created_count': created_count}\n        \n        if errors:\n            response_data['warnings'] = errors\n            response_data['message'] = f\"Created {created_count} scripts with {len(errors)} warnings\"\n        \n        return jsonify(response_data)\n        \n    except Exception as e:\n        db.session.rollback()\n        return jsonify({'success': False, 'error': f'Failed to process CSV: {str(e)}'}), 500\n\n@app.route('/api/scripts/bulk-text', methods=['POST'])\n@require_role(['admin'])\ndef bulk_add_text_scripts():\n    \"\"\"Bulk add scripts from multiline text where each line is a script\"\"\"\n    try:\n        data = request.get_json()\n        \n        if not data:\n            return jsonify({'success': False, 'error': 'No data provided'}), 400\n        \n        language = data.get('language')\n        script_text = data.get('scriptText', '')\n        \n        if not language:\n            return jsonify({'success': False, 'error': 'Language is required'}), 400\n        \n        if not script_text.strip():\n            return jsonify({'success': False, 'error': 'Script text is required'}), 400\n        \n        # Verify language exists\n        if not Language.query.filter_by(code=language).first():\n            return jsonify({'success': False, 'error': 'Invalid language selected'}), 400\n        \n        # Split text into lines and process each one\n        lines = [line.strip() for line in script_text.split('\\n') if line.strip()]\n        \n        if not lines:\n            return jsonify({'success': False, 'error': 'No valid script lines found'}), 400\n        \n        created_count = 0\n        errors = []\n        \n        for line_num, content in enumerate(lines, start=1):\n            # Check for duplicate\n            existing_script = Script.query.filter_by(content=content, language=language).first()\n            if existing_script:\n                errors.append(f\"Line {line_num}: Script with same content already exists\")\n                continue\n            \n            # Create script\n            try:\n                script = Script(\n                    content=content,\n                    language=language,\n                    is_active=True\n                )\n                db.session.add(script)\n                created_count += 1\n            except Exception as e:\n                errors.append(f\"Line {line_num}: Error creating script - {str(e)}\")\n                continue\n        \n        # Commit all changes if at least one script was created\n        if created_count > 0:\n            db.session.commit()\n        \n        response_data = {'success': True, 'created_count': created_count}\n        \n        if errors:\n            response_data['warnings'] = errors\n            response_data['message'] = f\"Created {created_count} scripts with {len(errors)} warnings\"\n        \n        return jsonify(response_data)\n        \n    except Exception as e:\n        db.session.rollback()\n        return jsonify({'success': False, 'error': f'Failed to process text: {str(e)}'}), 500\n\n# Demographic requirement management APIs\n@app.route('/api/scripts/<int:script_id>/requirements', methods=['GET'])\n@require_role(['admin'])\ndef get_script_requirements(script_id):\n    \"\"\"Get demographic requirements for a script\"\"\"\n    script = Script.query.get_or_404(script_id)\n    requirements = ScriptVariantRequirement.query.filter_by(script_id=script_id).all()\n    \n    return jsonify({\n        'script_id': script_id,\n        'requirements': [{\n            'id': req.id,\n            'gender': req.gender,\n            'age_group': req.age_group,\n            'target_total': req.target_total,\n            'enabled': req.enabled\n        } for req in requirements]\n    })\n\n@app.route('/api/scripts/<int:script_id>/requirements', methods=['POST'])\n@require_role(['admin'])\ndef set_script_requirements(script_id):\n    \"\"\"Set demographic requirements for a script\"\"\"\n    script = Script.query.get_or_404(script_id)\n    data = request.get_json()\n    \n    requirements = data.get('requirements', [])\n    \n    try:\n        # Clear existing requirements\n        ScriptVariantRequirement.query.filter_by(script_id=script_id).delete()\n        \n        # Add new requirements\n        for req in requirements:\n            variant_req = ScriptVariantRequirement(\n                script_id=script_id,\n                gender=req['gender'],\n                age_group=req['age_group'],\n                target_total=req.get('target_total', 1),\n                enabled=req.get('enabled', True)\n            )\n            db.session.add(variant_req)\n        \n        db.session.commit()\n        return jsonify({'success': True})\n    \n    except Exception as e:\n        db.session.rollback()\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n@app.route('/api/scripts/<int:script_id>/progress', methods=['GET'])\n@require_role(['admin', 'reviewer'])\ndef get_script_progress(script_id):\n    \"\"\"Get progress matrix for a script showing completed vs target by demographic\"\"\"\n    script = Script.query.get_or_404(script_id)\n    \n    # Get requirements\n    requirements = ScriptVariantRequirement.query.filter_by(script_id=script_id, enabled=True).all()\n    \n    # Get completion counts by demographic\n    from sqlalchemy import func\n    completion_counts = db.session.query(\n        Submission.provider_gender,\n        Submission.provider_age_group,\n        Submission.status,\n        func.count(Submission.id).label('count')\n    ).filter_by(script_id=script_id).group_by(\n        Submission.provider_gender, \n        Submission.provider_age_group,\n        Submission.status\n    ).all()\n    \n    # Build progress matrix\n    progress = {}\n    for req in requirements:\n        key = f\"{req.gender}_{req.age_group}\"\n        progress[key] = {\n            'gender': req.gender,\n            'age_group': req.age_group,\n            'target': req.target_total,\n            'approved': 0,\n            'pending': 0,\n            'rejected': 0\n        }\n    \n    # Fill in actual counts\n    for count_row in completion_counts:\n        if count_row.provider_gender and count_row.provider_age_group:\n            key = f\"{count_row.provider_gender}_{count_row.provider_age_group}\"\n            if key in progress:\n                if count_row.status == 'approved':\n                    progress[key]['approved'] = count_row.count\n                elif count_row.status == 'pending':\n                    progress[key]['pending'] = count_row.count\n                elif count_row.status == 'rejected':\n                    progress[key]['rejected'] = count_row.count\n    \n    return jsonify({\n        'script_id': script_id,\n        'progress': list(progress.values())\n    })\n\n# Provider recording queue APIs\n@app.route('/api/recording/next', methods=['GET'])\n@require_auth\ndef get_next_recording_task():\n    \"\"\"Get the next script that needs recording for the current user's demographic\"\"\"\n    user = User.query.get(session['user_id'])\n    if not user:\n        return jsonify({'error': 'User not found'}), 404\n        \n    language = request.args.get('language', 'en')\n    \n    if not user.gender or not user.age_group:\n        return jsonify({'error': 'User profile incomplete - gender and age group required'}), 400\n    \n    # Find scripts that need recordings for this user's demographic\n    # and haven't been recorded by this user yet\n    subquery = db.session.query(Submission.script_id).filter_by(user_id=user.id)\n    \n    available_scripts = db.session.query(Script, ScriptVariantRequirement).join(\n        ScriptVariantRequirement, Script.id == ScriptVariantRequirement.script_id\n    ).filter(\n        Script.is_active == True,\n        Script.language == language,\n        ScriptVariantRequirement.enabled == True,\n        ScriptVariantRequirement.gender == user.gender,\n        ScriptVariantRequirement.age_group == user.age_group,\n        ~Script.id.in_(subquery)  # User hasn't recorded this script yet\n    ).order_by(Script.created_at.asc()).first()\n    \n    if not available_scripts:\n        return jsonify({'message': 'No scripts available for your demographic profile', 'has_task': False})\n    \n    script, requirement = available_scripts\n    \n    # Check if we still need more recordings for this variant\n    current_count = Submission.query.filter_by(\n        script_id=script.id,\n        provider_gender=user.gender,\n        provider_age_group=user.age_group,\n        status='approved'\n    ).count()\n    \n    if current_count >= requirement.target_total:\n        return jsonify({'message': 'Target reached for your demographic', 'has_task': False})\n    \n    return jsonify({\n        'has_task': True,\n        'script': {\n            'id': script.id,\n            'content': script.content,\n            'language': script.language\n        },\n        'requirement': {\n            'target_total': requirement.target_total,\n            'current_approved': current_count\n        },\n        'user_demographic': {\n            'gender': user.gender,\n            'age_group': user.age_group\n        }\n    })\n\n@app.route('/api/user-submissions/<int:script_id>', methods=['GET'])\n@require_auth\ndef get_user_submissions(script_id):\n    \"\"\"Get current user's submissions for a specific script\"\"\"\n    user_id = session['user_id']\n    script = Script.query.get_or_404(script_id)\n    \n    # Get user's submissions for this script\n    submissions = Submission.query.filter_by(\n        user_id=user_id,\n        script_id=script_id\n    ).order_by(Submission.created_at.desc()).all()\n    \n    return jsonify({\n        'success': True,\n        'script_id': script_id,\n        'submissions': [{\n            'id': sub.id,\n            'text_content': sub.text_content or '',\n            'audio_filename': sub.audio_filename,\n            'status': sub.status,\n            'created_at': sub.created_at.isoformat(),\n            'word_count': sub.word_count or 0,\n            'duration': sub.duration\n        } for sub in submissions]\n    })\n\n# User management routes\n@app.route('/admin/users')\n@require_role(['admin'])\ndef admin_users():\n    users = User.query.order_by(User.created_at.desc()).all()\n    return render_template('admin_users.html', users=users)\n\n@app.route('/admin/data-export')\n@require_role(['admin'])\ndef admin_data_export():\n    \"\"\"View all recordings with metadata for export\"\"\"\n    submissions = Submission.query.order_by(Submission.created_at.desc()).all()\n    \n    # Enrich submissions with related data\n    export_data = []\n    for sub in submissions:\n        script = Script.query.get(sub.script_id) if sub.script_id else None\n        \n        # Get submitter info\n        if sub.is_field_collection:\n            admin = User.query.get(sub.collected_by_admin_id) if sub.collected_by_admin_id else None\n            submitter = f\"{admin.first_name} {admin.last_name}\" if admin else 'Unknown Admin'\n            speaker_name = sub.speaker_name or 'Anonymous'\n        else:\n            user = User.query.get(sub.user_id) if sub.user_id else None\n            submitter = f\"{user.first_name} {user.last_name}\" if user else 'Unknown User'\n            speaker_name = submitter\n        \n        export_data.append({\n            'submission': sub,\n            'script_content': script.content if script else 'N/A',\n            'script_language': script.language if script else 'N/A',\n            'submitter': submitter,\n            'speaker_name': speaker_name\n        })\n    \n    return render_template('admin_data_export.html', export_data=export_data, total_count=len(export_data))\n\n@app.route('/admin/data-export/csv')\n@require_role(['admin'])\ndef export_data_csv():\n    \"\"\"Export all recordings metadata as CSV\"\"\"\n    submissions = Submission.query.order_by(Submission.created_at.desc()).all()\n    \n    # Create CSV in memory\n    output = io.StringIO()\n    writer = csv.writer(output)\n    \n    # Write header\n    writer.writerow([\n        'ID', 'Audio Filename', 'Script ID', 'Script Content', 'Language',\n        'Speaker Gender', 'Speaker Age Group', 'Speaker Name', 'Speaker Location',\n        'Is Field Collection', 'Collected By', 'Status', 'Word Count', 'Created At'\n    ])\n    \n    # Write data rows\n    for sub in submissions:\n        script = Script.query.get(sub.script_id) if sub.script_id else None\n        \n        # Get collector info\n        if sub.is_field_collection:\n            admin = User.query.get(sub.collected_by_admin_id) if sub.collected_by_admin_id else None\n            collector = f\"{admin.first_name} {admin.last_name}\" if admin else 'Unknown'\n        else:\n            user = User.query.get(sub.user_id) if sub.user_id else None\n            collector = f\"{user.first_name} {user.last_name}\" if user else 'Unknown'\n        \n        writer.writerow([\n            sub.id,\n            sub.audio_filename or '',\n            sub.script_id or '',\n            script.content if script else '',\n            script.language if script else '',\n            sub.provider_gender or '',\n            sub.provider_age_group or '',\n            sub.speaker_name or '',\n            sub.speaker_location or '',\n            'Yes' if sub.is_field_collection else 'No',\n            collector,\n            sub.status,\n            sub.word_count or 0,\n            sub.created_at.strftime('%Y-%m-%d %H:%M:%S') if sub.created_at else ''\n        ])\n    \n    # Prepare response\n    output.seek(0)\n    return send_file(\n        io.BytesIO(output.getvalue().encode('utf-8')),\n        mimetype='text/csv',\n        as_attachment=True,\n        download_name=f'voicescript_export_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv'\n    )\n\n@app.route('/api/submissions/<int:submission_id>', methods=['DELETE'])\n@require_role(['admin'])\ndef admin_delete_submission(submission_id):\n    \"\"\"Admin: Delete any submission and its audio file\"\"\"\n    submission = Submission.query.get_or_404(submission_id)\n    \n    # Delete audio file if exists\n    deleted_file = False\n    if submission.audio_filename:\n        audio_path = os.path.join(app.config['UPLOAD_FOLDER'], submission.audio_filename)\n        if os.path.exists(audio_path):\n            try:\n                os.remove(audio_path)\n                deleted_file = True\n                app.logger.info(f\"Deleted audio file: {audio_path}\")\n            except Exception as e:\n                app.logger.error(f\"Failed to delete audio file {audio_path}: {e}\")\n                return jsonify({\n                    'success': False,\n                    'error': f'Failed to delete audio file: {str(e)}'\n                }), 500\n    \n    # Delete the submission record\n    db.session.delete(submission)\n    db.session.commit()\n    \n    app.logger.info(f\"Deleted submission {submission_id} (audio file deleted: {deleted_file})\")\n    return jsonify({\n        'success': True,\n        'deleted_file': deleted_file\n    })\n\n@app.route('/admin/roles')\n@require_role(['admin'])\ndef admin_roles():\n    users = User.query.order_by(User.created_at.desc()).all()\n    role_stats = {\n        'admin': User.query.filter_by(role='admin').count(),\n        'reviewer': User.query.filter_by(role='reviewer').count(),\n        'provider': User.query.filter_by(role='provider').count()\n    }\n    return render_template('admin_roles.html', users=users, role_stats=role_stats)\n\n@app.route('/api/users/<int:user_id>/role', methods=['PUT'])\n@require_role(['admin'])\ndef update_user_role(user_id):\n    user = User.query.get_or_404(user_id)\n    data = request.json or {}\n    \n    new_role = data.get('role')\n    if new_role not in ['provider', 'reviewer', 'admin']:\n        return jsonify({'success': False, 'error': 'Invalid role'}), 400\n    \n    user.role = new_role\n    db.session.commit()\n    return jsonify({'success': True})\n\n@app.route('/api/users', methods=['POST'])\n@require_role(['admin'])\ndef create_user():\n    data = request.json or {}\n    \n    # Check if user already exists\n    if User.query.filter_by(email=data['email']).first():\n        return jsonify({'success': False, 'error': 'User already exists'}), 400\n    \n    user = User(\n        email=data['email'],\n        first_name=data['first_name'], \n        last_name=data['last_name'],\n        role=data.get('role', 'provider'),\n        gender=data.get('gender'),\n        age_group=data.get('age_group')\n    )\n    user.set_password(data['password'])\n    db.session.add(user)\n    db.session.commit()\n    return jsonify({'success': True, 'id': user.id})\n\n@app.route('/api/users/<int:user_id>', methods=['PUT'])\n@require_role(['admin'])\ndef update_user(user_id):\n    user = User.query.get_or_404(user_id)\n    data = request.json or {}\n    \n    user.first_name = data.get('first_name', user.first_name)\n    user.last_name = data.get('last_name', user.last_name)\n    user.email = data.get('email', user.email)\n    user.gender = data.get('gender', user.gender)\n    user.age_group = data.get('age_group', user.age_group)\n    \n    db.session.commit()\n    return jsonify({'success': True})\n\n@app.route('/api/users/<int:user_id>', methods=['DELETE'])\n@require_role(['admin'])\ndef delete_user(user_id):\n    user = User.query.get_or_404(user_id)\n    \n    # Prevent deleting the current user\n    if user.id == session.get('user_id'):\n        return jsonify({'success': False, 'error': 'Cannot delete your own account'}), 400\n    \n    db.session.delete(user)\n    db.session.commit()\n    return jsonify({'success': True})\n\n# Language management API routes\n@app.route('/api/languages', methods=['POST'])\n@require_role(['admin'])\ndef add_language():\n    data = request.json or {}\n    \n    # Check if language code already exists\n    if Language.query.filter_by(code=data['code']).first():\n        return jsonify({'success': False, 'error': 'Language code already exists'}), 400\n    \n    language = Language(\n        code=data['code'].lower(),\n        name=data['name'],\n        native_name=data.get('native_name', ''),\n        is_active=True\n    )\n    db.session.add(language)\n    \n    # Create pricing rates if provided\n    provider_rate = float(data.get('provider_rate', 0.010))\n    reviewer_rate = float(data.get('reviewer_rate', 2.00))\n    \n    pricing = PricingRate(\n        language_code=data['code'].lower(),\n        provider_rate_per_word=provider_rate,\n        reviewer_rate_per_submission=reviewer_rate,\n        currency=data.get('currency', 'USD')\n    )\n    db.session.add(pricing)\n    \n    db.session.commit()\n    return jsonify({'success': True, 'id': language.id})\n\n\n\n@app.route('/api/languages/<language_code>', methods=['PUT'])\n@require_role(['admin'])\ndef update_language(language_code):\n    language = Language.query.filter_by(code=language_code).first()\n    if not language:\n        return jsonify({'success': False, 'error': 'Language not found'}), 404\n    \n    data = request.json or {}\n    language.name = data.get('name', language.name)\n    language.native_name = data.get('native_name', language.native_name)\n    language.is_active = data.get('is_active', language.is_active)\n    \n    # Update or create pricing if rates provided\n    if 'provider_rate' in data or 'reviewer_rate' in data:\n        pricing = PricingRate.query.filter_by(language_code=language_code).first()\n        if pricing:\n            pricing.provider_rate_per_word = float(data.get('provider_rate', pricing.provider_rate_per_word))\n            pricing.reviewer_rate_per_submission = float(data.get('reviewer_rate', pricing.reviewer_rate_per_submission))\n            pricing.currency = data.get('currency', pricing.currency)\n            pricing.updated_at = datetime.utcnow()\n        else:\n            pricing = PricingRate(\n                language_code=language_code,\n                provider_rate_per_word=float(data.get('provider_rate', 0.01)),\n                reviewer_rate_per_submission=float(data.get('reviewer_rate', 2.00)),\n                currency=data.get('currency', 'USD')\n            )\n            db.session.add(pricing)\n    \n    db.session.commit()\n    return jsonify({'success': True})\n\n@app.route('/api/languages/<language_code>', methods=['GET'])\n@require_role(['admin'])\ndef get_language(language_code):\n    \"\"\"Get language details\"\"\"\n    language = Language.query.filter_by(code=language_code).first()\n    if not language:\n        return jsonify({'success': False, 'error': 'Language not found'}), 404\n    \n    return jsonify({\n        'code': language.code,\n        'name': language.name,\n        'native_name': language.native_name,\n        'is_active': language.is_active\n    })\n\n@app.route('/api/pricing/<language_code>', methods=['GET'])\n@require_role(['admin'])\ndef get_pricing(language_code):\n    \"\"\"Get pricing for a language\"\"\"\n    pricing = PricingRate.query.filter_by(language_code=language_code).first()\n    if not pricing:\n        return jsonify({\n            'provider_rate_per_word': 0.010,\n            'reviewer_rate_per_submission': 2.00,\n            'currency': 'USD'\n        })\n    \n    return jsonify({\n        'provider_rate_per_word': pricing.provider_rate_per_word,\n        'reviewer_rate_per_submission': pricing.reviewer_rate_per_submission,\n        'currency': pricing.currency\n    })\n\n@app.route('/api/settings/earnings', methods=['PUT'])\n@require_role(['admin'])\ndef update_earnings_setting():\n    \"\"\"Update earnings visibility setting\"\"\"\n    # Validate request has JSON content\n    if not request.is_json:\n        return jsonify({'success': False, 'error': 'Request must be JSON'}), 400\n    \n    data = request.get_json()\n    if not data:\n        return jsonify({'success': False, 'error': 'No data provided'}), 400\n    \n    show_earnings = data.get('show_earnings')\n    \n    # Strict validation of input values\n    if show_earnings is None:\n        return jsonify({'success': False, 'error': 'show_earnings field is required'}), 400\n    \n    if not isinstance(show_earnings, str) or show_earnings not in ['true', 'false']:\n        return jsonify({'success': False, 'error': 'Invalid value. Must be \"true\" or \"false\"'}), 400\n    \n    try:\n        set_app_setting('show_earnings', show_earnings, 'Whether to display earnings functionality throughout the application')\n        return jsonify({\n            'success': True, \n            'message': 'Settings updated successfully',\n            'show_earnings': show_earnings\n        })\n    except Exception as e:\n        app.logger.error(f\"Error updating earnings setting: {str(e)}\")\n        return jsonify({'success': False, 'error': 'Internal server error'}), 500\n\ndef create_demo_data(force=False):\n    \"\"\"Create demo users and initial data - Development only\"\"\"\n    if is_production and not force:\n        app.logger.warning(\"Attempted to create demo data in production - skipping\")\n        return\n        \n    try:\n        # Create demo users if they don't exist - matching init_data.sql exactly\n        demo_users = [\n            {'email': 'admin@demo.com', 'password': 'demo123', 'first_name': 'Demo', 'last_name': 'Admin', 'role': 'admin', 'gender': 'prefer-not-to-say', 'age_group': 'Adult (20–59)'},\n            {'email': 'provider@demo.com', 'password': 'demo123', 'first_name': 'Demo', 'last_name': 'Provider', 'role': 'provider', 'gender': 'female', 'age_group': 'Adult (20–59)'},\n            {'email': 'reviewer@demo.com', 'password': 'demo123', 'first_name': 'Demo', 'last_name': 'Reviewer', 'role': 'reviewer', 'gender': 'male', 'age_group': 'Adult (20–59)'},\n            {'email': 'john.provider@example.com', 'password': 'demo123', 'first_name': 'John', 'last_name': 'Smith', 'role': 'provider', 'gender': 'male', 'age_group': 'Teen (13–19)'},\n            {'email': 'maria.provider@example.com', 'password': 'demo123', 'first_name': 'Maria', 'last_name': 'Rodriguez', 'role': 'provider', 'gender': 'female', 'age_group': 'Elderly (60+)'},\n            {'email': 'male.child@demo.com', 'password': 'demo123', 'first_name': 'Alex', 'last_name': 'Johnson', 'role': 'provider', 'gender': 'male', 'age_group': 'Child (0–12)'},\n            {'email': 'male.teen@demo.com', 'password': 'demo123', 'first_name': 'Ryan', 'last_name': 'Davis', 'role': 'provider', 'gender': 'male', 'age_group': 'Teen (13–19)'},\n            {'email': 'male.adult@demo.com', 'password': 'demo123', 'first_name': 'Michael', 'last_name': 'Brown', 'role': 'provider', 'gender': 'male', 'age_group': 'Adult (20–59)'},\n            {'email': 'male.elderly@demo.com', 'password': 'demo123', 'first_name': 'Robert', 'last_name': 'Wilson', 'role': 'provider', 'gender': 'male', 'age_group': 'Elderly (60+)'},\n            {'email': 'female.child@demo.com', 'password': 'demo123', 'first_name': 'Emma', 'last_name': 'Taylor', 'role': 'provider', 'gender': 'female', 'age_group': 'Child (0–12)'},\n            {'email': 'female.teen@demo.com', 'password': 'demo123', 'first_name': 'Sophie', 'last_name': 'Anderson', 'role': 'provider', 'gender': 'female', 'age_group': 'Teen (13–19)'},\n            {'email': 'female.adult@demo.com', 'password': 'demo123', 'first_name': 'Jessica', 'last_name': 'Martinez', 'role': 'provider', 'gender': 'female', 'age_group': 'Adult (20–59)'},\n            {'email': 'female.elderly@demo.com', 'password': 'demo123', 'first_name': 'Margaret', 'last_name': 'Garcia', 'role': 'provider', 'gender': 'female', 'age_group': 'Elderly (60+)'}\n        ]\n        \n        for user_data in demo_users:\n            # Check if user exists by trying to query, but handle schema errors gracefully\n            try:\n                existing_user = User.query.filter_by(email=user_data['email']).first()\n            except Exception:\n                existing_user = None\n                \n            if not existing_user:\n                user = User(\n                    email=user_data['email'],\n                    first_name=user_data['first_name'],\n                    last_name=user_data['last_name'],\n                    role=user_data['role'],\n                    gender=user_data.get('gender', 'prefer-not-to-say'),\n                    age_group=user_data.get('age_group', 'Adult (20–59)'),\n                    auth_provider='local'  # Set default auth provider for demo users\n                )\n                user.set_password(user_data['password'])\n                db.session.add(user)\n        \n        # Create demo scripts - matching init_data.sql exactly\n        demo_scripts = [\n            {'content': 'Hello, my name is [Your Name] and I am from [Your Location]. I am excited to contribute to this voice data collection project.', 'language': 'en', 'is_active': True},\n            {'content': 'Today is a beautiful sunny day with clear blue skies. The temperature is perfect for outdoor activities.', 'language': 'en', 'is_active': True},\n            {'content': 'Once upon a time, in a land far away, there lived a wise old owl who helped all the forest animals solve their problems.', 'language': 'en', 'is_active': True},\n            {'content': 'Please read the following numbers clearly: 123, 456, 789, 1000, 2023, 15.5, 99.99, 0.01', 'language': 'en', 'is_active': True},\n            {'content': 'Artificial intelligence, machine learning, natural language processing, neural networks, deep learning, algorithm', 'language': 'en', 'is_active': True}\n        ]\n        \n        for script_data in demo_scripts:\n            try:\n                existing_script = Script.query.filter_by(content=script_data['content']).first()\n            except Exception:\n                existing_script = None\n                \n            if not existing_script:\n                script = Script(**script_data)\n                db.session.add(script)\n        \n        # Create demo languages with pricing - matching init_data.sql exactly\n        demo_languages = [\n            {'name': 'English', 'code': 'en', 'native_name': 'English', 'provider_rate': 0.01, 'reviewer_rate': 2.00, 'currency': 'USD'},\n            {'name': 'Spanish', 'code': 'es', 'native_name': 'Español', 'provider_rate': 0.012, 'reviewer_rate': 2.20, 'currency': 'USD'},\n            {'name': 'French', 'code': 'fr', 'native_name': 'Français', 'provider_rate': 0.013, 'reviewer_rate': 2.30, 'currency': 'USD'},\n            {'name': 'German', 'code': 'de', 'native_name': 'Deutsch', 'provider_rate': 0.014, 'reviewer_rate': 2.40, 'currency': 'USD'},\n            {'name': 'Bengali', 'code': 'bn', 'native_name': 'বাংলা', 'provider_rate': 0.015, 'reviewer_rate': 2.50, 'currency': 'USD'},\n            {'name': 'Hindi', 'code': 'hi', 'native_name': 'हिन्दी', 'provider_rate': 0.015, 'reviewer_rate': 2.50, 'currency': 'USD'},\n            {'name': 'Arabic', 'code': 'ar', 'native_name': 'العربية', 'provider_rate': 0.016, 'reviewer_rate': 2.60, 'currency': 'USD'},\n            {'name': 'Chinese', 'code': 'zh', 'native_name': '中文', 'provider_rate': 0.018, 'reviewer_rate': 2.80, 'currency': 'USD'},\n            {'name': 'Japanese', 'code': 'ja', 'native_name': '日本語', 'provider_rate': 0.020, 'reviewer_rate': 3.00, 'currency': 'USD'},\n            {'name': 'Korean', 'code': 'ko', 'native_name': '한국어', 'provider_rate': 0.020, 'reviewer_rate': 3.00, 'currency': 'USD'},\n        ]\n        \n        for lang_data in demo_languages:\n            try:\n                existing_language = Language.query.filter_by(code=lang_data['code']).first()\n            except Exception:\n                existing_language = None\n                \n            if not existing_language:\n                # Create language\n                language = Language(\n                    name=lang_data['name'],\n                    code=lang_data['code'],\n                    native_name=lang_data['native_name'],\n                    is_active=True\n                )\n                db.session.add(language)\n                \n                # Create corresponding pricing\n                pricing = PricingRate(\n                    language_code=lang_data['code'],\n                    provider_rate_per_word=lang_data['provider_rate'],\n                    reviewer_rate_per_submission=lang_data['reviewer_rate'],\n                    currency=lang_data['currency']\n                )\n                db.session.add(pricing)\n        \n        db.session.commit()\n        app.logger.info(\"Database initialized with demo data\")\n        \n    except Exception as e:\n        app.logger.error(f\"Error creating demo data: {e}\")\n        db.session.rollback()\n\n\n\n# Initialize database when the module is loaded (for both dev and production)\ndef init_database():\n    \"\"\"Initialize database with tables and demo data\"\"\"\n    with app.app_context():\n        try:\n            # Create tables if they don't exist\n            db.create_all()\n            app.logger.info(\"Database tables created successfully\")\n            \n            # Add missing columns to scripts table if they don't exist\n            migrate_scripts_table()\n            \n            # Only create demo data in development mode\n            if os.environ.get('FLASK_ENV') != 'production':\n                if User.query.count() == 0:\n                    create_demo_data()\n                    app.logger.info(\"Database initialized with demo data and Google OAuth support\")\n                else:\n                    app.logger.info(\"Database already contains data, skipping demo data creation\")\n            else:\n                app.logger.info(\"Production mode: Demo data creation skipped\")\n                \n        except Exception as e:\n            app.logger.error(f\"Database initialization error: {e}\")\n            if os.environ.get('FLASK_ENV') == 'production':\n                raise  # Fail fast in production\n\ndef migrate_scripts_table():\n    \"\"\"Add missing columns to scripts table\"\"\"\n    try:\n        # Check if title column exists by trying to query it\n        with db.engine.connect() as conn:\n            conn.execute(db.text('SELECT title FROM scripts LIMIT 1'))\n        print(\"📋 Scripts table already has new columns\")\n    except Exception:\n        print(\"🔧 Adding missing columns to scripts table...\")\n        try:\n            with db.engine.connect() as conn:\n                # Add missing columns\n                conn.execute(db.text('ALTER TABLE scripts ADD COLUMN title VARCHAR(255)'))\n                conn.execute(db.text('ALTER TABLE scripts ADD COLUMN category VARCHAR(100)'))  \n                conn.execute(db.text('ALTER TABLE scripts ADD COLUMN difficulty VARCHAR(50)'))\n                conn.execute(db.text('ALTER TABLE scripts ADD COLUMN target_duration INTEGER'))\n                conn.commit()\n            print(\"✅ Successfully added missing columns to scripts table\")\n        except Exception as e:\n            # Columns might already exist\n            print(f\"📋 Scripts table migration skipped (columns may already exist): {e}\")\n\n# Health check endpoint for Docker\n@app.route('/health', methods=['GET'])\ndef health_check():\n    \"\"\"Health check endpoint for Docker container monitoring\"\"\"\n    try:\n        # Test database connection\n        db.session.execute(db.text('SELECT 1'))\n        return jsonify({\n            'status': 'healthy',\n            'database': 'connected',\n            'timestamp': datetime.utcnow().isoformat()\n        }), 200\n    except Exception as e:\n        return jsonify({\n            'status': 'unhealthy',\n            'database': 'disconnected',\n            'error': str(e),\n            'timestamp': datetime.utcnow().isoformat()\n        }), 503\n\n# Production error handlers\n@app.errorhandler(404)\ndef not_found_error(error):\n    return render_template('404.html'), 404\n\n@app.errorhandler(500)\ndef internal_error(error):\n    db.session.rollback()\n    app.logger.error(f'Server Error: {error}')\n    return render_template('500.html'), 500\n\n@app.errorhandler(403)\ndef forbidden_error(error):\n    return render_template('403.html'), 403\n\n# Security headers for production\n@app.after_request\ndef after_request(response):\n    if is_production:\n        response.headers['X-Content-Type-Options'] = 'nosniff'\n        response.headers['X-Frame-Options'] = 'DENY'\n        response.headers['X-XSS-Protection'] = '1; mode=block'\n        response.headers['Strict-Transport-Security'] = 'max-age=31536000; includeSubDomains'\n    return response\n\n# Flask CLI Commands\n@app.cli.command('seed-demo')\n@click.option('--force', is_flag=True, help='Force recreation of demo data (clears existing demo data first)')\n@click.option('--yes', is_flag=True, help='Skip confirmation prompt in production')\ndef seed_demo_command(force, yes):\n    \"\"\"Seed database with demo data for development and testing.\"\"\"\n    \n    # Production safety check\n    if is_production:\n        if not yes:\n            app.logger.error(\"❌ Cannot seed demo data in production without --yes flag\")\n            app.logger.error(\"   Use: flask seed-demo --force --yes (if you really know what you're doing)\")\n            return\n        app.logger.warning(\"⚠️  Seeding demo data in PRODUCTION mode (--yes flag provided)\")\n    \n    with app.app_context():\n        try:\n            # If force flag is set, delete existing demo data first\n            if force:\n                app.logger.info(\"🗑️  Force flag set - removing existing demo data...\")\n                \n                # Delete demo users (by known email patterns)\n                demo_emails = [\n                    'provider@demo.com', 'reviewer@demo.com', 'admin@demo.com',\n                    'john.provider@example.com', 'maria.provider@example.com',\n                    'male.child@demo.com', 'male.teen@demo.com', 'male.adult@demo.com', 'male.elderly@demo.com',\n                    'female.child@demo.com', 'female.teen@demo.com', 'female.adult@demo.com', 'female.elderly@demo.com'\n                ]\n                deleted_users = User.query.filter(User.email.in_(demo_emails)).delete(synchronize_session=False)\n                \n                # Delete demo scripts (by known titles)\n                demo_titles = ['Introduction Script', 'Weather Description', 'Story Reading']\n                deleted_scripts = Script.query.filter(Script.title.in_(demo_titles)).delete(synchronize_session=False)\n                \n                db.session.commit()\n                app.logger.info(f\"   ✅ Deleted {deleted_users} demo users, {deleted_scripts} demo scripts\")\n            \n            # Count existing data before seeding\n            users_before = User.query.count()\n            scripts_before = Script.query.count()\n            languages_before = Language.query.count()\n            \n            # Create demo data\n            app.logger.info(\"🌱 Seeding demo data...\")\n            create_demo_data(force=True)  # Always run when using CLI command\n            \n            # Count after seeding\n            users_after = User.query.count()\n            scripts_after = Script.query.count()\n            languages_after = Language.query.count()\n            \n            # Summary\n            app.logger.info(\"✅ Demo data seeding completed successfully!\")\n            app.logger.info(f\"   📊 Users: {users_before} → {users_after} (+{users_after - users_before})\")\n            app.logger.info(f\"   📄 Scripts: {scripts_before} → {scripts_after} (+{scripts_after - scripts_before})\")\n            app.logger.info(f\"   🌍 Languages: {languages_before} → {languages_after} (+{languages_after - languages_before})\")\n            app.logger.info(\"\")\n            app.logger.info(\"🔑 Demo Accounts (all use password: demo123):\")\n            app.logger.info(\"   👤 provider@demo.com (Provider role)\")\n            app.logger.info(\"   👤 reviewer@demo.com (Reviewer role)\")\n            app.logger.info(\"   👤 admin@demo.com (Admin role)\")\n            \n        except Exception as e:\n            app.logger.error(f\"❌ Error seeding demo data: {e}\")\n            db.session.rollback()\n            raise\n\n@app.cli.command('migrate-field-collection')\ndef migrate_field_collection_command():\n    \"\"\"Add field collection columns to submissions table\"\"\"\n    with app.app_context():\n        try:\n            app.logger.info(\"🔄 Adding field collection columns to submissions table...\")\n            \n            # Add new columns to submissions table\n            with db.engine.connect() as conn:\n                # Make user_id nullable\n                conn.execute(text(\"ALTER TABLE submissions ALTER COLUMN user_id DROP NOT NULL\"))\n                conn.commit()\n                \n                # Add new columns if they don't exist\n                try:\n                    conn.execute(text(\"ALTER TABLE submissions ADD COLUMN collected_by_admin_id INTEGER REFERENCES users(id)\"))\n                    conn.commit()\n                except Exception:\n                    pass  # Column already exists\n                \n                try:\n                    conn.execute(text(\"ALTER TABLE submissions ADD COLUMN speaker_name VARCHAR(100)\"))\n                    conn.commit()\n                except Exception:\n                    pass\n                \n                try:\n                    conn.execute(text(\"ALTER TABLE submissions ADD COLUMN speaker_location VARCHAR(255)\"))\n                    conn.commit()\n                except Exception:\n                    pass\n                \n                try:\n                    conn.execute(text(\"ALTER TABLE submissions ADD COLUMN is_field_collection BOOLEAN DEFAULT FALSE\"))\n                    conn.commit()\n                except Exception:\n                    pass\n            \n            app.logger.info(\"✅ Field collection migration completed successfully!\")\n            \n        except Exception as e:\n            app.logger.error(f\"❌ Error during migration: {e}\")\n            raise\n\n# Initialize database on module load\ninit_database()\n\nif __name__ == '__main__':\n    # Direct execution mode - use proper WSGI server for production\n    port = int(os.environ.get('PORT', 8000))\n    \n    if is_production:\n        app.logger.warning(\"⚠️  Running with built-in server in production mode\")\n        app.logger.warning(\"⚠️  Use Gunicorn or similar WSGI server for production deployment\")\n        app.logger.info(f\"Starting VoiceScript Collector on port {port}\")\n    else:\n        app.logger.info(\"🔧 Starting in development mode\")\n        app.logger.info(f\"🚀 VoiceScript Collector: http://localhost:{port}\")\n        app.logger.info(\"👤 Demo Accounts: provider@demo.com, reviewer@demo.com, admin@demo.com (password: demo123)\")\n    \n    app.run(host='0.0.0.0', port=port, debug=not is_production)","size_bytes":98911},"deploy.sh":{"content":"#!/bin/bash\n\n# VoiceScript Collector - Local Deployment Script\n# This script sets up the application on your local machine\n\nset -e  # Exit on any error\n\necho \"🚀 VoiceScript Collector - Local Deployment\"\necho \"============================================\"\n\n# Check if Python 3 is installed\nif ! command -v python3 &> /dev/null; then\n    echo \"❌ Python 3 is required but not installed.\"\n    echo \"Please install Python 3.8+ and run this script again.\"\n    exit 1\nfi\n\n# Check Python version\nPYTHON_VERSION=$(python3 --version | cut -d' ' -f2 | cut -d'.' -f1-2)\necho \"✅ Python $PYTHON_VERSION detected\"\n\n# Create virtual environment if it doesn't exist\nif [ ! -d \"venv\" ]; then\n    echo \"📦 Creating virtual environment...\"\n    python3 -m venv venv\nfi\n\n# Activate virtual environment\necho \"🔄 Activating virtual environment...\"\nsource venv/bin/activate\n\n# Upgrade pip\necho \"⬆️  Upgrading pip...\"\npip install --upgrade pip\n\n# Install dependencies\necho \"📋 Installing Python dependencies...\"\npip install flask flask-sqlalchemy python-dotenv werkzeug gunicorn authlib requests\n\n# Create uploads directory\necho \"📁 Creating uploads directory...\"\nmkdir -p uploads\n\n# Set permissions for uploads directory\nchmod 755 uploads\n\n# Create .env file if it doesn't exist\nif [ ! -f \".env\" ]; then\n    echo \"⚙️  Creating .env configuration file...\"\n    cat > .env << EOF\n# VoiceScript Collector Configuration\nFLASK_ENV=production\nFLASK_DEBUG=False\nSECRET_KEY=$(python3 -c 'import secrets; print(secrets.token_hex(32))')\nDATABASE_URL=sqlite:///voicescript.db\nUPLOAD_FOLDER=uploads\nMAX_CONTENT_LENGTH=52428800\n\n# Google OAuth Configuration (optional - uncomment and configure to enable)\n# GOOGLE_CLIENT_ID=your-google-client-id.apps.googleusercontent.com\n# GOOGLE_CLIENT_SECRET=your-google-client-secret\nEOF\n    echo \"✅ .env file created with secure random secret key\"\nelse\n    echo \"✅ .env file already exists\"\nfi\n\n# Create systemd service file (optional)\necho \"🔧 Creating systemd service file...\"\ncat > voicescript-collector.service << EOF\n[Unit]\nDescription=VoiceScript Collector\nAfter=network.target\n\n[Service]\nType=simple\nUser=$USER\nWorkingDirectory=$(pwd)\nEnvironment=PATH=$(pwd)/venv/bin\nExecStart=$(pwd)/venv/bin/gunicorn --bind 0.0.0.0:8000 --workers 4 app:app\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\nEOF\n\n# Create startup script\necho \"📝 Creating startup script...\"\ncat > start.sh << 'EOF'\n#!/bin/bash\n# VoiceScript Collector Startup Script\n\n# Activate virtual environment\nsource venv/bin/activate\n\n# Load environment variables\nexport $(cat .env | grep -v '^#' | xargs)\n\necho \"🚀 Starting VoiceScript Collector...\"\necho \"📊 Dashboard will be available at: http://localhost:8000\"\necho \"👤 Demo Accounts:\"\necho \"   Provider: provider@demo.com / demo123\"\necho \"   Reviewer: reviewer@demo.com / demo123\"\necho \"   Admin:    admin@demo.com / demo123\"\necho \"\"\necho \"Press Ctrl+C to stop the server\"\necho \"\"\n\n# Start the application\npython app.py\nEOF\n\n# Make scripts executable\nchmod +x start.sh\nchmod +x deploy.sh\n\n# Initialize database and create demo data\necho \"🗄️  Initializing database...\"\nsource venv/bin/activate\nexport $(cat .env | grep -v '^#' | xargs)\npython3 -c \"\nfrom app import app, db, create_demo_data\nwith app.app_context():\n    db.create_all()\n    create_demo_data()\n    print('✅ Database initialized with demo data')\n\"\n\necho \"\"\necho \"🎉 Deployment Complete!\"\necho \"=======================\"\necho \"\"\necho \"To start the application:\"\necho \"  ./start.sh\"\necho \"\"\necho \"Or manually:\"\necho \"  source venv/bin/activate\"\necho \"  python app.py\"\necho \"\"\necho \"The application will be available at: http://localhost:8000\"\necho \"\"\necho \"Demo Accounts:\"\necho \"  Provider: provider@demo.com / demo123\"\necho \"  Reviewer: reviewer@demo.com / demo123\"\necho \"  Admin:    admin@demo.com / demo123\"\necho \"\"\necho \"For production deployment with systemd:\"\necho \"  sudo cp voicescript-collector.service /etc/systemd/system/\"\necho \"  sudo systemctl enable voicescript-collector\"\necho \"  sudo systemctl start voicescript-collector\"","size_bytes":4065},"ecosystem.config.js":{"content":"// PM2 Configuration for Production Deployment\nmodule.exports = {\n  apps: [{\n    name: 'voicescript-collector',\n    script: 'dist/index.js',\n    instances: 1,\n    exec_mode: 'cluster',\n    env: {\n      NODE_ENV: 'production',\n      PORT: 5000\n    },\n    error_file: './logs/err.log',\n    out_file: './logs/out.log',\n    log_file: './logs/combined.log',\n    time: true,\n    autorestart: true,\n    max_memory_restart: '1G',\n    watch: false,\n    ignore_watch: [\n      'node_modules',\n      'uploads',\n      'logs'\n    ]\n  }]\n};","size_bytes":525},"gunicorn.conf.py":{"content":"# Gunicorn configuration file for production deployment\nimport os\n\n# Server socket\nbind = \"0.0.0.0:8000\"\nbacklog = 2048\n\n# Worker processes\nworkers = 4\nworker_class = \"sync\"\nworker_connections = 1000\ntimeout = 120\nkeepalive = 2\n\n# Restart workers after this many requests, to prevent memory leaks\nmax_requests = 1000\nmax_requests_jitter = 50\n\n# Logging\naccesslog = \"-\"\nerrorlog = \"-\"\nloglevel = \"info\"\naccess_log_format = '%(h)s %(l)s %(u)s %(t)s \"%(r)s\" %(s)s %(b)s \"%(f)s\" \"%(a)s\"'\n\n# Process naming\nproc_name = \"voicescript-collector\"\n\n# Server mechanics\npreload_app = True\ndaemon = False\npidfile = \"/tmp/gunicorn.pid\"\n# Remove user/group settings for development environment compatibility\n# user = \"appuser\"  # Only use in Docker with proper user setup\n# group = \"appuser\"  # Only use in Docker with proper user setup\ntmp_upload_dir = None\n\n# SSL (if needed in production)\n# keyfile = None\n# certfile = None","size_bytes":911},"healthcheck.js":{"content":"// Simple health check for Docker container\nconst http = require('http');\n\nconst options = {\n  hostname: 'localhost',\n  port: process.env.PORT || 5000,\n  path: '/api/health',\n  timeout: 3000,\n  method: 'GET'\n};\n\nconst req = http.request(options, (res) => {\n  if (res.statusCode === 200) {\n    process.exit(0);\n  } else {\n    console.log(`Health check failed with status: ${res.statusCode}`);\n    process.exit(1);\n  }\n});\n\nreq.on('error', (err) => {\n  console.log(`Health check error: ${err.message}`);\n  process.exit(1);\n});\n\nreq.on('timeout', () => {\n  console.log('Health check timeout');\n  req.destroy();\n  process.exit(1);\n});\n\nreq.end();","size_bytes":642},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"authlib>=1.6.1\",\n    \"flask>=3.1.1\",\n    \"flask-sqlalchemy>=3.1.1\",\n    \"gunicorn>=23.0.0\",\n    \"psycopg2-binary>=2.9.10\",\n    \"pytest>=8.4.1\",\n    \"pytest-flask>=1.3.0\",\n    \"python-dotenv>=1.1.1\",\n    \"requests>=2.32.4\",\n    \"werkzeug>=3.1.3\",\n]\n","size_bytes":395},"replit.md":{"content":"# VoiceScript Collector - NLP Data Collection Platform\n\n## Overview\n\nVoiceScript Collector is a web-based platform designed to collect high-quality voice and text data for NLP training. The system supports a structured workflow involving data providers (who submit voice/text data), quality reviewers (who verify submissions), and administrators (who manage the platform). Built with a modern full-stack architecture using React, Express, and PostgreSQL.\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## System Architecture\n\n### Backend Architecture (Python Flask)\n- **Runtime**: Python 3.11 with Flask framework\n- **Template Engine**: Jinja2 for server-side rendering with Tailwind CSS\n- **Database ORM**: SQLAlchemy with SQLite (development) / PostgreSQL (production)\n- **Authentication**: Session-based authentication with Google OAuth integration\n- **Session Management**: Flask sessions with secure cookie configuration\n- **File Uploads**: Werkzeug secure file handling with validation\n- **Production Server**: Gunicorn WSGI server with multi-worker support\n\n### Database Design\n- **Primary Database**: SQLite (local development) / PostgreSQL (production)\n- **Schema Management**: SQLAlchemy automatic table creation with model definitions\n- **Key Tables**:\n  - `users`: User profiles with role-based access (provider/reviewer/admin)\n  - `scripts`: Pre-defined prompts for voice recording\n  - `submissions`: User-generated content (audio/text/combined)\n  - `reviews`: Quality assessments of submissions\n  - `billing_records`: Payment tracking for approved submissions\n  - `sessions`: Authentication session storage\n\n## Key Components\n\n### Authentication System\n- **Provider**: Local authentication with session management\n- **Session Storage**: In-memory sessions (configurable for PostgreSQL in production)\n- **Authorization**: Role-based access control (provider, reviewer, admin)\n- **Security**: Secure cookies with HTTP-only flags\n- **Demo Users**: Three test accounts for development (provider, reviewer, admin)\n- **Production**: Real user registration and email/password authentication\n\n### Data Collection Workflow\n1. **Admin Script Creation**: Administrators create recording scripts with prompts\n2. **Script Selection**: Users browse and select from available scripts\n3. **Voice Recording**: Users provide audio recordings (required) with optional text notes\n4. **Multi-Voice Collection**: Support for different voice types (men, women, children) per script\n5. **Quality Review**: Reviewers assess audio submissions for approval\n6. **Billing Integration**: Automatic payment calculation for approved recordings\n\n### File Management\n- **Audio Storage**: Local filesystem with Multer handling\n- **File Validation**: Audio file type and size restrictions (50MB limit)\n- **Security**: Controlled file access through API endpoints\n\n### UI Components\n- **Audio Recorder**: Custom component with MediaRecorder API integration\n- **Review Interface**: Comprehensive review tools with quality scoring\n- **Dashboard**: Role-specific views with statistics and recent activity\n- **Navigation**: Responsive navigation with role-based menu items\n\n### Mobile-First Responsive Design\n- **Hamburger Navigation**: Mobile menu with smooth animations and ARIA support\n  - ESC key and outside-click to close\n  - Auto-closes on navigation\n  - 44px minimum touch targets\n- **Responsive Tables**: Mobile card view and desktop table layout\n  - Provider dashboard submissions show as cards on mobile\n  - Full table view on tablets and desktops (768px+)\n- **Touch-Optimized UI**: Proper spacing and button sizes for mobile devices\n- **Error Pages**: Mobile-friendly 404, 403, and 500 error pages\n- **Viewport Configuration**: Proper meta tags for mobile scaling and accessibility\n\n## Data Flow\n\n### Submission Process\n1. User authenticates via Replit Auth\n2. User selects script or creates custom content\n3. Audio recording captured via WebRTC MediaRecorder\n4. Form data and audio file uploaded via multipart/form-data\n5. Submission stored in database with pending status\n6. Real-time UI updates via React Query cache invalidation\n\n### Review Process\n1. Reviewers access pending submissions queue\n2. Audio playback and content review interface\n3. Quality scoring and feedback submission\n4. Status updates (approved/rejected/correction requested)\n5. Billing record creation for approved submissions\n\n### Analytics and Reporting\n- User statistics (submission counts, earnings)\n- Platform metrics (approval rates, content volume)\n- Real-time dashboard updates\n\n## External Dependencies\n\n### Core Dependencies\n- **Flask**: Web framework for Python\n- **Flask-SQLAlchemy**: Database ORM integration\n- **python-dotenv**: Environment variable management\n- **Werkzeug**: WSGI utility library for file uploads\n- **Gunicorn**: Production WSGI server\n\n### Frontend Styling\n- **Tailwind CSS**: Utility-first CSS framework (via CDN)\n- **Font Awesome**: Icon library (via CDN)\n- **MediaRecorder API**: Browser-based audio recording\n\n### Authentication\n- **Flask Sessions**: Built-in session management with secure cookies\n- **SQLAlchemy**: Database models for user management\n\n## Deployment Strategy\n\n### Development Environment\n- **Dev Server**: Vite dev server with HMR for frontend\n- **Backend**: tsx for TypeScript execution with live reload\n- **Database**: Neon PostgreSQL with development branch\n- **File Storage**: Local filesystem for audio uploads\n\n### Production Build\n- **Frontend**: Vite production build with asset optimization\n- **Backend**: ESBuild bundling to single JavaScript file\n- **Database**: Neon PostgreSQL production instance\n- **Static Assets**: Served via Express static middleware\n\n### Environment Configuration\n- Database URL configuration via environment variables\n- Session secrets and authentication credentials\n- File upload directory configuration\n- Development vs production feature flags\n\n### Scalability Considerations\n- Database connection pooling via Neon serverless\n- React Query caching reduces API calls\n- Optimistic UI updates for better user experience\n- Role-based route protection and data access\n\n## Local Deployment Configuration\n\n### Production Build System\n- **Frontend Build**: Vite production build with asset optimization\n- **Backend Build**: ESBuild bundling for Node.js deployment\n- **Static Assets**: Express static middleware serves built frontend\n- **Process Management**: PM2 configuration for production deployment\n\n### Deployment Files\n- **README.md**: Comprehensive deployment guide with step-by-step instructions\n- **DEPLOYMENT_GUIDE.md**: Quick start guide for local deployment\n- **deploy.sh**: Automated deployment script with environment setup\n- **.env.example**: Template for environment configuration\n- **ecosystem.config.js**: PM2 configuration for process management\n- **docker-compose.yml**: PostgreSQL database setup via Docker\n- **Dockerfile**: Full application containerization (optional)\n- **healthcheck.js**: Application health monitoring endpoint\n\n### Local Machine Requirements\n- Node.js 18+ for modern JavaScript features\n- PostgreSQL 13+ for database operations\n- Proper file permissions for upload directory\n- Environment variables for database and session configuration\n\n### Security Features\n- Secure session management with configurable secrets\n- Database connection encryption\n- File upload restrictions and validation\n- Health check endpoint for monitoring\n- Production-ready error handling\n\n### Authentication System (Local)\n- Token-based authentication with local session storage\n- Demo user accounts for immediate testing\n- Role-based access control (admin, reviewer, provider)\n- Secure password handling and session management\n\n### Recent Changes (Latest - October 1, 2025)\n- ✅ **CASCADE DELETE SYSTEM**: Script deletion now removes all related recordings\n  - Deleting a script automatically deletes all associated submissions\n  - Audio files are removed from filesystem when submissions are deleted\n  - Works for both single script delete and bulk delete operations\n  - Provides feedback on number of submissions and files deleted\n- ✅ **ADMIN RECORDING DELETE**: Admins can delete individual recordings\n  - Delete button added to data export page for each recording\n  - Removes submission record and associated audio file\n  - Confirmation dialog prevents accidental deletions\n  - DELETE endpoint: `/api/submissions/<id>`\n- ✅ **DATA EXPORT SYSTEM**: Comprehensive data export functionality for ML training workflows\n  - New `/admin/data-export` page showing all recordings in sortable table\n  - CSV metadata export with complete recording information\n  - Statistics dashboard (total, approved, field-collected, user-submitted counts)\n  - Supports both field-collected and user-submitted recordings\n  - Export format: ID, Audio Filename, Script Content, Language, Demographics, Status, Timestamps\n  - Accessible via \"Export\" link in admin navigation (desktop + mobile)\n  \n### Previous Changes (September 30, 2025)\n- ✅ **FIELD COLLECTION AUTO-APPROVAL**: Admin field-collected recordings now auto-approve\n  - Field-collected submissions set to 'approved' status automatically\n  - Skip review queue for trusted admin-collected data\n  - Maintains quality workflow for user submissions\n- ✅ **SCRIPT SUBMISSIONS VIEWER**: Added comprehensive submissions tracking per script\n  - \"View Submissions\" button on admin scripts page\n  - Modal displays all recordings for each script (regular + field-collected)\n  - Shows submitter info, speaker metadata, status, and audio playback\n  - Distinguishes between user submissions and field-collected data\n- ✅ **MOBILE-FIRST RESPONSIVE DESIGN**: Implemented comprehensive mobile UI improvements\n  - Added hamburger navigation menu with ARIA accessibility support\n  - Implemented responsive table/card layouts (mobile cards, desktop tables)\n  - Added ESC key and outside-click to close mobile menu\n  - Created mobile-friendly error pages (404, 403, 500)\n  - Touch-optimized UI with 44px minimum touch targets\n  - Tested and verified across mobile (375px), tablet (768px), and desktop (1280px) viewports\n- ✅ **DOCKER SESSION FIX**: Fixed login redirect issue in Docker deployments\n  - Added USE_HTTPS environment variable to control secure cookie behavior\n  - Docker (HTTP) now works with USE_HTTPS=false\n  - HTTPS deployments can set USE_HTTPS=true for secure cookies\n- ✅ **SECURITY HARDENING**: Disabled fallback authentication in production\n  - Added ENABLE_WEBVIEW_FALLBACK flag (default: false)\n  - Fallback cookie/token auth only available in development mode\n  - Prevents privilege escalation via forged cookies in production\n- ✅ **COMPREHENSIVE DOCKER DOCUMENTATION**: Created DOCKER.md deployment guide\n  - Session configuration troubleshooting\n  - HTTPS reverse proxy setup guidance\n  - Security best practices for production\n  \n### Previous Changes (August 11, 2025)\n- ✅ **WORKFLOW DEBUGGING FIXED**: Resolved npm run dev failure by creating minimal package.json wrapper\n- ✅ **CODEBASE CLEANUP**: Removed unnecessary JavaScript/TypeScript files (client/, server/, shared/, config files)  \n- ✅ **PURE PYTHON ARCHITECTURE**: Restored clean Flask-only codebase without Node.js dependencies\n- ✅ **MINIMAL NODE SETUP**: Created simple package.json that runs Python Flask app via npm run dev\n- ✅ **APPLICATION STATUS**: Python Flask application running successfully on port 8000 with all features\n- → **STATUS**: Clean Python Flask application with minimal Node.js wrapper for workflow compatibility\n\n### Authentication Test Results - CONFIRMED WORKING\n- Test Client: ✅ Login 302 → Dashboard 200 (Working)\n- Session Data: ✅ {'user_id': 1, 'user_role': 'provider', 'user_name': 'Demo Provider'}  \n- Curl Tests: ✅ Login 302 → Dashboard 200 (Working)\n- Debug Output: ✅ Session properly stored and retrieved in Replit environment\n- **AUTHENTICATION SYSTEM CONFIRMED WORKING**: Session-based authentication working perfectly in local environment\n- **GOOGLE OAUTH ROUTES ADDED**: Complete Google login functionality with account linking and profile picture support\n- **PRODUCTION READY**: All core features implemented - recording, review workflow, billing, admin panel, multi-language support\n- **DEPLOYMENT READY**: Local deployment package complete with comprehensive documentation and setup scripts\n- **NOTE**: Replit webview has iframe session limitations (known issue) - application works perfectly when deployed locally","size_bytes":12492},"run.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nSimple runner for the VoiceScript Collector Flask application\n\"\"\"\n\nfrom app import app\n\nif __name__ == '__main__':\n    # Database is automatically initialized when app module is imported\n    app.run(\n        host='0.0.0.0',\n        port=5000,\n        debug=True\n    )","size_bytes":294},"start-production.sh":{"content":"#!/bin/bash\n\n# Production startup script using Gunicorn\necho \"🚀 Starting VoiceScript Collector in Production Mode\"\necho \"📊 Server will be available at: http://localhost:8000\"\necho \"👤 Demo Accounts: provider@demo.com, reviewer@demo.com, admin@demo.com (password: demo123)\"\necho \"\"\n\n# Set production environment\nexport FLASK_ENV=production\n\n# Start Gunicorn with configuration\nexec gunicorn --config gunicorn.conf.py app:app","size_bytes":431},"tests/__init__.py":{"content":"# Tests package for VoiceScript Collector","size_bytes":41},"tests/test_google_oauth.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nGoogle OAuth Integration Tests\nTests Google authentication flow and user account linking\n\"\"\"\n\nimport unittest\nfrom unittest.mock import Mock, patch, MagicMock\nimport json\nfrom app import app, db, User\n\nclass GoogleOAuthTestCase(unittest.TestCase):\n    \"\"\"Test Google OAuth integration\"\"\"\n    \n    def setUp(self):\n        \"\"\"Set up test environment\"\"\"\n        app.config['TESTING'] = True\n        app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///:memory:'\n        app.config['WTF_CSRF_ENABLED'] = False\n        app.config['GOOGLE_CLIENT_ID'] = 'test_client_id'\n        app.config['GOOGLE_CLIENT_SECRET'] = 'test_client_secret'\n        \n        self.app = app.test_client()\n        self.app_context = app.app_context()\n        self.app_context.push()\n        \n        db.create_all()\n        \n        # Create existing user for account linking test\n        self.existing_user = User(\n            email='existing@test.com',\n            first_name='Existing',\n            last_name='User',\n            role='provider',\n            auth_provider='local'\n        )\n        self.existing_user.set_password('testpass')\n        db.session.add(self.existing_user)\n        db.session.commit()\n    \n    def tearDown(self):\n        \"\"\"Clean up\"\"\"\n        db.session.remove()\n        db.drop_all()\n        self.app_context.pop()\n    \n    def test_google_login_redirect(self):\n        \"\"\"Test Google login initiates OAuth redirect\"\"\"\n        with patch('app.google') as mock_google:\n            mock_google.authorize_redirect.return_value = Mock()\n            rv = self.app.get('/login/google')\n            mock_google.authorize_redirect.assert_called_once()\n    \n    def test_google_login_without_config(self):\n        \"\"\"Test Google login when not configured\"\"\"\n        # Temporarily remove Google config\n        app.config['GOOGLE_CLIENT_ID'] = None\n        \n        rv = self.app.get('/login/google', follow_redirects=True)\n        self.assertEqual(rv.status_code, 200)\n        self.assertIn(b'not configured', rv.data)\n        \n        # Restore config\n        app.config['GOOGLE_CLIENT_ID'] = 'test_client_id'\n    \n    @patch('app.google')\n    def test_google_callback_new_user(self, mock_google):\n        \"\"\"Test Google callback creates new user\"\"\"\n        # Mock Google token response\n        mock_token = {\n            'userinfo': {\n                'sub': 'google_user_123',\n                'email': 'newuser@gmail.com',\n                'given_name': 'New',\n                'family_name': 'User',\n                'picture': 'https://example.com/pic.jpg'\n            }\n        }\n        mock_google.authorize_access_token.return_value = mock_token\n        \n        rv = self.app.get('/callback/google', follow_redirects=True)\n        self.assertEqual(rv.status_code, 200)\n        \n        # Verify user was created\n        new_user = User.query.filter_by(email='newuser@gmail.com').first()\n        self.assertIsNotNone(new_user)\n        self.assertEqual(new_user.google_id, 'google_user_123')\n        self.assertEqual(new_user.auth_provider, 'google')\n        self.assertEqual(new_user.role, 'provider')  # Default role\n        self.assertIsNotNone(new_user.profile_picture)\n    \n    @patch('app.google')\n    def test_google_callback_account_linking(self, mock_google):\n        \"\"\"Test Google callback links to existing account\"\"\"\n        # Mock Google token for existing user email\n        mock_token = {\n            'userinfo': {\n                'sub': 'google_user_456',\n                'email': 'existing@test.com',\n                'given_name': 'Existing',\n                'family_name': 'User',\n                'picture': 'https://example.com/newpic.jpg'\n            }\n        }\n        mock_google.authorize_access_token.return_value = mock_token\n        \n        rv = self.app.get('/callback/google', follow_redirects=True)\n        self.assertEqual(rv.status_code, 200)\n        \n        # Verify existing user was updated with Google info\n        updated_user = User.query.filter_by(email='existing@test.com').first()\n        self.assertEqual(updated_user.google_id, 'google_user_456')\n        self.assertEqual(updated_user.auth_provider, 'google')\n        self.assertEqual(updated_user.profile_picture, 'https://example.com/newpic.jpg')\n    \n    @patch('app.google')\n    def test_google_callback_existing_google_user(self, mock_google):\n        \"\"\"Test Google callback for returning Google user\"\"\"\n        # Create existing Google user\n        google_user = User(\n            email='googleuser@gmail.com',\n            first_name='Google',\n            last_name='User',\n            role='provider',\n            google_id='existing_google_123',\n            auth_provider='google'\n        )\n        db.session.add(google_user)\n        db.session.commit()\n        \n        # Mock returning user token\n        mock_token = {\n            'userinfo': {\n                'sub': 'existing_google_123',\n                'email': 'googleuser@gmail.com',\n                'given_name': 'Google',\n                'family_name': 'User',\n                'picture': 'https://example.com/pic.jpg'\n            }\n        }\n        mock_google.authorize_access_token.return_value = mock_token\n        \n        rv = self.app.get('/callback/google', follow_redirects=True)\n        self.assertEqual(rv.status_code, 200)\n        \n        # Verify user count didn't increase (no duplicate created)\n        users = User.query.filter_by(email='googleuser@gmail.com').all()\n        self.assertEqual(len(users), 1)\n    \n    @patch('app.google')\n    def test_google_callback_error_handling(self, mock_google):\n        \"\"\"Test Google callback error handling\"\"\"\n        # Mock OAuth error\n        mock_google.authorize_access_token.side_effect = Exception(\"OAuth error\")\n        \n        rv = self.app.get('/callback/google', follow_redirects=True)\n        self.assertEqual(rv.status_code, 200)\n        self.assertIn(b'authentication failed', rv.data)\n    \n    @patch('app.google')\n    def test_google_callback_without_config(self, mock_google):\n        \"\"\"Test Google callback when not configured\"\"\"\n        app.config['GOOGLE_CLIENT_ID'] = None\n        \n        rv = self.app.get('/callback/google', follow_redirects=True)\n        self.assertEqual(rv.status_code, 200)\n        self.assertIn(b'not configured', rv.data)\n        \n        # Restore config\n        app.config['GOOGLE_CLIENT_ID'] = 'test_client_id'\n    \n    def test_user_model_oauth_fields(self):\n        \"\"\"Test User model OAuth-specific fields\"\"\"\n        user = User(\n            email='oauth@test.com',\n            first_name='OAuth',\n            last_name='User',\n            role='provider',\n            google_id='oauth_123',\n            profile_picture='https://example.com/pic.jpg',\n            auth_provider='google'\n        )\n        \n        # OAuth users don't need password\n        self.assertIsNone(user.password_hash)\n        self.assertFalse(user.check_password('anypassword'))\n        \n        # But can still be saved\n        db.session.add(user)\n        db.session.commit()\n        \n        saved_user = User.query.filter_by(email='oauth@test.com').first()\n        self.assertIsNotNone(saved_user)\n        self.assertEqual(saved_user.google_id, 'oauth_123')\n        self.assertEqual(saved_user.auth_provider, 'google')\n\nif __name__ == '__main__':\n    unittest.main()","size_bytes":7347},"db/migrate.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nDatabase migration script for VoiceScript Collector\nHandles migration from SQLite to PostgreSQL and schema updates\n\"\"\"\n\nimport os\nimport sys\nimport psycopg2\nimport sqlite3\nfrom datetime import datetime\nfrom werkzeug.security import generate_password_hash\n\ndef get_db_connection():\n    \"\"\"Get PostgreSQL database connection\"\"\"\n    database_url = os.environ.get('DATABASE_URL')\n    if not database_url:\n        print(\"❌ DATABASE_URL environment variable not found\")\n        sys.exit(1)\n    \n    try:\n        conn = psycopg2.connect(database_url)\n        return conn\n    except Exception as e:\n        print(f\"❌ Failed to connect to PostgreSQL: {e}\")\n        sys.exit(1)\n\ndef run_sql_file(conn, filename):\n    \"\"\"Execute SQL commands from a file\"\"\"\n    try:\n        with open(filename, 'r') as file:\n            sql_content = file.read()\n        \n        cursor = conn.cursor()\n        cursor.execute(sql_content)\n        conn.commit()\n        cursor.close()\n        print(f\"✅ Successfully executed {filename}\")\n        \n    except Exception as e:\n        print(f\"❌ Error executing {filename}: {e}\")\n        conn.rollback()\n        return False\n    return True\n\ndef create_schema(conn):\n    \"\"\"Create database schema\"\"\"\n    print(\"🏗️  Creating database schema...\")\n    return run_sql_file(conn, 'schema.sql')\n\ndef init_demo_data(conn):\n    \"\"\"Initialize demo data\"\"\"\n    print(\"📊 Initializing demo data...\")\n    return run_sql_file(conn, 'init_data.sql')\n\ndef migrate_from_sqlite():\n    \"\"\"Migrate existing data from SQLite to PostgreSQL\"\"\"\n    sqlite_path = 'instance/voicescript.db'\n    \n    if not os.path.exists(sqlite_path):\n        print(\"ℹ️  No existing SQLite database found, skipping migration\")\n        return True\n    \n    print(\"📦 Migrating data from SQLite...\")\n    \n    pg_conn = get_db_connection()\n    sqlite_conn = sqlite3.connect(sqlite_path)\n    sqlite_conn.row_factory = sqlite3.Row\n    \n    try:\n        # Migrate users (with new fields defaulted)\n        sqlite_cursor = sqlite_conn.cursor()\n        sqlite_cursor.execute(\"SELECT * FROM user\")\n        users = sqlite_cursor.fetchall()\n        \n        pg_cursor = pg_conn.cursor()\n        for user in users:\n            # Insert user with default gender and age_group\n            pg_cursor.execute(\"\"\"\n                INSERT INTO users (id, email, password_hash, first_name, last_name, role, \n                                 google_id, profile_picture, auth_provider, gender, age_group, created_at)\n                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n                ON CONFLICT (email) DO NOTHING\n            \"\"\", (\n                user['id'], user['email'], user['password_hash'], \n                user['first_name'], user['last_name'], user['role'],\n                user.get('google_id'), user.get('profile_picture'), \n                user.get('auth_provider', 'local'),\n                'prefer-not-to-say',  # Default gender\n                'Adult (20–59)',      # Default age group\n                user.get('created_at', datetime.utcnow())\n            ))\n        \n        # Migrate scripts\n        sqlite_cursor.execute(\"SELECT * FROM script\")\n        scripts = sqlite_cursor.fetchall()\n        \n        for script in scripts:\n            pg_cursor.execute(\"\"\"\n                INSERT INTO scripts (id, title, content, language, category, is_active, created_at)\n                VALUES (%s, %s, %s, %s, %s, %s, %s)\n                ON CONFLICT DO NOTHING\n            \"\"\", (\n                script['id'], script['title'], script['content'],\n                script.get('language', 'en'), script.get('category'),\n                script.get('is_active', True), script.get('created_at', datetime.utcnow())\n            ))\n        \n        # Migrate submissions\n        sqlite_cursor.execute(\"SELECT * FROM submission\")\n        submissions = sqlite_cursor.fetchall()\n        \n        for submission in submissions:\n            pg_cursor.execute(\"\"\"\n                INSERT INTO submissions (id, user_id, script_id, text_content, audio_filename,\n                                       status, created_at, reviewed_at, reviewed_by, review_notes,\n                                       quality_score, word_count, duration)\n                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n                ON CONFLICT DO NOTHING\n            \"\"\", (\n                submission['id'], submission['user_id'], submission.get('script_id'),\n                submission.get('text_content'), submission['audio_filename'],\n                submission.get('status', 'pending'), submission.get('created_at'),\n                submission.get('reviewed_at'), submission.get('reviewed_by'),\n                submission.get('review_notes'), submission.get('quality_score'),\n                submission.get('word_count', 0), submission.get('duration', 0.0)\n            ))\n        \n        pg_conn.commit()\n        pg_cursor.close()\n        \n        print(\"✅ Data migration completed successfully\")\n        return True\n        \n    except Exception as e:\n        print(f\"❌ Error during migration: {e}\")\n        pg_conn.rollback()\n        return False\n    finally:\n        sqlite_conn.close()\n        pg_conn.close()\n\ndef main():\n    \"\"\"Main migration function\"\"\"\n    print(\"🚀 Starting database migration to PostgreSQL...\")\n    \n    # Get PostgreSQL connection\n    conn = get_db_connection()\n    \n    try:\n        # Create schema\n        if not create_schema(conn):\n            print(\"❌ Schema creation failed\")\n            return False\n        \n        # Initialize demo data\n        if not init_demo_data(conn):\n            print(\"❌ Demo data initialization failed\")\n            return False\n        \n        # Migrate existing SQLite data if present\n        if not migrate_from_sqlite():\n            print(\"❌ Data migration failed\")\n            return False\n        \n        print(\"✅ Database migration completed successfully!\")\n        print(\"🎉 PostgreSQL database is ready for production use\")\n        \n    finally:\n        conn.close()\n\nif __name__ == '__main__':\n    main()","size_bytes":6116},"README-Docker.md":{"content":"# VoiceScript Collector - Docker PostgreSQL Setup\n\n## Overview\n\nYour VoiceScript Collector application has been fully dockerized with PostgreSQL database support. The setup includes:\n\n- **PostgreSQL 15** database container\n- **Flask application** container with Gunicorn\n- **Docker Compose** orchestration\n- **Health checks** for both services\n- **Production-ready** configuration\n\n## Quick Start\n\n1. **Clone/Download** your codebase to a local machine with Docker installed\n\n2. **Build and run** the containers:\n   ```bash\n   docker-compose up --build\n   ```\n\n3. **Access the application**:\n   - Application: http://localhost:8000\n   - Health Check: http://localhost:8000/health\n\n## Configuration Files Created\n\n### 1. `docker-compose.yml`\n- PostgreSQL service with persistent volume\n- Flask application service\n- Network configuration\n- Health checks for both services\n- Environment variable management\n\n### 2. Updated `Dockerfile`\n- Multi-stage build for optimization\n- PostgreSQL client libraries\n- Production Gunicorn configuration\n- Port 8000 exposure\n- Security best practices (non-root user)\n\n### 3. `gunicorn.conf.py` (Updated)\n- Bind to 0.0.0.0:8000\n- 4 worker processes\n- Request timeout: 120 seconds\n- Production logging\n\n### 4. `.env.docker` (Template)\n- PostgreSQL connection settings\n- Flask production configuration\n- Google OAuth placeholders\n\n### 5. Health Check Endpoint\n- `/health` endpoint added to Flask app\n- Tests database connectivity\n- Used by Docker health checks\n\n## Database Configuration\n\nThe application now uses PostgreSQL by default when running in Docker:\n\n```\nDATABASE_URL=postgresql://voicescript_user:voicescript_password@postgres:5432/voicescript_db\n```\n\n### Database Features:\n- **Persistent storage** with Docker volumes\n- **Connection pooling** for stability\n- **Health monitoring** with automatic retries\n- **Automatic schema migration** on startup\n\n## Environment Variables\n\n### Required:\n- `DATABASE_URL` - PostgreSQL connection string\n- `SECRET_KEY` - Flask secret key for sessions\n\n### Optional:\n- `GOOGLE_CLIENT_ID` - For Google OAuth\n- `GOOGLE_CLIENT_SECRET` - For Google OAuth\n- `FLASK_ENV` - Set to 'production' for Docker\n\n## Services\n\n### PostgreSQL Service (`postgres`)\n- **Image**: postgres:15-alpine\n- **Database**: voicescript_db\n- **User**: voicescript_user\n- **Password**: voicescript_password\n- **Port**: 5432 (mapped to host)\n- **Volume**: postgres_data (persistent)\n\n### Web Service (`web`)\n- **Build**: From local Dockerfile\n- **Port**: 8000 (mapped to host)\n- **Depends on**: PostgreSQL service\n- **Restart**: unless-stopped\n- **User**: appuser (non-root)\n\n## Commands\n\n### Start services:\n```bash\ndocker-compose up\n```\n\n### Start in background:\n```bash\ndocker-compose up -d\n```\n\n### Rebuild and start:\n```bash\ndocker-compose up --build\n```\n\n### Stop services:\n```bash\ndocker-compose down\n```\n\n### View logs:\n```bash\ndocker-compose logs web\ndocker-compose logs postgres\n```\n\n### Access database:\n```bash\ndocker-compose exec postgres psql -U voicescript_user -d voicescript_db\n```\n\n## Production Deployment\n\nFor production deployment:\n\n1. **Update environment variables** in `.env.docker`\n2. **Change default passwords** for security\n3. **Configure SSL/TLS** if needed\n4. **Set up backup strategy** for PostgreSQL data\n5. **Configure reverse proxy** (nginx/Apache) if needed\n\n## Data Migration from SQLite\n\nIf you have existing SQLite data to migrate:\n\n1. **Export data** from SQLite using Python scripts\n2. **Import data** to PostgreSQL using the Flask shell\n3. **Or use migration tools** like pgloader\n\n## Troubleshooting\n\n### Database Connection Issues:\n- Check if PostgreSQL container is healthy: `docker-compose ps`\n- View PostgreSQL logs: `docker-compose logs postgres`\n- Verify environment variables are set correctly\n\n### Application Issues:\n- Check application logs: `docker-compose logs web`\n- Verify health endpoint: `curl http://localhost:8000/health`\n- Ensure port 8000 is not in use by other services\n\n### Performance:\n- Adjust Gunicorn workers in `gunicorn.conf.py`\n- Monitor resource usage: `docker stats`\n- Scale services if needed: `docker-compose up --scale web=3`\n\n## Development vs Production\n\n- **Development**: Run `python run.py` locally with SQLite\n- **Production**: Use Docker Compose with PostgreSQL\n- **Testing**: Run containers locally before deployment\n\nYour application is now fully dockerized and PostgreSQL-ready! 🐳","size_bytes":4413},"DOCKER.md":{"content":"# Docker Deployment Guide\n\n## Quick Start\n\n### Prerequisites\n- Docker and Docker Compose installed\n- 2GB+ free disk space\n\n### Standard Deployment (HTTP - Local Access)\n\n1. **Clone/Download the repository**\n\n2. **Build and start the containers:**\n   ```bash\n   docker-compose up -d\n   ```\n\n3. **Seed demo data:**\n   ```bash\n   docker exec -it voicescript_app flask seed-demo --force\n   ```\n\n4. **Access the application:**\n   - Local: http://localhost:8000\n   - Network: http://[YOUR_IP]:8000\n\n### Demo Login\n- Provider: http://localhost:8000/login?demo=provider\n- Reviewer: http://localhost:8000/login?demo=reviewer\n- Admin: http://localhost:8000/login?demo=admin\n\nOr use the login form:\n- Email: `provider@demo.com` / Password: `demo123`\n- Email: `reviewer@demo.com` / Password: `demo123`\n- Email: `admin@demo.com` / Password: `demo123`\n\n## Environment Configuration\n\n### Session Security (Important!)\n\nThe application uses different session configurations based on whether HTTPS is available:\n\n**For HTTP deployments (Docker local):**\n- Set `USE_HTTPS=false` (default)\n- Sessions work over HTTP for local testing\n\n**For HTTPS deployments (production with SSL):**\n- Set `USE_HTTPS=true`\n- Enables secure cookies (HTTPS only)\n\n### Configuration Files\n\n#### `.env.docker` - Default configuration\n```env\nDATABASE_URL=postgresql://voicescript_user:voicescript_password@postgres:5432/voicescript_db\nFLASK_ENV=production\nSECRET_KEY=production-secret-key-change-this-in-production\nUSE_HTTPS=false  # Set to true if using HTTPS/SSL\nENABLE_WEBVIEW_FALLBACK=false  # MUST be false in production for security\n```\n\n#### `docker-compose.yml` - Environment variables\n```yaml\nenvironment:\n  - DATABASE_URL=postgresql://voicescript_user:voicescript_password@postgres:5432/voicescript_db\n  - FLASK_ENV=production\n  - SECRET_KEY=production-secret-key-change-this-in-production\n  - USE_HTTPS=false  # Change to true for HTTPS\n```\n\n## Production HTTPS Setup\n\nIf deploying behind an HTTPS proxy (nginx, Traefik, etc.):\n\n1. **Update environment variables:**\n   ```yaml\n   environment:\n     - USE_HTTPS=true\n     - SECRET_KEY=your-strong-secret-key-here\n   ```\n\n2. **Configure your reverse proxy to forward:**\n   - `X-Forwarded-Proto: https`\n   - `X-Forwarded-For: client_ip`\n\n3. **Example nginx configuration:**\n   ```nginx\n   location / {\n       proxy_pass http://localhost:8000;\n       proxy_set_header X-Forwarded-Proto https;\n       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n       proxy_set_header Host $host;\n   }\n   ```\n\n## Database Management\n\n### Seed Demo Data\n```bash\n# Seed demo data (13 users, 5 scripts, 10 languages)\ndocker exec -it voicescript_app flask seed-demo\n\n# Force recreate demo data\ndocker exec -it voicescript_app flask seed-demo --force\n```\n\n### Database Backup\n```bash\n# Backup PostgreSQL database\ndocker exec voicescript_postgres pg_dump -U voicescript_user voicescript_db > backup.sql\n\n# Restore backup\ndocker exec -i voicescript_postgres psql -U voicescript_user voicescript_db < backup.sql\n```\n\n### Access PostgreSQL CLI\n```bash\ndocker exec -it voicescript_postgres psql -U voicescript_user -d voicescript_db\n```\n\n## Container Management\n\n### View Logs\n```bash\n# All containers\ndocker-compose logs -f\n\n# Specific container\ndocker-compose logs -f web\ndocker-compose logs -f postgres\n```\n\n### Stop/Start\n```bash\n# Stop containers\ndocker-compose down\n\n# Start containers\ndocker-compose up -d\n\n# Rebuild after code changes\ndocker-compose up -d --build\n```\n\n### Clean Restart\n```bash\n# Remove containers and volumes (DELETES DATA!)\ndocker-compose down -v\n\n# Rebuild from scratch\ndocker-compose up -d --build\n\n# Seed demo data again\ndocker exec -it voicescript_app flask seed-demo --force\n```\n\n## Troubleshooting\n\n### Login Redirects to Index Page\n\n**Problem:** Demo login or regular login redirects back to index/login page instead of dashboard.\n\n**Solution:** Ensure `USE_HTTPS=false` is set in your environment if accessing via HTTP:\n\n```yaml\n# docker-compose.yml\nenvironment:\n  - USE_HTTPS=false  # MUST be false for HTTP access\n```\n\n**Why this happens:** \n- When `USE_HTTPS=true`, the app sets secure cookies requiring HTTPS\n- Accessing via HTTP (http://localhost:8000) won't send secure cookies\n- Session fails, causing login redirects\n\n### Microphone Not Working\n\n**Problem:** Audio recording doesn't work in browser.\n\n**Solution:** Use `https://` or `localhost` for microphone access:\n- ✅ Works: `https://yourdomain.com` or `http://localhost:8000`\n- ❌ Fails: `http://192.168.1.100:8000` (use HTTPS for network access)\n\n### Container Health Checks Failing\n\n```bash\n# Check container status\ndocker-compose ps\n\n# View detailed health logs\ndocker inspect voicescript_app | grep -A 20 Health\n```\n\n### Database Connection Issues\n\n```bash\n# Check if PostgreSQL is ready\ndocker exec voicescript_postgres pg_isready -U voicescript_user\n\n# Verify connection from app container\ndocker exec voicescript_app flask db-check\n```\n\n### Port Already in Use\n\n```bash\n# Change port in docker-compose.yml\nports:\n  - \"9000:8000\"  # Access via localhost:9000\n```\n\n## File Persistence\n\nDocker volumes persist data between container restarts:\n\n```yaml\nvolumes:\n  - ./uploads:/app/uploads    # Audio files\n  - ./logs:/app/logs          # Application logs\n  - postgres_data:/var/lib/postgresql/data  # Database\n```\n\nTo completely reset:\n```bash\ndocker-compose down -v  # Removes volumes\nrm -rf uploads/ logs/   # Removes local files\n```\n\n## Security Best Practices\n\n1. **Change default secrets:**\n   - Generate strong `SECRET_KEY`: `openssl rand -hex 32`\n   - Update PostgreSQL password in both `.env.docker` and `docker-compose.yml`\n\n2. **Use HTTPS in production:**\n   - Set `USE_HTTPS=true`\n   - Configure SSL termination with nginx/Traefik\n\n3. **Restrict database access:**\n   - Don't expose PostgreSQL port publicly\n   - Use firewall rules to limit access\n\n4. **Regular backups:**\n   - Schedule automated database backups\n   - Store backups securely off-server\n\n## Network Configuration\n\n### Access from Other Devices\n\nThe app is accessible on your local network:\n\n1. Find your machine's IP:\n   ```bash\n   # Linux/macOS\n   ip addr show | grep inet\n   \n   # Windows\n   ipconfig\n   ```\n\n2. Access from other devices:\n   ```\n   http://[YOUR_IP]:8000\n   ```\n\n**Note:** Microphone access requires HTTPS or localhost. Use HTTPS for network access.\n\n## Performance Tuning\n\n### Gunicorn Workers\nAdjust worker count in `gunicorn.conf.py`:\n```python\nworkers = 4  # Recommended: (2 x CPU cores) + 1\n```\n\n### PostgreSQL Connection Pool\nAdjust in `app.py`:\n```python\n'pool_size': 10,      # Increase for high traffic\n'max_overflow': 20,   # Additional connections\n```\n\n### Resource Limits\nAdd to `docker-compose.yml`:\n```yaml\ndeploy:\n  resources:\n    limits:\n      cpus: '2'\n      memory: 1G\n```\n\n## Monitoring\n\n### Health Endpoints\n```bash\n# Application health\ncurl http://localhost:8000/health\n\n# Database health\ncurl http://localhost:8000/db-health\n```\n\n### Container Stats\n```bash\ndocker stats voicescript_app voicescript_postgres\n```\n\n## Upgrading\n\n1. **Backup data:**\n   ```bash\n   docker exec voicescript_postgres pg_dump -U voicescript_user voicescript_db > backup.sql\n   ```\n\n2. **Pull latest changes:**\n   ```bash\n   git pull  # or download latest release\n   ```\n\n3. **Rebuild containers:**\n   ```bash\n   docker-compose down\n   docker-compose up -d --build\n   ```\n\n4. **Verify:**\n   ```bash\n   docker-compose logs -f\n   ```\n\n## Support\n\nFor issues:\n1. Check container logs: `docker-compose logs -f`\n2. Verify environment variables: `docker exec voicescript_app env`\n3. Test database connection: `docker exec voicescript_app flask db-check`\n4. Review this guide for common issues\n","size_bytes":7689},"DOCKER_UPDATE_INSTRUCTIONS.md":{"content":"# Docker Login Fix - Update Instructions\n\n## What Was Fixed\n\nYour Docker deployment had a session configuration issue causing login redirects. This has been **completely fixed** with two important changes:\n\n### 1. Session Cookie Configuration (Login Fix)\n- **Problem**: Secure cookies required HTTPS, but Docker runs on HTTP\n- **Solution**: Added `USE_HTTPS=false` environment variable\n- **Result**: Sessions now work correctly on HTTP (localhost:8000)\n\n### 2. Security Hardening (Critical)\n- **Problem**: Fallback authentication allowed privilege escalation via forged cookies\n- **Solution**: Added `ENABLE_WEBVIEW_FALLBACK=false` to disable insecure fallback auth\n- **Result**: Production deployments are now secure\n\n## How to Update Your Docker Deployment\n\n### Option 1: Pull Latest Changes (Recommended)\n\n```bash\n# Stop containers\ndocker-compose down\n\n# Pull latest code\ngit pull  # or re-download the latest version\n\n# Rebuild and start\ndocker-compose up -d --build\n\n# Seed demo data\ndocker exec -it voicescript_app flask seed-demo --force\n```\n\n### Option 2: Manual Configuration Update\n\nIf you can't pull new code, manually update these files:\n\n#### 1. Update `docker-compose.yml`\nAdd these two environment variables:\n\n```yaml\nenvironment:\n  - DATABASE_URL=postgresql://voicescript_user:voicescript_password@postgres:5432/voicescript_db\n  - FLASK_ENV=production\n  - SECRET_KEY=production-secret-key-change-this-in-production\n  - USE_HTTPS=false           # ADD THIS LINE\n  - ENABLE_WEBVIEW_FALLBACK=false  # ADD THIS LINE\n```\n\n#### 2. Update `.env.docker`\nAdd these two lines:\n\n```env\nUSE_HTTPS=false\nENABLE_WEBVIEW_FALLBACK=false\n```\n\n#### 3. Rebuild and Restart\n\n```bash\ndocker-compose down\ndocker-compose up -d --build\n```\n\n## Verify It's Working\n\n### Test Demo Login\nVisit these URLs to test each role:\n- Provider: http://localhost:8000/login?demo=provider\n- Reviewer: http://localhost:8000/login?demo=reviewer\n- Admin: http://localhost:8000/login?demo=admin\n\n**Expected Result**: You should be taken directly to the appropriate dashboard (no redirect loop)\n\n### Test Regular Login\n1. Go to: http://localhost:8000\n2. Click \"Login\"\n3. Enter: `provider@demo.com` / `demo123`\n4. **Expected Result**: Redirected to Provider Dashboard\n\n## Important Configuration Notes\n\n### USE_HTTPS Flag\n- **For HTTP (local Docker)**: `USE_HTTPS=false` (default)\n- **For HTTPS (production with SSL)**: `USE_HTTPS=true`\n\n### ENABLE_WEBVIEW_FALLBACK Flag\n- **Must be `false` in production** (security requirement)\n- **Only set to `true` in development** if using Replit webview\n\n## Production HTTPS Setup\n\nIf deploying with HTTPS (nginx, Traefik, etc.):\n\n1. **Set environment variables:**\n   ```yaml\n   environment:\n     - USE_HTTPS=true\n     - ENABLE_WEBVIEW_FALLBACK=false\n     - SECRET_KEY=your-strong-secret-key\n   ```\n\n2. **Configure reverse proxy:**\n   ```nginx\n   location / {\n       proxy_pass http://localhost:8000;\n       proxy_set_header X-Forwarded-Proto https;\n       proxy_set_header Host $host;\n   }\n   ```\n\n## Security Best Practices\n\n1. ✅ Always keep `ENABLE_WEBVIEW_FALLBACK=false` in production\n2. ✅ Use `USE_HTTPS=true` only when actually running on HTTPS\n3. ✅ Change `SECRET_KEY` to a strong random value\n4. ✅ Update PostgreSQL password in production\n\n## Troubleshooting\n\n### Still Getting Login Redirects?\n\n1. **Verify environment variables:**\n   ```bash\n   docker exec voicescript_app env | grep -E \"(USE_HTTPS|ENABLE_WEBVIEW_FALLBACK)\"\n   ```\n   Should show:\n   ```\n   USE_HTTPS=false\n   ENABLE_WEBVIEW_FALLBACK=false\n   ```\n\n2. **Check container logs:**\n   ```bash\n   docker-compose logs -f web\n   ```\n\n3. **Rebuild from scratch:**\n   ```bash\n   docker-compose down -v\n   docker-compose up -d --build\n   docker exec -it voicescript_app flask seed-demo --force\n   ```\n\n### Microphone Not Working?\n\nUse `https://` or `localhost` for microphone access:\n- ✅ Works: `http://localhost:8000`\n- ❌ Fails: `http://192.168.1.100:8000` (use HTTPS for network access)\n\n## Complete Documentation\n\nFor comprehensive Docker deployment guide, see:\n- **DOCKER.md** - Full Docker deployment and troubleshooting guide\n- **README.md** - General application documentation\n- **replit.md** - Technical architecture and recent changes\n\n## Questions?\n\nIf you encounter issues:\n1. Check logs: `docker-compose logs -f`\n2. Review DOCKER.md for detailed troubleshooting\n3. Verify environment variables are set correctly\n4. Ensure you're using the latest version of the code\n","size_bytes":4469},"SECURITY_PUBLIC_DEPLOYMENT.md":{"content":"# Secure Public Deployment Guide\n\n## ⚠️ CRITICAL: Your Current Setup is NOT Secure\n\nIf your application is accessible via a public IP from the internet, you **MUST** follow this guide to secure it properly.\n\n### Current Risks (with USE_HTTPS=false on public IP):\n- 🔴 **Passwords transmitted in plaintext** - anyone on the network can intercept them\n- 🔴 **Session cookies not secure** - vulnerable to session hijacking\n- 🔴 **Database exposed** - port 5432 open to brute force attacks\n- 🔴 **No encryption** - all application traffic visible to attackers\n\n---\n\n## 🛡️ Secure Deployment (HTTPS with Let's Encrypt)\n\n### Prerequisites\n\n1. **Domain name** pointing to your server's public IP\n   - Required for Let's Encrypt SSL certificate\n   - Configure DNS A record: `example.com` → `Your Public IP`\n   - Configure DNS A record: `www.example.com` → `Your Public IP`\n\n2. **Server requirements**\n   - Public IP address\n   - Ports 80 and 443 accessible from internet\n   - Docker and Docker Compose installed\n   - Root/sudo access for firewall configuration\n\n3. **Close dangerous ports**\n   - Port 8000 (Flask) must NOT be exposed\n   - Port 5432 (PostgreSQL) must NOT be exposed\n\n---\n\n## 🚀 Automated HTTPS Setup (Recommended)\n\n### Step 1: Prepare\n\n```bash\n# Stop current insecure deployment\ndocker-compose down\n\n# Make setup script executable\nchmod +x setup-https.sh\n```\n\n### Step 2: Run Setup Script\n\n```bash\n# Run with sudo (needed for firewall)\nsudo ./setup-https.sh\n```\n\nThe script will:\n1. ✅ Generate strong SECRET_KEY and database password\n2. ✅ Configure nginx with your domain\n3. ✅ Set up Let's Encrypt SSL certificate\n4. ✅ Configure firewall (block 8000, 5432; allow 22, 80, 443)\n5. ✅ Deploy secure Docker stack\n6. ✅ Enable automatic SSL renewal\n\n### Step 3: Verify\n\nVisit your domain:\n- `https://your-domain.com` → Should load securely (🔒 in browser)\n- `http://your-domain.com` → Should redirect to HTTPS\n\nTest demo login:\n- `https://your-domain.com/login?demo=provider`\n\n---\n\n## 🔧 Manual HTTPS Setup\n\nIf you prefer manual setup:\n\n### 1. Create Secure Environment File\n\n```bash\n# Generate strong SECRET_KEY\nopenssl rand -hex 32\n\n# Generate database password\nopenssl rand -hex 16\n\n# Create .env file\ncat > .env << EOF\nPOSTGRES_PASSWORD=<generated-password>\nSECRET_KEY=<generated-secret-key>\nFLASK_ENV=production\nUSE_HTTPS=true\nENABLE_WEBVIEW_FALLBACK=false\nDOMAIN=your-domain.com\nEMAIL=admin@your-domain.com\nEOF\n```\n\n### 2. Update Nginx Configuration\n\nEdit `nginx/conf.d/voicescript.conf`:\n- Replace `your-domain.com` with your actual domain (3 places)\n\n### 3. Configure Firewall\n\n```bash\n# UFW (Ubuntu/Debian)\nsudo ufw enable\nsudo ufw default deny incoming\nsudo ufw allow 22/tcp    # SSH\nsudo ufw allow 80/tcp    # HTTP (Let's Encrypt)\nsudo ufw allow 443/tcp   # HTTPS\nsudo ufw deny 8000/tcp   # Block Flask\nsudo ufw deny 5432/tcp   # Block PostgreSQL\nsudo ufw status\n\n# Firewalld (RHEL/CentOS)\nsudo firewall-cmd --permanent --add-service=ssh\nsudo firewall-cmd --permanent --add-service=http\nsudo firewall-cmd --permanent --add-service=https\nsudo firewall-cmd --permanent --add-port=8000/tcp --remove\nsudo firewall-cmd --permanent --add-port=5432/tcp --remove\nsudo firewall-cmd --reload\n```\n\n### 4. Start Secure Stack\n\n```bash\n# Create directories\nmkdir -p certbot/conf certbot/www nginx/conf.d uploads logs\n\n# Start services\ndocker-compose -f docker-compose-secure.yml up -d --build\n```\n\n### 5. Obtain SSL Certificate\n\n```bash\n# Test with dry run first\ndocker-compose -f docker-compose-secure.yml run --rm certbot certonly \\\n    --webroot -w /var/www/certbot \\\n    --email your@email.com \\\n    --agree-tos --no-eff-email \\\n    --dry-run \\\n    -d your-domain.com -d www.your-domain.com\n\n# If successful, get real certificate\ndocker-compose -f docker-compose-secure.yml run --rm certbot certonly \\\n    --webroot -w /var/www/certbot \\\n    --email your@email.com \\\n    --agree-tos --no-eff-email \\\n    -d your-domain.com -d www.your-domain.com\n\n# Reload nginx\ndocker-compose -f docker-compose-secure.yml exec nginx nginx -s reload\n```\n\n### 6. Seed Demo Data\n\n```bash\ndocker exec -it voicescript_app flask seed-demo --force\n```\n\n---\n\n## 🔒 Security Checklist\n\n### Required Security Measures:\n\n- [ ] **HTTPS enabled** via Let's Encrypt or commercial SSL\n- [ ] **USE_HTTPS=true** in environment variables\n- [ ] **Strong SECRET_KEY** (32+ random characters)\n- [ ] **Strong database password** (16+ random characters)\n- [ ] **Firewall configured** (only 22, 80, 443 allowed)\n- [ ] **Port 8000 blocked** from internet (Flask internal only)\n- [ ] **Port 5432 blocked** from internet (DB internal only)\n- [ ] **ENABLE_WEBVIEW_FALLBACK=false** (no fallback auth)\n- [ ] **HSTS header enabled** (in nginx config)\n- [ ] **Secure cookies enabled** (automatic with USE_HTTPS=true)\n\n### Recommended Additional Security:\n\n- [ ] **Fail2ban** installed and configured for SSH\n- [ ] **Regular backups** automated (database + uploads)\n- [ ] **Log monitoring** configured\n- [ ] **Rate limiting** enabled for login endpoints (in nginx)\n- [ ] **Google OAuth** configured with HTTPS redirect URIs\n- [ ] **Security headers** enabled (CSP, X-Frame-Options, etc.)\n- [ ] **Regular updates** of Docker images and system packages\n- [ ] **Monitoring** setup (Prometheus, Grafana, etc.)\n\n---\n\n## 🔍 Verification Steps\n\n### 1. Check HTTPS is Working\n\n```bash\n# Should return 200 with HTTPS\ncurl -I https://your-domain.com\n\n# Should redirect to HTTPS\ncurl -I http://your-domain.com\n```\n\n### 2. Verify Ports are Secured\n\n```bash\n# From external machine - these should FAIL:\ncurl http://your-ip:8000     # Should timeout/refuse\ncurl http://your-ip:5432     # Should timeout/refuse\n\n# From external machine - these should WORK:\ncurl https://your-domain.com  # Should return 200\n```\n\n### 3. Test SSL Certificate\n\nVisit: https://www.ssllabs.com/ssltest/analyze.html?d=your-domain.com\n\nShould get A or A+ rating.\n\n### 4. Verify Session Security\n\n1. Login to your app via HTTPS\n2. Open browser DevTools → Application → Cookies\n3. Verify session cookie has:\n   - `Secure`: ✅ (checked)\n   - `HttpOnly`: ✅ (checked)\n   - `SameSite`: `Lax` or `Strict`\n\n---\n\n## 🔄 Maintenance\n\n### SSL Certificate Renewal\n\nCertificates auto-renew via the certbot container every 12 hours.\n\nManual renewal:\n```bash\ndocker-compose -f docker-compose-secure.yml run --rm certbot renew\ndocker-compose -f docker-compose-secure.yml exec nginx nginx -s reload\n```\n\n### Backup Important Data\n\n```bash\n# Backup database\ndocker exec voicescript_postgres pg_dump -U voicescript_user voicescript_db > backup.sql\n\n# Backup uploads\ntar -czf uploads_backup.tar.gz uploads/\n\n# Backup configuration\ncp .env .env.backup\n```\n\n### View Logs\n\n```bash\n# All services\ndocker-compose -f docker-compose-secure.yml logs -f\n\n# Specific service\ndocker-compose -f docker-compose-secure.yml logs -f nginx\ndocker-compose -f docker-compose-secure.yml logs -f web\n```\n\n### Restart Services\n\n```bash\n# Restart all\ndocker-compose -f docker-compose-secure.yml restart\n\n# Restart specific service\ndocker-compose -f docker-compose-secure.yml restart nginx\n```\n\n---\n\n## ⚠️ Common Mistakes to Avoid\n\n1. **❌ Using USE_HTTPS=false on public IP**\n   - Exposes passwords and sessions to attackers\n\n2. **❌ Exposing ports 8000 or 5432 to internet**\n   - Direct access to Flask or PostgreSQL is dangerous\n\n3. **❌ Weak SECRET_KEY**\n   - Use minimum 32 random characters\n\n4. **❌ Not configuring firewall**\n   - Always block unnecessary ports\n\n5. **❌ Using self-signed certificates in production**\n   - Browsers will show warnings, OAuth will fail\n\n6. **❌ Forgetting to update OAuth redirect URIs**\n   - Update Google OAuth to use https://your-domain.com/callback/google\n\n---\n\n## 🆘 Troubleshooting\n\n### SSL Certificate Issues\n\n**Problem**: Certificate not issued\n```bash\n# Check Let's Encrypt logs\ndocker-compose -f docker-compose-secure.yml logs certbot\n\n# Verify DNS is pointing to your server\nnslookup your-domain.com\n\n# Check port 80 is accessible\ncurl -I http://your-domain.com/.well-known/acme-challenge/test\n```\n\n### Firewall Blocking Everything\n\n```bash\n# Check firewall status\nsudo ufw status verbose\n\n# Reset if needed (CAUTION: may lock you out via SSH!)\nsudo ufw reset\nsudo ufw allow 22/tcp  # Allow SSH first!\nsudo ufw enable\n```\n\n### Sessions Still Not Working\n\n1. Verify USE_HTTPS=true in container:\n   ```bash\n   docker exec voicescript_app env | grep USE_HTTPS\n   ```\n\n2. Check nginx is forwarding headers:\n   ```bash\n   docker-compose -f docker-compose-secure.yml logs nginx | grep X-Forwarded\n   ```\n\n3. Clear browser cookies and try again\n\n---\n\n## 📚 Additional Resources\n\n- **Let's Encrypt Documentation**: https://letsencrypt.org/docs/\n- **Nginx SSL Configuration**: https://ssl-config.mozilla.org/\n- **SSL Test**: https://www.ssllabs.com/ssltest/\n- **Security Headers**: https://securityheaders.com/\n\n---\n\n## 🚨 Emergency Rollback\n\nIf something goes wrong:\n\n```bash\n# Stop secure deployment\ndocker-compose -f docker-compose-secure.yml down\n\n# Start basic deployment (INSECURE - local only!)\ndocker-compose up -d\n\n# Access at http://localhost:8000\n```\n\n**Note**: Only use insecure deployment for local testing, never on public IP!\n","size_bytes":9223},"setup-https.sh":{"content":"#!/bin/bash\n\n# VoiceScript Collector - HTTPS Setup Script\n# This script sets up secure HTTPS deployment with Let's Encrypt\n\nset -e  # Exit on any error\n\necho \"=========================================\"\necho \"VoiceScript Collector - HTTPS Setup\"\necho \"=========================================\"\necho \"\"\n\n# Check if running as root\nif [ \"$EUID\" -ne 0 ]; then \n    echo \"⚠️  This script needs sudo privileges for firewall configuration\"\n    echo \"Please run with: sudo ./setup-https.sh\"\n    exit 1\nfi\n\n# Check prerequisites\necho \"📋 Checking prerequisites...\"\nif ! command -v docker &> /dev/null; then\n    echo \"❌ Docker is not installed. Please install Docker first.\"\n    exit 1\nfi\n\nif ! command -v docker-compose &> /dev/null; then\n    echo \"❌ Docker Compose is not installed. Please install Docker Compose first.\"\n    exit 1\nfi\n\n# Get domain and email (from arguments or prompt)\nif [ -n \"$1\" ] && [ -n \"$2\" ]; then\n    DOMAIN=\"$1\"\n    EMAIL=\"$2\"\n    echo \"\"\n    echo \"📝 Using provided configuration:\"\n    echo \"   Domain: $DOMAIN\"\n    echo \"   Email: $EMAIL\"\nelse\n    echo \"\"\n    echo \"📝 Configuration\"\n    echo \"----------------------------------------\"\n    read -p \"Enter your domain name (e.g., example.com): \" DOMAIN\n    read -p \"Enter your email for SSL notifications: \" EMAIL\n    \n    if [ -z \"$DOMAIN\" ] || [ -z \"$EMAIL\" ]; then\n        echo \"❌ Domain and email are required!\"\n        exit 1\n    fi\nfi\n\n# Generate strong SECRET_KEY\necho \"\"\necho \"🔐 Generating secure SECRET_KEY...\"\nSECRET_KEY=$(openssl rand -hex 32)\n\n# Generate strong database password\nPOSTGRES_PASSWORD=$(openssl rand -hex 16)\n\n# Create .env file\necho \"\"\necho \"📄 Creating .env file...\"\ncat > .env << EOF\n# SECURE PRODUCTION CONFIGURATION\nPOSTGRES_PASSWORD=$POSTGRES_PASSWORD\nSECRET_KEY=$SECRET_KEY\nFLASK_ENV=production\nUSE_HTTPS=true\nENABLE_WEBVIEW_FALLBACK=false\nDOMAIN=$DOMAIN\nEMAIL=$EMAIL\nEOF\n\necho \"✅ .env file created with secure credentials\"\n\n# Update nginx configuration with domain\necho \"\"\necho \"🔧 Configuring nginx with your domain...\"\n# Mac-compatible sed command\nif [[ \"$OSTYPE\" == \"darwin\"* ]]; then\n    sed -i '' \"s/YOUR_DOMAIN_HERE/$DOMAIN/g\" nginx/conf.d/voicescript.conf\nelse\n    sed -i \"s/YOUR_DOMAIN_HERE/$DOMAIN/g\" nginx/conf.d/voicescript.conf\nfi\necho \"✅ Nginx configured for $DOMAIN\"\n\n# Create required directories\necho \"\"\necho \"📁 Creating required directories...\"\nmkdir -p uploads logs\nchmod -R 755 uploads logs\necho \"✅ Directories created\"\n\n# Create Docker volumes for certbot (avoids permission issues)\necho \"📦 Creating Docker volumes for SSL certificates...\"\ndocker volume create certbot_conf 2>/dev/null || true\ndocker volume create certbot_www 2>/dev/null || true\necho \"✅ Docker volumes ready\"\n\n# Configure firewall\necho \"\"\necho \"🔥 Configuring firewall...\"\necho \"This will:\"\necho \"  - Allow ports 22 (SSH), 80 (HTTP), 443 (HTTPS)\"\necho \"  - Block ports 8000 (Flask) and 5432 (PostgreSQL)\"\necho \"\"\nread -p \"Configure firewall? (y/n): \" -n 1 -r\necho\nif [[ $REPLY =~ ^[Yy]$ ]]; then\n    if command -v ufw &> /dev/null; then\n        ufw --force enable\n        ufw default deny incoming\n        ufw default allow outgoing\n        ufw allow 22/tcp comment 'SSH'\n        ufw allow 80/tcp comment 'HTTP'\n        ufw allow 443/tcp comment 'HTTPS'\n        ufw deny 8000/tcp comment 'Block Flask'\n        ufw deny 5432/tcp comment 'Block PostgreSQL'\n        ufw status\n        echo \"✅ Firewall configured with UFW\"\n    else\n        echo \"⚠️  UFW not found. Please configure firewall manually:\"\n        echo \"   - Allow: 22, 80, 443\"\n        echo \"   - Block: 8000, 5432\"\n    fi\nfi\n\n# Obtain SSL certificate FIRST (before starting nginx)\necho \"\"\necho \"🔒 Obtaining SSL certificate from Let's Encrypt...\"\necho \"Getting certificate before starting nginx...\"\n\n# Stop any running containers\ndocker-compose -f docker-compose-secure.yml down 2>/dev/null || true\n\n# Get certificate using standalone mode (nginx not running yet)\n# Use Docker-managed volumes to avoid permission issues\ndocker run --rm -p 80:80 -p 443:443 \\\n    -v certbot_conf:/etc/letsencrypt \\\n    -v certbot_www:/var/www/certbot \\\n    certbot/certbot certonly --standalone \\\n    -d $DOMAIN \\\n    --email $EMAIL \\\n    --agree-tos \\\n    --no-eff-email \\\n    --non-interactive\n\nif [ $? -eq 0 ]; then\n    echo \"✅ SSL certificate obtained successfully!\"\n    \n    # Verify certificate exists in Docker volume\n    echo \"🔍 Verifying certificate in Docker volume...\"\n    docker run --rm -v certbot_conf:/etc/letsencrypt \\\n        alpine ls -la /etc/letsencrypt/live/$DOMAIN/fullchain.pem 2>/dev/null\n    \n    if [ $? -ne 0 ]; then\n        echo \"❌ Certificate files not found in Docker volume!\"\n        echo \"Checking what's in the volume...\"\n        docker run --rm -v certbot_conf:/etc/letsencrypt alpine ls -la /etc/letsencrypt/\n        exit 1\n    fi\n    echo \"✅ Certificate verified in volume\"\nelse\n    echo \"❌ Failed to obtain SSL certificate. Please check:\"\n    echo \"   - Domain DNS points to this server\"\n    echo \"   - Ports 80 and 443 are accessible from internet\"\n    echo \"   - No other service is using ports 80/443\"\n    exit 1\nfi\n\n# NOW start services with certificate in place\necho \"\"\necho \"🚀 Starting services...\"\ndocker-compose -f docker-compose-secure.yml up -d --build\n\necho \"⏳ Waiting for services to be ready...\"\nsleep 10\n\n# Seed demo data\necho \"\"\necho \"📊 Seeding demo data...\"\ndocker exec -it voicescript_app flask seed-demo --force\n\n# Final status\necho \"\"\necho \"=========================================\"\necho \"✅ HTTPS Setup Complete!\"\necho \"=========================================\"\necho \"\"\necho \"🌐 Your application is now accessible at:\"\necho \"   https://$DOMAIN\"\necho \"\"\necho \"🔐 Security Status:\"\necho \"   ✅ HTTPS enabled with Let's Encrypt\"\necho \"   ✅ Secure cookies enabled\"\necho \"   ✅ Database not exposed to internet\"\necho \"   ✅ Flask app not exposed to internet\"\necho \"   ✅ Firewall configured\"\necho \"\"\necho \"📝 Credentials saved in .env file\"\necho \"   Keep this file secure and backup!\"\necho \"\"\necho \"📊 Demo Accounts:\"\necho \"   Provider: https://$DOMAIN/login?demo=provider\"\necho \"   Reviewer: https://$DOMAIN/login?demo=reviewer\"\necho \"   Admin: https://$DOMAIN/login?demo=admin\"\necho \"\"\necho \"🔧 Useful Commands:\"\necho \"   View logs:     docker-compose -f docker-compose-secure.yml logs -f\"\necho \"   Stop:          docker-compose -f docker-compose-secure.yml down\"\necho \"   Restart:       docker-compose -f docker-compose-secure.yml restart\"\necho \"   Renew cert:    docker-compose -f docker-compose-secure.yml run --rm certbot renew\"\necho \"\"\necho \"⚠️  Important Security Reminders:\"\necho \"   1. Keep your SECRET_KEY secure (in .env file)\"\necho \"   2. SSL certificate renews automatically every 12 hours\"\necho \"   3. Backup your database regularly\"\necho \"   4. Monitor access logs for suspicious activity\"\necho \"\"\n","size_bytes":6889},"INSTALLATION.md":{"content":"# VoiceScript Collector - Installation Guide\n\n## 📋 Prerequisites\n\nBefore you begin, ensure you have:\n\n- **Server with public IP** (Ubuntu 20.04+ or similar Linux distribution)\n- **Docker** and **Docker Compose** installed\n- **Domain name** pointing to your server's public IP (e.g., from DuckDNS, Freenom, or any registrar)\n- **Ports 80 and 443** accessible from the internet\n- **Root/sudo access** for firewall configuration\n\n---\n\n## 🚀 Quick Start (Automated Setup)\n\n### Step 1: Download the Codebase\n\n```bash\n# Clone or download the repository\ncd /path/to/voicescript-collector\n```\n\n### Step 2: Clean Any Previous Installation\n\n```bash\n# Stop any running containers\ndocker-compose down\ndocker-compose -f docker-compose-secure.yml down\n\n# Remove old database volume (if exists)\ndocker volume rm voicescript_postgres_data 2>/dev/null || true\n\n# Clean up old certificates\nrm -rf certbot/conf/* certbot/www/*\n```\n\n### Step 3: Make Setup Script Executable\n\n```bash\nchmod +x setup-https.sh\n```\n\n### Step 4: Run Automated HTTPS Setup\n\n```bash\nsudo ./setup-https.sh\n```\n\nWhen prompted, enter:\n- **Your domain name** (e.g., `textgather.duckdns.org`)\n- **Your email address** (for SSL certificate notifications)\n\nThe script will automatically:\n1. ✅ Generate secure SECRET_KEY and database password\n2. ✅ Create `.env` file with production settings\n3. ✅ Configure nginx for your domain\n4. ✅ Set up firewall rules (allow 22, 80, 443; block 8000, 5432)\n5. ✅ Obtain Let's Encrypt SSL certificate\n6. ✅ Start all services securely\n7. ✅ Seed demo data\n\n### Step 5: Access Your Application\n\nVisit: `https://your-domain.com`\n\n**Demo Accounts:**\n- Provider: `https://your-domain.com/login?demo=provider`\n- Reviewer: `https://your-domain.com/login?demo=reviewer`\n- Admin: `https://your-domain.com/login?demo=admin`\n\n**All demo accounts use password:** `demo123`\n\n---\n\n## 🔧 Manual Installation (Step-by-Step)\n\nIf you prefer manual setup or the automated script fails:\n\n### Step 1: Clean Installation\n\n```bash\n# Stop all containers\ndocker-compose down\ndocker-compose -f docker-compose-secure.yml down\n\n# Remove old volumes\ndocker volume rm voicescript_postgres_data 2>/dev/null || true\n\n# Create required directories\nmkdir -p certbot/conf certbot/www nginx/conf.d uploads logs\nchmod 755 uploads logs\n```\n\n### Step 2: Generate Secure Credentials\n\n```bash\n# Generate strong SECRET_KEY (copy the output)\nopenssl rand -hex 32\n\n# Generate database password (copy the output)\nopenssl rand -hex 16\n```\n\n### Step 3: Create .env File\n\n```bash\ncat > .env << 'EOF'\n# Database Configuration\nPOSTGRES_PASSWORD=PASTE_GENERATED_PASSWORD_HERE\n\n# Flask Configuration\nSECRET_KEY=PASTE_GENERATED_SECRET_KEY_HERE\nFLASK_ENV=production\n\n# Security Settings\nUSE_HTTPS=true\nENABLE_WEBVIEW_FALLBACK=false\n\n# Domain Configuration\nDOMAIN=your-domain.com\nEMAIL=your@email.com\n\n# Google OAuth (Optional - leave empty if not using)\nGOOGLE_CLIENT_ID=\nGOOGLE_CLIENT_SECRET=\nEOF\n```\n\n**Replace:**\n- `PASTE_GENERATED_PASSWORD_HERE` with your database password\n- `PASTE_GENERATED_SECRET_KEY_HERE` with your secret key\n- `your-domain.com` with your actual domain\n- `your@email.com` with your email\n\n### Step 4: Update Nginx Configuration\n\n```bash\n# Replace placeholder domain with your actual domain\nsed -i 's/your-domain\\.com/your-actual-domain.com/g' nginx/conf.d/voicescript.conf\n```\n\n### Step 5: Configure Firewall\n\n**For UFW (Ubuntu/Debian):**\n```bash\nsudo ufw enable\nsudo ufw default deny incoming\nsudo ufw default allow outgoing\nsudo ufw allow 22/tcp    # SSH\nsudo ufw allow 80/tcp    # HTTP (for Let's Encrypt)\nsudo ufw allow 443/tcp   # HTTPS\nsudo ufw deny 8000/tcp   # Block Flask port\nsudo ufw deny 5432/tcp   # Block PostgreSQL port\nsudo ufw status\n```\n\n**For Firewalld (RHEL/CentOS):**\n```bash\nsudo firewall-cmd --permanent --add-service=ssh\nsudo firewall-cmd --permanent --add-service=http\nsudo firewall-cmd --permanent --add-service=https\nsudo firewall-cmd --reload\n```\n\n### Step 6: Obtain SSL Certificate (Standalone Method)\n\n```bash\n# Get certificate before starting nginx\ndocker run --rm -p 80:80 \\\n  -v \"$PWD/certbot/conf:/etc/letsencrypt\" \\\n  -v \"$PWD/certbot/www:/var/www/certbot\" \\\n  certbot/certbot certonly --standalone \\\n  -d your-domain.com -d www.your-domain.com \\\n  --email your@email.com \\\n  --agree-tos --no-eff-email\n```\n\n**Replace:**\n- `your-domain.com` with your actual domain\n- `your@email.com` with your email\n\n### Step 7: Start Secure Deployment\n\n```bash\n# Start all services\ndocker-compose -f docker-compose-secure.yml up -d --build\n\n# Wait for services to be ready\nsleep 10\n\n# Seed demo data\ndocker exec -it voicescript_app flask seed-demo --force\n```\n\n### Step 8: Verify Installation\n\n```bash\n# Check all containers are running\ndocker-compose -f docker-compose-secure.yml ps\n\n# Check logs for any errors\ndocker-compose -f docker-compose-secure.yml logs web\ndocker-compose -f docker-compose-secure.yml logs nginx\n```\n\n---\n\n## 🔍 Testing Your Installation\n\n### From External Network (Mobile/Another Computer)\n\nVisit: `https://your-domain.com`\n\n**You should see:**\n- 🔒 Secure padlock in browser\n- VoiceScript Collector landing page\n- No security warnings\n\n### SSL Certificate Validation\n\nTest your SSL setup:\n```bash\n# Check certificate\ncurl -I https://your-domain.com\n\n# Or use online tool\n# Visit: https://www.ssllabs.com/ssltest/analyze.html?d=your-domain.com\n```\n\n### Session Cookie Security\n\n1. Login via HTTPS\n2. Open DevTools → Application → Cookies\n3. Verify session cookie has:\n   - ✅ `Secure` flag checked\n   - ✅ `HttpOnly` flag checked\n   - ✅ `SameSite` set to `Lax`\n\n---\n\n## ⚠️ Common Issues & Solutions\n\n### Issue 1: \"Rejected request from RFC1918 IP to public server address\"\n\n**Cause:** You're accessing your public domain from the same local network (NAT loopback issue)\n\n**Solutions:**\n- ✅ Test from external network (mobile with cellular data)\n- ✅ Access locally via `http://localhost:8000` or `http://192.168.x.x:8000`\n- ✅ Enable NAT loopback/hairpinning on your router\n\n### Issue 2: Database Connection Failed\n\n**Cause:** Old database volume has different password than `.env` file\n\n**Solution:**\n```bash\n# Clean restart\ndocker-compose -f docker-compose-secure.yml down\ndocker volume rm voicescript_postgres_data\ndocker-compose -f docker-compose-secure.yml up -d --build\ndocker exec -it voicescript_app flask seed-demo --force\n```\n\n### Issue 3: Nginx Fails to Start\n\n**Cause:** SSL certificate files don't exist when nginx starts\n\n**Solution:**\n```bash\n# Get certificate FIRST using standalone mode\ndocker-compose -f docker-compose-secure.yml down\ndocker run --rm -p 80:80 \\\n  -v \"$PWD/certbot/conf:/etc/letsencrypt\" \\\n  certbot/certbot certonly --standalone \\\n  -d your-domain.com \\\n  --email your@email.com \\\n  --agree-tos --no-eff-email\n\n# Then start services\ndocker-compose -f docker-compose-secure.yml up -d --build\n```\n\n### Issue 4: Can't Access from Internet\n\n**Troubleshooting:**\n```bash\n# Verify DNS points to your server\nnslookup your-domain.com\n\n# Check firewall allows 80 and 443\nsudo ufw status\n\n# Verify nginx is listening\ndocker-compose -f docker-compose-secure.yml logs nginx\n\n# Check if ports are accessible\n# From external machine:\ncurl -I http://your-public-ip:80\ncurl -I http://your-public-ip:443\n```\n\n### Issue 5: Used Wrong docker-compose.yml\n\n**Problem:** Ran `docker compose up` instead of `docker-compose -f docker-compose-secure.yml up`\n\n**Solution:**\n```bash\n# Stop insecure deployment\ndocker compose down\n\n# Use secure deployment\ndocker-compose -f docker-compose-secure.yml up -d --build\n```\n\n---\n\n## 🔒 Security Checklist\n\nAfter installation, verify:\n\n- [ ] Application accessible via HTTPS with valid certificate\n- [ ] HTTP automatically redirects to HTTPS\n- [ ] Session cookies have `Secure` and `HttpOnly` flags\n- [ ] Port 8000 (Flask) NOT accessible from internet\n- [ ] Port 5432 (PostgreSQL) NOT accessible from internet\n- [ ] Firewall configured (only 22, 80, 443 allowed)\n- [ ] Strong SECRET_KEY set (32+ characters)\n- [ ] Strong database password set (16+ characters)\n- [ ] `USE_HTTPS=true` in .env file\n- [ ] `ENABLE_WEBVIEW_FALLBACK=false` in .env file\n\n---\n\n## 🔄 Maintenance Commands\n\n### View Logs\n```bash\n# All services\ndocker-compose -f docker-compose-secure.yml logs -f\n\n# Specific service\ndocker-compose -f docker-compose-secure.yml logs -f nginx\ndocker-compose -f docker-compose-secure.yml logs -f web\ndocker-compose -f docker-compose-secure.yml logs -f postgres\n```\n\n### Restart Services\n```bash\n# Restart all\ndocker-compose -f docker-compose-secure.yml restart\n\n# Restart specific service\ndocker-compose -f docker-compose-secure.yml restart nginx\ndocker-compose -f docker-compose-secure.yml restart web\n```\n\n### Update Application\n```bash\n# Pull latest code\ngit pull\n\n# Rebuild and restart\ndocker-compose -f docker-compose-secure.yml up -d --build\n```\n\n### Backup Database\n```bash\n# Create backup\ndocker exec voicescript_postgres pg_dump -U voicescript_user voicescript_db > backup_$(date +%Y%m%d).sql\n\n# Backup uploads\ntar -czf uploads_backup_$(date +%Y%m%d).tar.gz uploads/\n```\n\n### Restore Database\n```bash\n# Restore from backup\ndocker exec -i voicescript_postgres psql -U voicescript_user voicescript_db < backup_20250930.sql\n```\n\n### Renew SSL Certificate (Manual)\n```bash\n# Certificates auto-renew every 12 hours via certbot container\n# Manual renewal:\ndocker-compose -f docker-compose-secure.yml run --rm certbot renew\ndocker-compose -f docker-compose-secure.yml exec nginx nginx -s reload\n```\n\n---\n\n## 📚 File Structure\n\n```\nvoicescript-collector/\n├── app.py                          # Flask application\n├── models.py                       # Database models\n├── Dockerfile                      # Container configuration\n├── docker-compose.yml              # LOCAL development (insecure)\n├── docker-compose-secure.yml       # PRODUCTION deployment (secure)\n├── setup-https.sh                  # Automated HTTPS setup script\n├── .env                            # Environment configuration (create this)\n├── templates/                      # HTML templates\n├── static/                         # CSS, JS, images\n├── uploads/                        # User file uploads\n├── logs/                           # Application logs\n├── nginx/\n│   ├── nginx.conf                  # Main nginx config\n│   └── conf.d/\n│       └── voicescript.conf        # Site configuration (update domain)\n├── certbot/\n│   ├── conf/                       # SSL certificates\n│   └── www/                        # ACME challenge files\n└── SECURITY_PUBLIC_DEPLOYMENT.md   # Detailed security guide\n```\n\n---\n\n## 🆘 Getting Help\n\n### Check Service Status\n```bash\ndocker-compose -f docker-compose-secure.yml ps\n```\n\n### Debugging Steps\n1. Check logs: `docker-compose -f docker-compose-secure.yml logs`\n2. Verify .env file exists and has correct values\n3. Ensure domain DNS points to your server IP\n4. Confirm firewall allows ports 80 and 443\n5. Test from external network (not local network)\n\n### Clean Reinstall\n```bash\n# Complete cleanup\ndocker-compose -f docker-compose-secure.yml down -v\ndocker system prune -af\nrm -rf certbot/conf/* certbot/www/* uploads/* logs/*\n\n# Start fresh\nsudo ./setup-https.sh\n```\n\n---\n\n## 📝 Important Notes\n\n1. **Never use `docker-compose.yml` for public deployment** - it's insecure (HTTP only)\n2. **Always use `docker-compose-secure.yml`** for production with `-f` flag\n3. **Test from external network** - local network may block access due to NAT loopback\n4. **Backup your .env file** - it contains critical secrets\n5. **Monitor logs regularly** - check for suspicious activity\n6. **Keep Docker images updated** - `docker-compose -f docker-compose-secure.yml pull`\n\n---\n\n## ✅ Success Indicators\n\nYour installation is successful when:\n\n- ✅ `https://your-domain.com` loads with green padlock 🔒\n- ✅ Demo login works from external network\n- ✅ Session cookies are secure (Secure + HttpOnly flags)\n- ✅ HTTP redirects to HTTPS automatically\n- ✅ Ports 8000 and 5432 are not accessible from internet\n- ✅ All containers show \"Up\" status\n- ✅ No errors in logs\n\n---\n\n## 🎉 You're Done!\n\nYour VoiceScript Collector is now securely deployed and accessible from anywhere!\n\n**Next Steps:**\n1. Share `https://your-domain.com` with your team\n2. Users can register or use demo accounts\n3. Configure Google OAuth (optional) for social login\n4. Set up regular database backups\n5. Monitor logs for issues\n\nFor more advanced configuration, see `SECURITY_PUBLIC_DEPLOYMENT.md`\n","size_bytes":12608},"check-cert-volume.sh":{"content":"#!/bin/bash\n\necho \"Checking certbot_conf Docker volume contents:\"\necho \"==============================================\"\necho \"\"\n\necho \"1. Volume contents:\"\ndocker run --rm -v certbot_conf:/etc/letsencrypt alpine ls -la /etc/letsencrypt/\necho \"\"\n\necho \"2. Live certificates directory:\"\ndocker run --rm -v certbot_conf:/etc/letsencrypt alpine ls -la /etc/letsencrypt/live/ 2>/dev/null || echo \"No live directory\"\necho \"\"\n\necho \"3. Looking for textgather.logiclayerhq.com:\"\ndocker run --rm -v certbot_conf:/etc/letsencrypt alpine ls -la /etc/letsencrypt/live/textgather.logiclayerhq.com/ 2>/dev/null || echo \"Domain directory not found\"\necho \"\"\n\necho \"4. Archive directory:\"\ndocker run --rm -v certbot_conf:/etc/letsencrypt alpine ls -la /etc/letsencrypt/archive/ 2>/dev/null || echo \"No archive directory\"\n","size_bytes":804},"full-reset.sh":{"content":"#!/bin/bash\n\n# VoiceScript Collector - Full Reset Script\n# Completely wipes and recreates the Docker deployment\n\nset -e\n\necho \"=========================================\"\necho \"VoiceScript Collector - Full Reset\"\necho \"=========================================\"\necho \"\"\necho \"⚠️  WARNING: This will DELETE all data!\"\necho \"\"\nread -p \"Continue? (y/n): \" -n 1 -r\necho\nif [[ ! $REPLY =~ ^[Yy]$ ]]; then\n    echo \"Aborted.\"\n    exit 1\nfi\n\n# Stop and remove EVERYTHING\necho \"\"\necho \"🛑 Stopping and removing all containers and volumes...\"\ndocker-compose -f docker-compose-secure.yml down -v\n\n# Generate secure credentials\necho \"\"\necho \"🔐 Generating secure credentials...\"\nSECRET_KEY=$(openssl rand -hex 32)\nPOSTGRES_PASSWORD=$(openssl rand -hex 16)\n\n# Get domain info\necho \"\"\nread -p \"Enter your domain (e.g., textgather.duckdns.org): \" DOMAIN\nread -p \"Enter your email: \" EMAIL\n\n# Create .env file\necho \"\"\necho \"📄 Creating .env file...\"\ncat > .env << EOF\n# PRODUCTION CONFIGURATION\nPOSTGRES_PASSWORD=$POSTGRES_PASSWORD\nSECRET_KEY=$SECRET_KEY\nFLASK_ENV=production\nUSE_HTTPS=true\nENABLE_WEBVIEW_FALLBACK=false\nDOMAIN=$DOMAIN\nEMAIL=$EMAIL\nUPLOAD_FOLDER=/app/uploads\nPORT=8000\nEOF\n\necho \"✅ .env file created\"\n\n# Fix permissions\necho \"\"\necho \"📁 Creating directories and fixing permissions...\"\n# Remove if they exist as files (not directories)\n[ -f logs ] && rm -f logs\n[ -f uploads ] && rm -f uploads\nmkdir -p logs uploads certbot/conf certbot/www\nchmod -R 777 logs uploads certbot\necho \"✅ Directories ready\"\n\n# Check if SSL certificates exist\nif [ ! -f \"certbot/conf/live/$DOMAIN/fullchain.pem\" ]; then\n    echo \"\"\n    echo \"⚠️  SSL certificates not found. Running SSL setup first...\"\n    echo \"\"\n    \n    # Run SSL setup with domain and email passed as arguments\n    if [ -f \"./setup-https.sh\" ]; then\n        ./setup-https.sh \"$DOMAIN\" \"$EMAIL\"\n    else\n        echo \"❌ setup-https.sh not found. Please run it manually after this script.\"\n        echo \"   Then restart with: docker-compose -f docker-compose-secure.yml restart nginx\"\n    fi\nfi\n\n# Start services\necho \"\"\necho \"🚀 Building and starting containers...\"\ndocker-compose -f docker-compose-secure.yml up -d --build\n\n# Wait for database\necho \"\"\necho \"⏳ Waiting for database to initialize...\"\nsleep 15\n\n# Seed demo data\necho \"\"\necho \"📊 Seeding demo data...\"\ndocker exec voicescript_app flask seed-demo --force --yes\n\necho \"\"\necho \"=========================================\"\necho \"✅ Full Reset Complete!\"\necho \"=========================================\"\necho \"\"\necho \"🌐 Application URL: https://$DOMAIN\"\necho \"\"\necho \"🔐 Demo Accounts (password: demo123):\"\necho \"   Admin:    admin@demo.com\"\necho \"   Reviewer: reviewer@demo.com\"\necho \"   Provider: provider@demo.com\"\necho \"\"\necho \"🔧 View logs: docker-compose -f docker-compose-secure.yml logs -f\"\necho \"\"\n","size_bytes":2847},"restart-docker.sh":{"content":"#!/bin/bash\n\n# VoiceScript Collector - Docker Restart Script\n# Fixes permissions and restarts containers\n\necho \"=========================================\"\necho \"VoiceScript Collector - Docker Restart\"\necho \"=========================================\"\necho \"\"\n\n# Fix permissions\necho \"📁 Fixing directory permissions...\"\nchmod -R 777 logs uploads\nmkdir -p logs uploads\necho \"✅ Permissions fixed\"\n\n# Stop containers\necho \"\"\necho \"🛑 Stopping containers...\"\ndocker-compose -f docker-compose-secure.yml down\n\n# Start containers\necho \"\"\necho \"🚀 Starting containers...\"\ndocker-compose -f docker-compose-secure.yml up -d\n\n# Wait for services\necho \"\"\necho \"⏳ Waiting for services to start...\"\nsleep 10\n\n# Show status\necho \"\"\necho \"📊 Container status:\"\ndocker-compose -f docker-compose-secure.yml ps\n\necho \"\"\necho \"=========================================\"\necho \"✅ Restart Complete!\"\necho \"=========================================\"\necho \"\"\necho \"🔧 Useful commands:\"\necho \"   View logs:  docker-compose -f docker-compose-secure.yml logs -f\"\necho \"   Stop:       docker-compose -f docker-compose-secure.yml down\"\necho \"\"\n","size_bytes":1130},"test-domain.sh":{"content":"#!/bin/bash\n\nDOMAIN=\"textgather.logiclayerhq.com\"\n\necho \"Testing domain: $DOMAIN\"\necho \"================================\"\necho \"\"\n\necho \"1. DNS Resolution:\"\nnslookup $DOMAIN\necho \"\"\n\necho \"2. Testing port 80 accessibility:\"\ntimeout 5 curl -I http://$DOMAIN 2>&1 || echo \"Port 80 not accessible\"\necho \"\"\n\necho \"3. Getting Let's Encrypt certificate (dry run):\"\ndocker run --rm -p 80:80 -p 443:443 \\\n    -v certbot_conf:/etc/letsencrypt \\\n    -v certbot_www:/var/www/certbot \\\n    certbot/certbot certonly --standalone --dry-run \\\n    -d $DOMAIN \\\n    --email hamid.badsha@gmail.com \\\n    --agree-tos \\\n    --no-eff-email \\\n    --non-interactive \\\n    -v\n\necho \"\"\necho \"================================\"\necho \"If dry run succeeded, the real certificate will work.\"\n","size_bytes":762}},"version":1}